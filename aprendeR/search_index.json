[
["index.html", "aprendeR Capítulo 1 Introducción", " aprendeR Andrea Fernández Conde Capítulo 1 Introducción R inicia a principios de los noventas en la Universidad de Auckland en Nueva Zelanda. Ross Ihaka, profesor del departamento de estadística, pensaba que debía existir una alternativa superior para el análisis de datos realizado por los alumnos, que utilizaban lo que él llamaba programas viejos y cuchos. Robert Gentleman le sugiere a Ross escribir un software cuya ambición inicial era poder enseñar sus cursos de licenciatura de primer año. Así, en 1991 generan una estructura básica a través de la cuál sus estudiantes podían hacer análisis de datos y producir modelos gráficos de la información. Lo bautizan R por sus iniciales (Ingenio 2016). Ross y Robert no comercializan el software sino que lo ponen a disposición de otros interesados. Ross ha expresado que R cambió su opinión acerca de la humanidad pues es el resultado del trabajo de muchos que no reciben ingresos o reconocimiento por el mismo (Ingenio 2016). En 1996, presentan R en un paper introductorio (Ihaka and Gentleman 1996). A partir de entonces, R ha crecido en forma importante. Entre los contribuidores actuales más relevantes se encuentra Hadley Wickham, alumno de licenciatura en el departamento de estadística de la Universidad de Auckland cuando R se encontraba en desarrollo. En la gráfica siguiente, se muestran las descargas anuales de paquetes de R del 2012 al 2016 del espejo de RStudio.1 Figura 1.1: Descargas anuales del espejo de RStudio de paquetes de R de 2012 a 2016 (en millones). En el 2016 paquetes de R fueron descargados 218,480,053 veces. El aumento en la popularidad de R no es el único elemento por el cuál R es un lenguaje valioso. Sin embargo, el que sea un lenguaje comúnmente enseñado en universidades y utilizado en empresas, lo convierte en una habilidad con considerable valor de mercado. En la encuesta de Stackoverflow, R se encuentra en el lugar séptimo de los mejores pagados para los desarrolladores cuya ocupación es matemáticas, superando a Python y a SQL (Stackoverflow 2016, Top paying tech per occupation, mathematics). En cuanto a las tecnologías más populares por tipo de desarrollador que declara dedicarse a matemáticas y datos, R está en el sexto lugar, el primer lugar lo tiene python, seguido de SQL (Stackoverflow 2016, Most Popular Technologies per Dev Type, Math and Data). Actualmente, R, python y SQL se encuentran entre las herramientas más populares tanto entre desarrolladores como empresas, aunque no son las únicas. La decisión de aprender alguno de estos lenguajes depende de muchos factores, entre ellos cuán natural resulta la interacción individual con cada cuál, el lenguaje preferido en el grupo de trabajo particular y el tipo de análisis que se requiere realizar en el día a día. Escapa del objetivo de este manual el realizar una comparación exhaustiva de tecnologías pero se recomienda tener en cuenta que cada herramienta tiene una especialidad específica y, particularmente en un ambiente de producción, es necesario tener esto en consideración. R es un excelente lenguaje para aprender ciencia de datos; de hecho en CRAN (2016) se describe a R como un proyecto para estadística computacional. Esto lo convierte en un lenguaje único pues fue construido por estadísticos y diseñado para realizar análisis de datos. Su uso generalizado en la comunidad estadística tiene la ventaja de que casi cualquier prueba o técnica estadística puede ser encontrada en algún paquete de R (Labs 2016). Además, existe una documentación extensa y estandarizada que facilita su uso. Aunque el material para aprender R es amplio y hay una comunidad mundial muy activa que constantemente produce nuevos recursos, existen pocas referencias que faciliten iniciar su aprendizaje para hispanoparlantes. En general, la documentación, listas de distribución, libros y tutoriales están escritos en inglés. Este manual tiene como objetivo guiar a principiantes en programación que tienen una formación previa como analistas de datos. El enfoque principal es el de facilitar de ejemplos que permitan al analista traducir la manipulación de datos que ya saben realizar en otro ambiente a R. El manual se estructura como sigue: en el capítulo 2 , se introducen elementos básicos para poder iniciar el trabajo en R. Se especifica cómo instalar el software, se recomienda utilizar un editor especializado, así como paquetes útiles para diferentes tareas. En particular, se explica cómo guardar código de manera que otras personas puedan ejecutarlo y cómo realizar documentos reproducibles. Por último, se explica cómo accesar a la ayuda y documentación, así como la forma en la que puede optimizarse su funcionamiento. Este capítulo actúa más como una referencia general para poder realizar el trabajo en el ambiente. En el capítulo 3, se introducen las funciones, las estructuras de datos y las estructuras de control disponibles en el lenguaje. El capítulo 4, explica como operar los objetos y estructuras detallados en el capítulo anterior, proporcionando múltiples ejemplos y ejercicios para familiarizar al lector con el lenguaje. El capítulo 5, detalla las herramientas básicas para poder realizar un proyecto de datos en R. Las herramientas que se desarrollan en este capítulo permiten iterar sobre parte del ciclo de un proyecto de datos: importación de datos al ambiente, manipulación, limpieza y visualización de los mismos. Éstas herramientas permiten operar sobre los objetos introducidos en el capítulo 3 en una forma eficiente, fácil de aprender, fácil de leer y que permite que el usuario realice manipulaciones de datos complejas que le permitirán, a su vez, utilizar todas las herramientas de modelado que R posee que necesitan como insumo datos limpios y preparados en una forma específica. Cada capítulo incluye ejercicios y respuestas a los mismos; al final se recomienda material adicional para repasar los conceptos estudiados. El material se encuentra disponible electrónicamente en https://github.com/animalito/aprendeR. Para facilitar el aprendizaje, se recomienda descargar los materiales o clonar el repositorio, esto permite revisar el material y el código desde el ambiente local evitando copiar y pegar el mismo para su ejecución. Bibliografía "],
["r-lo-basico.html", "Capítulo 2 R: lo básico", " Capítulo 2 R: lo básico En este capítulo se revisarán elementos básicos para poder iniciar el trabajo en R. Primero que nada, se proporcionan instrucciones de instalación según el sistema operativo utilizado. Posteriormente, se recomiendan editores que facilitan la edición de código y documentos en R, particularmente Rstudio o Emacs combinado con ESS. Posteriormente, se describe brevemente el espacio de trabajo y se dan algunos ejemplos que ilustran la interacción con la consola. Se cubren algunos temas útiles para el trabajo continuo en R: se recomiendan paquetes que complementan a la instalación básica de R y que son particularmente útiles para el análisis de datos; se describe qué es un script y un documento de R; se explica cómo obtener ayuda y accesar a la documentación. Por último, se recomienda realizar instalaciones adicionales que permiten optimizar el trabajo de álgebra lineal que soporta los distintos métodos implementados en R. "],
["instalacion.html", "2.1 Instalación", " 2.1 Instalación Para los usuarios de Linux, se pueden correr los siguientes comandos en la consola para instalar R compilándolo (Escalante 2015). Ésta es la mejor opción pues se aprovecharán todas las características de su máquina. #!/bin/bash while true; do read -p &quot;Do you wish to Compile R? y/n &quot; yn case $yn in [Yy]* ) sudo apt-get update; sudo apt-get upgrade -y; sudo apt-get install -y build-essential libpq-dev liblapack3 libblas3 \\ libmysql++-dev sqlite3 fort77 gnuplot-x11 texinfo liblapack-dev \\ texi2html libglpk-dev libgeos-dev libgdal1-dev libproj-dev; sudo apt install -y gfortran autoconf automake bzip2-doc cdbs \\ debhelper dh-strip-nondeterminism dh-translations gettext intltool \\ intltool-debian libarchive-zip-perl libasprintf-dev libbz2-dev \\ libfile-stripnondeterminism-perl libgettextpo-dev libgettextpo0 \\ liblzma-dev libmail-sendmail-perl libncurses5-dev libpcre3-dev \\ libpcre32-3 libpcrecpp0v5 libreadline-dev libreadline6-dev \\ libsys-hostname-long-perl libtinfo-dev libunistring0 m4 po-debconf \\ python-scour xorg-dev libcairo2-dev libgtk2.0-dev; sudo apt-get -y build-dep r-base; mkdir -p $HOME/src; cd $HOME/src; wget -c http://cran.r-project.org/src/base/R-latest.tar.gz; tar zxvf R-latest.tar.gz &amp;&amp; rm R-latest.tar.gz; cd &quot;$(ls -dt R-*/ | head -1 )&quot;; ./configure --enable-memory-profiling --enable-R-shlib \\ --with-blas --with-lapack --with-tcltk --with-cairo \\ --with-libpng --with-jpeglib --with-libtiff; make; sudo make install; break;; [Nn]* ) sudo apt-key adv --keyserver keyserver.ubuntu.com \\ --recv-keys E084DAB9; ubuntu_codename=`lsb_release -cs` ; sudo chmod ugo+rw /etc/apt/sources.list; echo \\ &quot;deb http://cran.r-project.org/bin/linux/ubuntu $ubuntu_codename/&quot; \\ &gt;&gt; &#39;/etc/apt/sources.list&#39;; sudo apt-get update; sudo apt-get install -y --no-install-recommends r-base r-base-dev; exit;; * ) echo &quot;Please answer yes or no.&quot;;; esac done Para descargar e instalar R en su versión precompilada, seguir las instrucciones de este link para el sistema operativo que estén utilizando. Bibliografía "],
["editores.html", "2.2 Editores", " 2.2 Editores Hay muchísimos, en particular se mencionarán dos. 2.2.1 RStudio Puedes descargar RStudio siguiendo las instrucciones para cada sistema operativo. RStudio es un IDE (integrated development environment) para R que incluye consola, editor de texto, memoria de gráficos, vista de objetos en el ambiente y otras herramientas útiles para desarrollar (RStudio Team 2016). En su versión más reciente, también autocompleta código y depura (debugging) “al vuelo”, es decir, al mismo tiempo que se escribe, señala potenciales errores de código. Hay que tener cuidad con el uso de la memoria RAM de este editor pues utiliza muchos recursos de la computadora y -cuando están usando una gran cantidad de datos o procesos muy pesados- RStudio suele detenerse fácilmente. Buenas prácticas en general: guardar seguido, seguir un flujo de trabajo (workflow) aunado a controlador de versiones (o algún tipo de respaldo) y, sobretodo, crear las funciones, lógica, algoritmos, con una muestra de los datos. 2.2.2 ESS Emacs speaks statistics es el add-on favorito para los usuarios de emacs y R (Rossini et al. 2004). Soporta la edición de scripts para R, S-plus, SAS, Stata, OPenBUGS/JAGS. Para los que además ya están acostumbrados al enorme poder de Emacs, ésta será la mejor opción. El editor interactivo es muy bueno y casi no consume memoria. Bibliografía "],
["el-espacio-de-trabajo-workspace.html", "2.3 El espacio de trabajo (Workspace)", " 2.3 El espacio de trabajo (Workspace) El espacio de trabajo es el ambiente actual de trabajo en R. Incluye todos los objetos definidos por el usuario (vectores, matrices, funciones, dataframes, listas). Una sesión de R inicia cuando abres la consola. Al terminar el trabajo se puede guardar la imagen del espacio de trabajo tal cual está, de manera que sea posible continuar desde donde te quedaste (Kabacoff 2015, pág. 11). 2.3.1 Directorio de trabajo El directorio de trabajo (working directory) es el directorio en tu computadora en el que estás trabajando en ese momento. Cuando se le pide a R que abra un archivo o guarde ciertos datos, R lo hará a partir del directorio de trabajo que le hayas fijado. Para saber en qué directorio te encuentras, se usa el comando getwd(). Usa la mnemotécnica del inglés: get working directory ≡ getwd. Notarás como muchas funciones tienen un nombre que acorta lo que hacen. getwd() ## [1] &quot;/home/salim/SOCIEDAT/ssR&quot; Para especificar el directorio de trabajo, se utiliza el comando setwd() (set working directory) en la consola. Y volvemos a setwd(&quot;/home/animalito/study/&quot;) getwd() Ejercicios Abre tu consola de R y escribe setwd(). Utiliza la tecla tab para autocompletar las posibles rutas desde donde quiera que estés. Escoge alguna (nuevamente usando la tecla tab para moverte entre las opciones). Si esto no funciona, teclea textualmente alguna de las rutas que ves. Cierra la doble comilla y el paréntesis. Teclea enter. Debes encontrarte en la ruta elegida cuando tecleas getwd(). Con lo que acabamos de hacer, R buscará archivos o guardará archivos en la carpeta que obtuviste con el comando getwd(). En R también es posible navegar a partir de el directorio de trabajo. Como siempre, ../un_archivo.R le indica a R que busque una carpeta arriba del actual directorio de trabajo por el archivo un_archivo.R. datos/otro_archivo.R hace que se busque en el directorio de trabajo, dentro de la carpeta datos por el archivo otro_archivo.R Rutas relativas vs. Rutas absolutas El resultado que se muestra aquí al usar el comando getwd() depende de la computadora en la que se esta trabajando debido a que es una ruta absoluta. Nota como es diferente la ruta que obtienes al correr el comando en tu consola de R. Eso es porque se trata de una ruta absoluta, es decir, es tal que da la ruta (path) completo al directorio en cuestión. Puedes accesar todos los directorios o archivos usando su ruta absoluta. En investigación reproducible (reproducible research), en investigación colaborativa o incluso cuando trabajas en varias computadoras es una buena idea usar rutas relativas en lugar de absolutas. Esto hace que el código sea menos dependiente de una estructura de archivos o computadora en particular (Gandrud 2013, pág. 67). En general, es buena práctica configurar el código de un proyecto con rutas relativas. En R en particular, cuando guardas un Rmarkdown y lo corres desde la línea de comandos (o lo tejes desde RStudio), la ruta que está fija -como si hubieras usado el comando setwd() es en donde vive ese archivo, es decir, el directorio en donde está guardado el mismo. Desde cualquier script puedes llamar a otros usando este tipo de ruta como en el ejemplo anterior. 2.3.2 Ejemplos básicos La consola permite hacer operaciones sobre números o caracteres (cuando tiene sentido). # Potencias, sumas, multiplicaciones 2^3 + 67 * 4 - (45 + 5) ## [1] 226 # Comparaciones 56 &gt; 78 ## [1] FALSE 34 &lt;= 34 ## [1] TRUE 234 &lt; 345 ## [1] TRUE &quot;hola&quot; == &quot;hola&quot; ## [1] TRUE &quot;buu&quot; != &quot;yay&quot; ## [1] TRUE # módulo 10 %% 4 ## [1] 2 Estas operaciones también pueden ser realizadas entre vectores2. # Creamos un vector con entradas del -1 al 12 y lo asignamos a la variable x x &lt;- -1:12 # Lo vemos x ## [1] -1 0 1 2 3 4 5 6 7 8 9 10 11 12 # Le sumamos 1 a todas las entradas x + 1 ## [1] 0 1 2 3 4 5 6 7 8 9 10 11 12 13 # Multiplicamos por 2 cada entrada y le sumamos 3 2 * x + 3 ## [1] 1 3 5 7 9 11 13 15 17 19 21 23 25 27 # Sacamos el módulo de cada entrada x %% 5 ## [1] 4 0 1 2 3 4 0 1 2 3 4 0 1 2 2.3.3 Comandos útiles Para enlistar los objetos que están en el espacio de trabajo ls() ## [1] &quot;all&quot; &quot;df&quot; &quot;df2&quot; &quot;group.colors&quot; ## [5] &quot;limpia&quot; &quot;pega.estados&quot; &quot;quita.nas&quot; &quot;x&quot; Para eliminar todos los objetos en un directorio de trabajo (workspace) rm(list = ls()) # se puede borrar solo uno, por ejemplo, nombrándolo ls() ## character(0) También se puede utilizar/guardar la historia de comandos utilizados history() history(max.show = 5) history(max.show = Inf) # Muestra toda la historia # Se puede salvar la historia de comandos a un archivo savehistory(file = &quot;mihistoria&quot;) # Por default, R ya hace esto # en un archivo &quot;.Rhistory&quot; # Cargar al espacio de trabajo actual (current workspace) una # historia de comandos en particular loadhistory(file = &quot;mihistoria&quot;) Es posible también guardar el ambiente de trabao (workspace) -en forma completa- en un archivo con el comando save.image() a un archivo con extensión .RData. Puedes guardar una lista de objetos específica a un archivo .RData. Por ejemplo: x &lt;- 1:12 y &lt;- 3:45 save(x, y, file = &quot;ejemplo.RData&quot;) #la extensión puede ser arbitraria. Después puedo cargar ese archivo. Prueba hacer: rm(list = ls()) # limpiamos workspace load(file = &quot;ejemplo.RData&quot;) #la extensión puede ser arbitraria. ls() Nota como los objetos preservan el nombre con el que fueron guardados. Bibliografía "],
["paquetes-libraries.html", "2.4 Paquetes (libraries)", " 2.4 Paquetes (libraries) R puede hacer muchos análisis estadísticos y de datos. Las diferentes capacidades están organizadas en paquetes o librerías. Con la instalación estándar resumida en la sección B-2, se instalan también los paquetes más comunes (también llamado el base o R-básico). Para obtener una lista de todos los paquetes instalados se puede utilizar el comando library() en la consola o en un script. Existen una gran cantidad de paquetes disponibles además de los incluidos por omisión (default). 2.4.1 CRAN Comprehensive R Archive Network (CRAN 2016) es una colección de sitios que contienen exactamente el mismo material, es decir, son espejos (mirrors) de las distribuciones de R, las extensiones, la documentación y los binarios. El master de CRAN está en Wirtschaftsuniversität Wien en Austria. Éste se “espeja” (mirrors) en forma diaria a muchos sitios alrededor del mundo. En la lista de espejos se puede ver que para México están disponibles el espejo del ITAM, del Colegio de Postgraduados (Texcoco) y Jellyfish Foundation (CRAN 2016). Los espejos son importantes pues, cada vez que busquen instalar paquetes, se les preguntará qué espejo quieren utilizar para la sesión en cuestión. Del espejo que selecciones, será del cuál R bajará el binario y la documentación. Del CRAN es que se obtiene la última versión oficial de R. Diario se actualizan los espejos. Para más detalles consultar el FAQ. Para contribuir un paquete en CRAN se deben seguir las instrucciones aquí. 2.4.2 Github Git es un controlador de versiones muy popular para desarrollar software. Cuando se combina con GitHub se puede compartir el código con el resto de la comunidad. Éste controlador de versiones es el más popular entre los que contribuyen a R. Muchos problemas a los que uno se enfrenta alguien ya los desarrolló y no necesariamente publicó el paquete en CRAN. Para instalar algún paquete desde GitHub, se pueden seguir las instrucciones siguientes install.packages(&quot;devtools&quot;) devtools::install_github(&quot;username/packagename&quot;) Donde username es el usuario de Github y packagename es el nombre del repositorio que contiene el paquete. Cuidado, no todo repositorio en GitHub es un paquete. Para más información ver el capítulo Git and GitHub en H. Wickham (2015b). 2.4.3 Otras fuentes Otros lugares en donde es común que se publiquen paquetes es en Bioconductor un proyecto de software para la comprensión de datos del genoma humano. Bibliografía "],
["paquetes-recomendados.html", "2.5 Paquetes recomendados", " 2.5 Paquetes recomendados Hay muchísimas librerías y lo recomendable es, dado un problema y un modelo para resolverlo, revisar si alguien ya implementó el método en algunas de las fuentes de paquetes mencionadas antes. Para mantener orden en los paquetes descargados puede ser útil utilizar el Rinker and Kurkiewicz (2015) pues provee de herramientas para instalar paquetes en una forma un poco más sencilla que usando la función install.packages. En particular, la función p_load permite instalar, cargar y actualizar uno o varios paquetes. Si queremos instalar varios paquetes usando las herramientas del R básico (base) (R Core Team 2016b) haríamos algo como (ejemplo tomado de Rinker and Kurkiewicz 2015, en la viñeta de introducción al paquete): packs &lt;- c(&quot;XML&quot;, &quot;devtools&quot;, &quot;RCurl&quot;, &quot;fakePackage&quot;, &quot;SPSSemulate&quot;) success &lt;- suppressWarnings(sapply(packs, require, character.only = TRUE)) install.packages(names(success)[!success]) sapply(names(success)[!success], require, character.only = TRUE) Con pacman::p_load la tarea se reduce a: pacman::p_load(XML, devtools, RCurl, fakePackage, SPSSemulate) Nota como se puede llamar a una función por su nombre p_load una vez que ya cargamos el paquete en el cuál esa función está guardada con el comando library(pacman) o podemos llamarla directamente utilizando la convención paquete::funcion, en este caso, pacman::p_load. Para instalar pacman escribe: install.packages(&quot;pacman&quot;) Algunos paquetes se encuentran en desarrollo. En particular, si se encuentran en github pueden descargarse usando la función pacman::p_install_gh('usuario/repositorio'). A continuación, hay una lista de paquetes que se recomienda descargar o revisar para tener a la mano herramientas diversas útiles para el trabajo del científico de datos. La lista no es comprensiva pues hay un gran número de paquetes útiles. # Para cargar datos al ambiente de trabajo (data load) pacman::p_load(RODBC, RMySQL, RPostgreSQL, RSQLite, foreign, Rpostgres, haven , readr) pacman::p_install_gh(&quot;hadley/readxl&quot;) pacman::p_install_gh(&quot;rstats-db/RPostgres&quot;) # Para manipular datos (data manipulation) pacman::p_load(plyr, dplyr, data.table, tidyr, stringr, lubridate, gsubfn) # Para visualizar datos (data visualization) pacman::p_load(ggplot2, graphics, ggvis) pacman::p_install_gh(&quot;RcppCore/Rcpp&quot;) pacman::p_install_gh(&quot;rstats-db/DBI&quot;) pacman::p_install_gh(&#39;ramnathv/htmlwidgets&#39;) pacman::p_install_gh(&#39;rstudio/leaflet&#39;) pacman::p_install_gh(&#39;bwlewis/rthreejs&#39;) pacman::p_install_gh(&#39;htmlwidgets/sparkline&#39;) pacman::p_load(dygraphs, DT, DiagrammeR, networkD3, googleVis) # Para modelar (data modelling) pacman::p_load(car, mgcv, lme4, nlme, randomForest, multcomp, vcd , glmnet, survival, caret) # Para generar reportes (reports) pacman::p_load(shiny, xtable, knitr, rmarkdown) # Para trabajar con datos espaciales (spatial data) pacman::p_load(sp, maptools, maps, ggmap, rgdal) # Para trabajo con series de tiempo (time series) pacman::p_load(zoo, quantmod) # Para escribir código de alto rendimiento en R (High performance R code) pacman::p_load(Rcpp, parallel) # Trabajar con la web pacman::p_load(XML, jsonlite, httr) # Para escribir paquetes en R pacman::p_load(devtools, testthat, roxygen2) Packrat Cuando cambian las versiones de distintos paquetes de R, es posible que código que solía funcionar deje de hacerlo. Por esta razón, es conveniente empaquetar proyectos de código de manera que el código en un proyecto específico tenga asociados también las versiones específicas de los paquetes con los cuáles fue creado. Una forma de lograr esto es utilizando packrat. Para mayor detalle, ver el apéndice B. Bibliografía "],
["scripting.html", "2.6 Scripting", " 2.6 Scripting R es un intérprete. Utiliza un ambiente basado en línea de comandos. Por ende, es necesario escribir la secuencia de comandos que se desea realizar a diferencia de otras herramientas en donde es posible utilizar el mouse o menús. Aunque los comandos pueden ser ejecutados directamente en consola una única vez, también es posible guardarlos en archivos conocidos como scripts. Típicamente, utilizamos la extensión .R o .r. En RStudio (RStudio Team 2016), CTRL + SHIFT + N abre inmediatamente un nuevo editor en el panel superior izquierdo. En RStudio, por ejemplo, se puede ir editando el script y corriendo los comandos línea por línea con CTRL + ENTER. Esto también aplica para correr una selección del texto editable3. Es posible también ejecutar todo el script source(&quot;foo.R&quot;) O con el atajo CTRL + SHIFT + S en RStudio. Para enlistar algunos atajos (shortcuts) comunes en RStudio presiona ALT + SHIFT + K. De la misma manera, si utilizas Emacs + ESS (Rossini et al. 2004), existen múltiples atajos de teclado para realizar todo mucho más eficientemente. Estudiarlos no es tiempo perdido. Bibliografía "],
["rmarkdown.html", "2.7 rmarkdown", " 2.7 rmarkdown Es posible generar documentos reproducibles en R utilizando R Markdown, un framework que permite salvar y ejecutar código, así como generar reportes de alta calidad en múltiples formatos (Inc. 2016b). Para utilizarlo, se instala el paquete rmarkdown con el comando: install.packages(&quot;rmarkdown&quot;) Para generar un documento, se necesitan conocer únicamente algunos elementos importantes. La extensión que se suele utilizar para estos documentos es .Rmd o .rmd. 2.7.1 Encabezado y formatos El primer elemento es el encabezado y se conoce como el yaml o front-matter. Se coloca en la parte superior del documento y corresponde a las opciones que ofrece pandoc para la generación de documentos. Éste contiene la especificación de elementos como el título del documento, autor, fecha, entre otros. Además, se especifica el formato de salida del documento. Para crear un documento en HTML, por ejemplo, es necesario especificar como el output del documento html_output y se ve como sigue: --- title: &quot;Un título&quot; author: &quot;Un autor&quot; date: &quot;Una fecha&quot; output: html_document: toc: yes toc_depth: 2 toc_float: true theme: spacelab --- En este ejemplo, se colocaron opciones adicionales para el documento HTML como el que incluya una tabla de contenidos (toc: yes), que la profundidad de dicha tabla de contenidos incluya los primeros dos niveles de encabezados (toc_depth: 2), que la tabla de contenidos sea flotante -que se encuentre fija en una barra a la izquierda del documento aunque se desplace el documento (toc_float: true) y, por último, se especifica el tema para la estética del documento (theme: spacelab). Existen muchas otras opciones, mismas que puedes encontrar en la documentación (Inc. 2016a). Es posible también especificar como salida para el documento un pdf con la opción pdf_document. Las opciones se encuentran también en la documentación (Inc. 2016c). Esta opción es conveniente cuando se tiene conocimiento previo de LaTeX. Por último, cabe mencionar la opción word_document, cuyas opciones se encuentran aquí (Inc. 2016e) y la opción md_document que compila a Markdown. Así como es posible generar documentos, es posible crear presentaciones en HTML (ioslides o slidy) o pdf (beamer) (Inc. 2016d) y dashboards (con flexdashboards) (Allaire 2016). En el apéndice A se detalla la sintaxis de Markdown, misma que permitirá escribir documentos. 2.7.2 Knitr chunks Entre distintas líneas de texto, es posible incluir chunks o pedazos de código de R. Para iniciar un pedazo de código, se incluyen tres acentos invertidos, seguidos de la letra r entre llaves; se cierra un pedazo de código con tres acentos invertidos (Inc. 2016d). ```{r} paste(&quot;Hola&quot;, &quot;Mundo&quot;) ``` ## [1] &quot;Hola Mundo&quot; Se puede incluir un pedazo de código en cualquier parte del documento y se controlan las opciones de cada pedazo, por ejemplo, incluyendo una opción para que el código no se imprima y que solo se imprima el resultado agregando {r, echo = FALSE}: ## [1] &quot;Hola Mundo&quot; Las opciones se encuentran resumidas en Inc. (2016d). Bibliografía "],
["ayuda-y-documentacion.html", "2.8 Ayuda y documentación", " 2.8 Ayuda y documentación R tiene mucha documentación. Dado que es imposible recordar todas las funciones o cómo utilizar todo lo que ya está hecho, es necesario aprender a leerla. Desde la consola se puede accesar a la misma. Para ayuda general, help.start() Para la ayuda de una función en especifico, por ejemplo, si se quiere graficar algo y sabemos que existe la función plot podemos consultar fácilmente la ayuda. help(plot) # o tecleando directamente ?plot El segundo ejemplo se puede extender para buscar esa función en todos los paquetes que tengo instalados en mi ambiente al escribir ??plot. A veces, es útil ver el cuerpo de una función. Esta tarea no necesariamente es trivial. Para funciones generadas por el usuario, usa xx &lt;- function(x) x^2 body(xx) ## x^2 # o simplemente imprimir el objeto en donde guardamos la función xx ## function(x) x^2 También funciona para algunas funciones de paquete, por ejemplo rename: library(plyr) body(rename) ## { ## names(x) &lt;- revalue(names(x), replace, warn_missing = warn_missing) ## duplicated_names &lt;- names(x)[duplicated(names(x))] ## if (warn_duplicated &amp;&amp; (length(duplicated_names) &gt; 0L)) { ## duplicated_names_message &lt;- paste0(&quot;`&quot;, duplicated_names, ## &quot;`&quot;, collapse = &quot;, &quot;) ## warning(&quot;The plyr::rename operation has created duplicates for the &quot;, ## &quot;following name(s): (&quot;, duplicated_names_message, ## &quot;)&quot;, call. = FALSE) ## } ## x ## } Para plot, en cambio, al usar la función body se ve: body(plot) ## UseMethod(&quot;plot&quot;) Esto es porque plot es una función genérica (S3) que tiene métodos para distintas clases de objetos. En esos casos, primero debemos usar la función methods para enlistar los métodos que tiene esa función. methods(plot) ## [1] plot.acf* plot,ANY-method plot,color-method ## [4] plot.data.frame* plot.decomposed.ts* plot.default ## [7] plot.dendrogram* plot.density* plot.ecdf ## [10] plot.factor* plot.formula* plot.function ## [13] plot.ggplot* plot.gtable* plot.hclust* ## [16] plot.histogram* plot.HoltWinters* plot.isoreg* ## [19] plot.lm* plot.medpolish* plot.mlm* ## [22] plot.ppr* plot.prcomp* plot.princomp* ## [25] plot.profile.nls* plot.R6* plot.raster* ## [28] plot.spec* plot.stepfun plot.stl* ## [31] plot.table* plot.ts plot.tskernel* ## [34] plot.TukeyHSD* ## see &#39;?methods&#39; for accessing help and source code Si tiene asteriscos, significa que la función para ese método en particular no viene directamente del espacio de nombres del paquete pero, de cualquier forma, lo podemos pedir usando la función getAnywhere para cualquiera de los métodos que se desplegaron: getAnywhere(plot.density) ## A single object matching &#39;plot.density&#39; was found ## It was found in the following places ## registered S3 method for plot from namespace stats ## namespace:stats ## with value ## ## function (x, main = NULL, xlab = NULL, ylab = &quot;Density&quot;, type = &quot;l&quot;, ## zero.line = TRUE, ...) ## { ## if (is.null(xlab)) ## xlab &lt;- paste(&quot;N =&quot;, x$n, &quot; Bandwidth =&quot;, formatC(x$bw)) ## if (is.null(main)) ## main &lt;- deparse(x$call) ## plot.default(x, main = main, xlab = xlab, ylab = ylab, type = type, ## ...) ## if (zero.line) ## abline(h = 0, lwd = 0.1, col = &quot;gray&quot;) ## invisible(NULL) ## } ## &lt;bytecode: 0x50a08a0&gt; ## &lt;environment: namespace:stats&gt; Nota como el método plot.density viene del paquete stats.4 La documentación normalmente se acompaña de ejemplos. Para correr los ejemplos sin necesidad de copiar y pegar, prueba example(plot) Para búsquedas más comprensivas, se puede buscar de otras maneras: apropos(&quot;foo&quot;) # Enlista todas las funciones que contengan la cadena &quot;foo&quot; RSiteSearch(&quot;foo&quot;) # Busca por la cadena &quot;foo&quot; en todos # los manuales de ayuda y listas de distribución. Hay otro tipo de funciones en las que accesar al código fuente no se pueda con los métodos descritos. Para ello, es útil revisar la sección “old-school object-oriented programming in R” (Adler 2010, págs. 131-133) o las secciones dedicadas a los objetos S3 y S4 en H. Wickham (2014a).↩ "],
["optimizando.html", "2.9 Optimizando", " 2.9 Optimizando Es común que muy pronto nos encontremos con limitaciones al poder de cómputo y rapidez con el que R procesa los datos. Hay operaciones intensivas como, por ejemplo, la inversión de matrices (qr) o el análisis por componentes principales (svd). Incluso una selección de variables (back/forward selection) usando una simple regresión lineal sobre múltiples regresores puede llevar un tiempo de cómputo de horas/días o no terminar. Una de las manera más rápidas de mejorar el rendimiento (performance) de R es instalando las librerías de álgebra lineal que puede utilizar el software para hacer las operaciones más rápido. Para mucho (demasiado) detalle al respecto, referirse a la comparación de rendimiento en Eddelbuettel (2010) o al paquete del mismo autor Eddelbuettel (2016). Para la parte práctica de todo esto, referirse a este blog para instalar las librerías apropiadas para BLAS y Lapack (Klamer 2014). Para una comparación bastante práctica de las diferentes versiones de esas librerías, ver aquí (Nguyen 2014). Bibliografía "],
["material-adicional.html", "2.10 Material adicional", " 2.10 Material adicional Práctica y paciencia son dos elementos fundamentales para tener éxito cuando se aprende un nuevo lenguaje de programación. Un proyecto interesante para aprender R es swirl (Kross et al. 2016), un paquete en CRAN en el que se desarrolla una gama de cursos que permiten aprender interactivamente desde la consola de R. El material actualmente se encuentra en inglés. Para instalar swirl, install.packages(&quot;swirl&quot;) library(&quot;swirl&quot;) Luego llama a la función swirl para activarlo swirl() Lo primero que te pedirá es un nombre de usuario (para que pueda guardar el avance en los cursos y no debas regresar) y dará algunas instrucciones y comandos útiles. skip() para saltarte la pregunta actual play() para poder utilizar la consola en ese momento y practicar un poco más nxt() para que se pase a la siguiente pregunta bye() para salir de swirl main() para regresar al menú principal info() para recordar las instrucciones Una vez que te da la introducción, acepta que te instale el curso de R Programming El material de este capítulo se cubre en los módulos 1 a 3 del curso R Programming. Bibliografía "],
["estructuras-y-funciones.html", "Capítulo 3 Estructuras y funciones", " Capítulo 3 Estructuras y funciones En este capítulo se introducen los principales objetos de R. Primero, se definen brevemente. Después se introducen las funciones, objetos que permiten realizar acciones sobre otros objetos. Posteriormente, se introducen las distintas estructuras de datos en R básico. El primer bloque de construcción son las clases de datos con los que R sabe trabajar, es decir, caracteres, números enteros, reales, complejos y booleanos. El segundo bloque son los vectores. Esta es una estructura fundamental en R y están conformados por un conjunto de elementos de una de las clases de datos. El tercero son las matrices, que le agregan una dimensión a los vectores. Las listas son como vectores pero pueden contener un subconjunto de elementos de cualesquiera de las clases, incluida otra lista. Los dataframes son listas con la restricción que cada uno de sus elementos es un vector del mismo tamaño. Esta estructura es la más natural para un estadístico pues refiere a la forma tabular en la que se acostumbra pensar a los datos en esa disciplina. Los tibbles y los datatables extienden los dataframes, haciéndolos más eficientes para el procesamiento de una mayor cantidad de datos. Finalmente, se mencionan objetos adicionales -como el infinito y el objeto que representa valores perdidos- y se describen las principales estructuras de control, proporcionando ejemplos para escribirlos en R. "],
["objetos.html", "3.1 Objetos", " 3.1 Objetos En R Todo lo que existe es un objeto. Todo lo que sucede es una llamada a una función. Todo lenguaje de programación provee de una forma de accesar los datos guardados en memoria. R no permite un acceso directo a la memoria de la computadora pero ofrece varias estructuras de datos especializadas para realizar esa tarea. A estas estructuras, se les da el nombre de objetos (R Core Team 2016a, ver sección 2 “objetos”). Estos objetos son referidos a través de símbolos o variables, sin embargo, los símbolos son también objetos y pueden ser manipulados de la misma manera. Todos los objetos tienen un tipo, mismo que se le puede preguntar a los objetos con la función typeof typeof(&quot;hola&quot;) ## [1] &quot;character&quot; Esta función puede reconocer muchos tipos, entre ellos algunos de los que veremos con mayor detalle a continuación. Comenzaremos con las funciones que, regresando al cuadro anterior, todo lo que sucede es una llamada a una función. Posteriormente, se revisarán las estructuras de datos más básicas en R y, por último, se verán estructuras de control básicas que permitirán mezclar el uso de objetos de manera que se operen bajo ciertas condiciones lógicas. Bibliografía "],
["funciones.html", "3.2 Funciones", " 3.2 Funciones Hay una regla de oro en programación en general: DRY code5 (acrónimo de “Don’t repeat yourself”) (Hunt and Thomas 1999). Básicamente esto se reduce a no te repitas. Cuando tienes las mismas líneas de código varias veces (cuando estas copiando y pegando mucho) entonces lo que necesitas es escribir una función que realice esa tarea. En R las funciones son los building blocks de básicamente todo. Como todo lo demás en R, las funciones son también objetos. Cuando llamas a un objeto en R, casi siempre estas en realidad llamando a una función. 3.2.1 Componentes de una función El body() o cuerpo de la función es el código dentro de la misma. formals() o el listado de argumentos formales de la función, controla cómo se puede llamar a una función. El ambiente environment() determina cómo son referidas las variables dentro de la función. La lista de argumentos se obtiene con args() # Ejecuto la función f &lt;- function(x) x # Imprimo el objeto f f ## function(x) x # Al usar la función body, veo solo el cuerpo body(f) ## x # Listo sus parámetros o argumentos formals(f) ## $x # Veo en qué ambiente está la función environment(f) ## &lt;environment: R_GlobalEnv&gt; Una vez definida una función, llamarla es muy sencillo: se le proporciona un valor para los parámetros y nos regresa el resultado esperado. Una función puede regresar cualquier objeto, por ejemplo, una función o un valor. Llamamos a la función declarada arriba: f(4) ## [1] 4 # Elimino la función del espacio de trabajo rm(f) Por defecto (default), los argumentos de una función son flojos (lazy), es decir, solamente son evaluados cuando se utilizan (esto es importante pues si tienes un error en una función no te darás cuenta cuando ejecutes la misma sino cuando la mandes llamar). 3.2.2 El ambiente Las variables que se definen dentro de una función existen en un ambiente distinto al ambiente global de R. Si una variable no está definida dentro de la función, R busca en el nivel superior por esa variable. x &lt;- 2 g &lt;- function() { y &lt;- 1 c(x, y) } g() ## [1] 2 1 rm(x, g) Así como fuimos capaces de anidar ciclos for, también podemos anidar funciones. Esta capacidad es muy útil pero hay que tener cuidado con los ambientes y la jerarquía en los mismos. myfuncion &lt;- function() { print(&quot;Hola&quot;) } myfuncion() ## [1] &quot;Hola&quot; Podemos generar funciones con mayor utilidad. suma &lt;- function(x, y){ return(x + y) } vector &lt;- c(1, 2, 3, 4) sapply(vector, suma, 2) ## [1] 3 4 5 6 Toda función regresa un valor. x &lt;- 10 f &lt;- function() { y &lt;- 25 g &lt;- function() { z &lt;- 30 c(x = x, y = y, z = z) } g() } f() ## x y z ## 10 25 30 f &lt;- function(x) { x * 2 } g &lt;- function(x) { x + 2 } f(g(2)) ## [1] 8 g(f(2)) ## [1] 6 En este caso, utilizamos una función con parámetros que recibe cuando es llamada. También podemos generar funciones con valores predefinidos, es decir, defaults. Éstos son utilizados cuando se llama a la función a menos que se especifique lo contrario (es decir, se overide them). f &lt;- function(a = 2, b = 3) { return(a + b) } f() ## [1] 5 f(4, 5) ## [1] 9 f(b = 4) ## [1] 6 Return No es necesario especificar lo que regresa la función. Las funciones por default regresan el último elemento o valor computado. 3.2.3 Reglas de visibilidad (scoping) Sabemos que existe la función c que nos permite concatenar vectores o elementos a vectores. Sin embargo, es posible asignar un valor a una variable llamada c y que la función c siga funcionando. c &lt;- 1000 c + 1 ## [1] 1001 x &lt;- c(1:4) x ## [1] 1 2 3 4 Esto es debido a que R tienen espacios de nombres (namespaces) separados para funciones y no-funciones. Cuando R intenta concatenar los valores del 1 al 4, busca primero en el ambiente global y, en caso de no encontrarlo, busca en los namespaces de cada uno de los paquetes que tiene cargados. El orden en el que busca se puede encontrar utilizando el comando search(). search() ## [1] &quot;.GlobalEnv&quot; &quot;package:reshape2&quot; &quot;package:stringr&quot; ## [4] &quot;package:tidyr&quot; &quot;package:magrittr&quot; &quot;package:bindrcpp&quot; ## [7] &quot;package:pryr&quot; &quot;package:bigrquery&quot; &quot;package:googlesheets&quot; ## [10] &quot;package:xlsx&quot; &quot;package:readxl&quot; &quot;package:readr&quot; ## [13] &quot;package:haven&quot; &quot;package:foreign&quot; &quot;package:xtable&quot; ## [16] &quot;package:tibble&quot; &quot;package:data.table&quot; &quot;package:carData&quot; ## [19] &quot;package:VIF&quot; &quot;package:plyr&quot; &quot;package:ggplot2&quot; ## [22] &quot;package:dplyr&quot; &quot;package:knitr&quot; &quot;tools:rstudio&quot; ## [25] &quot;package:stats&quot; &quot;package:graphics&quot; &quot;package:grDevices&quot; ## [28] &quot;package:utils&quot; &quot;package:datasets&quot; &quot;package:methods&quot; ## [31] &quot;Autoloads&quot; &quot;package:base&quot; Los paquetes recién llamados acaban en la posición número 2 y todo lo demás se recorre en el orden de la lista. Nota como el base (que se carga por default en toda sesión) está hasta el final. .GlobalEnv es el workspace del que hablamos antes. Si hay un símbolo que corresponde a tu petición entonces tomará el valor en tu workspace para poder ejecutar tu petición. Si no encuentra nada, busca en el namespace de cada uno de los paquetes que has cargado hasta el momento en el orden en el que los llamaste. Esto es muy importante. Hay contribuidores de paquetes en todo el mundo y es muy común que utilicen el mismo nombre para implementaciones de distintas cosas y, por lo tanto, a veces nuestros resultados no son lo que esperábamos. El orden en el que cargamos los paquetes importa: ## &lt;environment: namespace:car&gt; ## &lt;environment: namespace:car&gt; ## &lt;environment: namespace:VIF&gt; La otra opción, sin quitar el paquete del ambiente, es especificar de que paquete tomarlo. En otras palabras, le pedimos explícitamente a R que busque la función en el espacio de nombres de un paquete en específico y que no use su búsqueda normal. environment(VIF::vif) ## &lt;environment: namespace:VIF&gt; environment(car::vif) ## &lt;environment: namespace:car&gt; Bibliografía "],
["estructuras-de-datos.html", "3.3 Estructuras de datos", " 3.3 Estructuras de datos R tiene diferentes tipos y estructuras de datos que permiten al usuario aprovechar el lenguaje. La manipulación de estos objetos es algo que se hace diario y entender cómo operarlos o cómo convertir de una a otra es muy útil. 3.3.1 Clases atómicas (atomic classes) R tiene 6 clases atómicas6 (R Core Team 2016a). character (caracter) numeric (números reales o decimales, a esta clase también se le llama double) integer (números enteros) logical (booleanos, i.e. falso-verdadero) complex (números complejos) raw (contiene bytes) Cuadro 3.1: Clases atómicas Type Tipo Ejemplo character Caracter ‘hola’, ‘x’ numeric Numérico 67, 45.5 integer Integer 2L, 67L logical Lógico TRUE, FALSE, T, F complex Complejo 1+4i raw Crudo 01 - imprime hexadecimales Algunos comandos importantes para las clases atómicas son su tipo typeof(), su tamaño length() y sus atributos attributes(), es decir, sus metadatos. ############ Ejemplo 1 x &lt;- &quot;una cadena&quot; typeof(x) ## [1] &quot;character&quot; length(x) # tamaño: ¿cuántas cadenas son? ## [1] 1 nchar(x) # Número de caracteres ## [1] 10 attributes(x) # Le pusimos metadatos? ## NULL ############ Ejemplo 2 y &lt;- 1:10 typeof(y) ## [1] &quot;integer&quot; length(y) ## [1] 10 attributes(y) ## NULL ############ Ejemplo 3 z &lt;- c(1L, 2L, 3L) # Nota como para denotar enteros se incluye una L al final typeof(z) ## [1] &quot;integer&quot; length(z) ## [1] 3 3.3.2 Vectores Los vectores son la estructura de datos más básica de R (H. Wickham 2014a). Hay dos tipos de vectores: vectores atómicos y listas. Típicamente -en libros, blogs, manuales, cuando se mencionan vectores se refieren a los atómicos y no a las listas. 3.3.2.1 Vectores atómicos Los vectores pueden ser pensados como celdas contiguas que contienen datos (R Core Team 2016a), es decir, elementos de alguna de las clases atómicas (character, logical, integer, numeric). Se puede crear un vector vacío con el comando vector() así como especificar su tamaño y su clase. v &lt;- vector() v ## logical(0) ## Especifico clase y longitud vector(&quot;character&quot;, length = 10) ## [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## Lo mismo pero usando un wrapper character(10) ## [1] &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; &quot;&quot; ## Numerico de tamaño 5 numeric(5) ## [1] 0 0 0 0 0 ## Lógico tamaño 5 logical(5) ## [1] FALSE FALSE FALSE FALSE FALSE 3.3.2.2 Tipos de vectores Realiza los siguientes ejemplos en la consola de R. x &lt;- rep(1, 5) x typeof(x) xi &lt;- c(1L, 3L, 56L, 4L) xi typeof(xi) y &lt;- c(T, F, T, F, F, T) z &lt;- c(&quot;a&quot;, &quot;aba&quot;, &quot;andrea&quot;, &quot;b&quot;, &quot;bueno&quot;) Dijimos que la función typeof permitía preguntarle a un objeto qué tipo de dato es. La función class permite hacer una pregunta similar. La diferencia radica en el punto de vista: el primero da el tipo del objeto como un objeto en R mientras que, el segundo identifica el tipo del objeto desde el punto de vista de la programación orientada a objetos en R. class(z) ## [1] &quot;integer&quot; Otra función útil es str pues permite desplegar en forma compacta la estructura interna de un objeto en R: str(z) ## int [1:3] 1 2 3 3.3.2.3 Operaciones con vectores Aritmética: por default, se realizan componente a componente. a &lt;- c(1:5) b &lt;- a + 10 b ## [1] 11 12 13 14 15 c &lt;- sqrt(b) # square root = raíz c ## [1] 3.316625 3.464102 3.605551 3.741657 3.872983 a + c ## [1] 4.316625 5.464102 6.605551 7.741657 8.872983 10 * (a + c) ## [1] 43.16625 54.64102 66.05551 77.41657 88.72983 a^2 ## [1] 1 4 9 16 25 a * c ## [1] 3.316625 6.928203 10.816654 14.966630 19.364917 Agregar elementos aun vector ya creado a &lt;- c(a, 7) a ## [1] 1 2 3 4 5 7 Para construir datos rápido, podemos usar comandos como rep, seq o distintas distribuciones, e.g., la normal rnorm, uniformes runif o cualquiera en esta lista. Prueba lo siguiente: # Dame un vector donde el minimo sea 0, maximo 1 en intervalos de 0.25 seq(0, 1, 0.25) # Vector con 10 unos rep(1, 10) # 5 realizaciones de una normal(0,1) rnorm(5) # De una normal(10, 5) rnorm(5, mean = 10, sd = sqrt(5)) # De una uniforme(0,1) runif(5) # De una uniforme(5, 15) runif(5, min = 5, max = 15) 3.3.2.4 Atributos de un vector Cada objeto tiene atributos. Hay atributos específicos para vectores que, sin importar su clase, tienen en común. Ya revisamos algunos: tamaño (length), clase (class). También son importantes atributos como los nombres calificaciones &lt;- c(6, 5, 8, 9, 10) names(calificaciones) &lt;- c(&quot;Maria&quot;, &quot;Jorge&quot;, &quot;Miguel&quot;, &quot;Raúl&quot;, &quot;Carla&quot;) attributes(calificaciones) ## $names ## [1] &quot;Maria&quot; &quot;Jorge&quot; &quot;Miguel&quot; &quot;Raúl&quot; &quot;Carla&quot; # O llamamos directo a los nombres names(calificaciones) ## [1] &quot;Maria&quot; &quot;Jorge&quot; &quot;Miguel&quot; &quot;Raúl&quot; &quot;Carla&quot; 3.3.2.5 Coerción Los vectores solo permiten tener objetos del mismo tipo. Hay coercioń explícita (explicit coercion, también llamada cast) utilizando as.&lt;nombre_clase&gt;. as.numeric() as.character() as.integer() as.logical() Utilizando coerción explícita garantizamos siempre tener el resultado en cuanto a la clase del objeto. c(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), as.character(c(1, 2, 3))) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; Realizar coerción explícita implica trabajar extra y, a veces, no se puede realizar de manera directa: los datos pueden venir sucios con varios tipos de datos mezclados en una misma variable. R mezcla distintos tipos de datos y realiza una coerción implícita utilizando reglas razonables. En otras palabras, R realiza una coerción explícita por default entre los objetos y “decide” cuál es la clase del vector. # Número + caracter = caracter c(1.7, &quot;a&quot;) ## [1] &quot;1.7&quot; &quot;a&quot; # Lógico + número = número c(TRUE, 2) ## [1] 1 2 # Número + caracter = caracter c(&quot;a&quot;, TRUE) ## [1] &quot;a&quot; &quot;TRUE&quot; En ese proceso, puede haber pérdidas de información, por ejemplo, al mezclar valores lógicos con numéricos, Se confunden valores verdaderos con un uno. Hay que tener cuidado particularmente cuando se limpian los datos: c(c(T, T, T), c(1, 2, 3)) ## [1] 1 1 1 1 2 3 Hay conversiones que no tienen sentido y generan pérdida de información total: x &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) as.numeric(x) ## [1] NA NA NA as.logical(x) ## [1] NA NA NA Normalmente, se obtiene un mensaje de advertencia (warning) cuando alguna coerción puede derivar en pérdida de información (H. Wickham 2014a). La última consideración importante es que para R un objeto no es igual, aunque no se pierda información, si su tipo no es el mismo x &lt;- 0:5 identical(x, as.numeric(x)) ## [1] FALSE En este ejemplo, cuando declaramos \\(x\\) no especificamos su clase y R decidió que era entero. Al coercionar al objeto para que fuese numérico, R no considera a los dos objetos iguales. En general, la coersión de R es muy útil pues permite incluso comparar objetos de distintas clases si el resultado tiene sentido 1 &lt; &quot;2&quot; ## [1] TRUE Lo importante es recordar que es importante revisar las advertencias que R arroja a la consola y verificar que el resultado obtenido es el deseado o que la pérdida de información no se puede evitar. 3.3.2.6 Extraer partes del vector R tiene constructos que permite acceder a elementos individuales o subconjuntos de un vector a través de operaciones de indexación (indexing) (R Core Team 2016a, sección “Indexing”). Para los vectores, es posible acceder al i-ésimo elemento usando x[i]. x &lt;- c(10, 20, 30, 40, 50) names(x) &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;) # Accedemos al 4to elemento x[4] ## d ## 40 Además de la indexación con un entero, se puede # x[i] - caso anterior # x[[i]] x[[4]] ## [1] 40 # x[&quot;a&quot;] - por nombre (cuando existen) x[&quot;a&quot;] ## a ## 10 # Se puede extraer un subconjunto x[1:3] ## a b c ## 10 20 30 [] vs. [[]] Estas dos formas de acceder a los elementos de un vector (utilizados también en otras estructuras de datos) suelen causar confusión. En vectores, [[ casi no se utiliza, aunque son ligeramente diferentes. Como vimos en el ejemplo, [[ quita los nombres o atributos y permite extraer únicamente un elemento a la vez. 3.3.3 Matrices Las matrices son un tipo especial de vectores. Son un vector atómico con una dimensión adicional pues tienen filas y columnas. m &lt;- matrix(c(1, 2, 3, 4), nrow = 2, ncol = 2) m ## [,1] [,2] ## [1,] 1 3 ## [2,] 2 4 En términos de sus atributos por default, la diferencia entre los vectores y las matrices es: x &lt;- c(1, 2, 3, 4) attributes(x) ## NULL attributes(m) ## $dim ## [1] 2 2 Como puedes notar, las matrices se forman por default usando los elementos del vector para llenar columna por columna de izquierda a derecha. Podemos simplemente “agregarle” una dimensión a un vector para construir una matriz. m &lt;- 1:10 m ## [1] 1 2 3 4 5 6 7 8 9 10 dim(m) &lt;- c(2, 5) m ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 3 5 7 9 ## [2,] 2 4 6 8 10 También podemos pegar o concatenar vectores de la misma longitud como si fueran columnas de una matriz usando cbind o como si fueran filas rbind (r = row, c = column). x &lt;- runif(4) y &lt;- rnorm(4) cbind(x, y) ## x y ## [1,] 0.96287589 -0.3065290 ## [2,] 0.01111454 0.6312563 ## [3,] 0.82282778 -0.8850892 ## [4,] 0.42547561 0.3376346 rbind(x, y) ## [,1] [,2] [,3] [,4] ## x 0.9628759 0.01111454 0.8228278 0.4254756 ## y -0.3065290 0.63125627 -0.8850892 0.3376346 Le agregamos atributos para accesar más fácilmente a los objetos. m &lt;- matrix(c(x, y), nrow = 4, ncol = 2, byrow = T, dimnames = list(paste0(&quot;row&quot;, 1:4), paste0(&quot;col&quot;, 1:2))) m ## col1 col2 ## row1 0.9628759 0.01111454 ## row2 0.8228278 0.42547561 ## row3 -0.3065290 0.63125627 ## row4 -0.8850892 0.33763458 dimnames(m) ## [[1]] ## [1] &quot;row1&quot; &quot;row2&quot; &quot;row3&quot; &quot;row4&quot; ## ## [[2]] ## [1] &quot;col1&quot; &quot;col2&quot; Acceder a elementos de una matriz puede hacerse de muchas formas # m[i] - quinto elemento, contando desde entrada 1,1 por columnas m[5] ## [1] 0.01111454 # m[[i]] - quinto elemento, quitando atributos m[[5]] ## [1] 0.01111454 # m[i, j] - mismo elemento que m[5] pero usando notacion fila, columna m[1, 2] ## [1] 0.01111454 # m[[i, j]] - mismo elemento, quitando atributos m[[1, 2]] ## [1] 0.01111454 # Puedo llamar por su nombre m[&quot;row1&quot;, &quot;col2&quot;] ## [1] 0.01111454 # Misma forma, quitando atributos m[[&quot;row1&quot;, &quot;col2&quot;]] ## [1] 0.01111454 # m[i, ] - toda la fila i-ésima m[1, ] ## col1 col2 ## 0.96287589 0.01111454 # m[, j] - toda la columna j-ésima m[, 2] ## row1 row2 row3 row4 ## 0.01111454 0.42547561 0.63125627 0.33763458 # Índices o nombres son equivalentes m[1, 1] == m[&quot;row1&quot;, &quot;col1&quot;] ## [1] TRUE [] vs. [[]] En matrices, [[ casi no se utiliza. Como vimos en el ejemplo, [[ quita los nombres o atributos y permite extraer únicamente un elemento a la vez. 3.3.4 Listas Tiene características muy similares a un vector pero permite que cada elemento sea de un tipo distinto. Mas aún, es posible incluir una lista como un elemento de otra lista y por eso también se les conoce como vectores recursivos (recursive vectors) (H. Wickham 2014a, sección “lists”). Para crear una lista vacía utilizas list() y para coercionar un objeto a una lista usa as.list(). x &lt;- list(3L, 3.56, 1 + 4i, TRUE, &quot;hola&quot;, list(&quot;genial&quot;, 1)) length(x) ## [1] 6 class(x) ## [1] &quot;list&quot; class(x[1]) ## [1] &quot;list&quot; class(x[[1]]) ## [1] &quot;integer&quot; y &lt;- as.list(1:10) length(y) ## [1] 10 Nota como muchas propiedades que tenían los vectores atómicos los tienen también las listas. Las listas también pueden tener nombres # Lista vacia lista &lt;- list() # Concatenamos un vector lista[[&quot;numeros&quot;]] &lt;- c(1, 34, 45.5, 34) # Concatenamos un objeto de datos lista[[&quot;datos&quot;]] &lt;- head(iris) # Concatenamos un número lista &lt;- c(lista, 3) # ¡No le tuvimos que poner nombre! lista ## $numeros ## [1] 1.0 34.0 45.5 34.0 ## ## $datos ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## ## [[3]] ## [1] 3 R tiene muchos datos de ejemplo que son utilizados en muchos paquetes, blogs y libros. Utiliza help(iris) para saber más del dataset usado arriba. Por su propiedad recursiva, se navega diferente. Repasamos las principales maneras de extraer los elementos de la lista utilizando la lista \\(x\\) declarada anteriormente: # Recordamos a x x ## [[1]] ## [1] 3 ## ## [[2]] ## [1] 3.56 ## ## [[3]] ## [1] 1+4i ## ## [[4]] ## [1] TRUE ## ## [[5]] ## [1] &quot;hola&quot; ## ## [[6]] ## [[6]][[1]] ## [1] &quot;genial&quot; ## ## [[6]][[2]] ## [1] 1 # x[i] - el i-ésimo elemento de la lista x[3] ## [[1]] ## [1] 1+4i ## Nota como la clase del objeto sigue siendo lista class(x[3]) ## [1] &quot;list&quot; # x[[i]] - el i-ésimo elemento de la lista x[[3]] ## [1] 1+4i ## La clase ahora es la del objeto dentro del &quot;espacio&quot; 3 en la lista original class(x[[3]]) ## [1] &quot;complex&quot; # Nombramos la lista names(x) &lt;- c(&quot;entero&quot;, &quot;numerico&quot;, &quot;complejo&quot; , &quot;booleano&quot;, &quot;caracter&quot;, &quot;lista&quot;) # Ganamos formas de accesar los objetos # x$a - llamamos al elemento con nombre &quot;a&quot; x$entero ## [1] 3 class(x$entero) # Es equivalente a [[]] ## [1] &quot;integer&quot; # x$&quot;a&quot; x$&quot;complejo&quot; ## [1] 1+4i # x[[&quot;lista&quot;]][i] - i-ésimo elemento de la lista dentro de la lista x[[&quot;lista&quot;]][1] ## [[1]] ## [1] &quot;genial&quot; # x[[j]][i] - Mismas reglas en la lista anidada x[[6]][1] ## [[1]] ## [1] &quot;genial&quot; # x[[j]][[i]] - i-ésimo elemento en la lista del j-ésimo elemento de x x[[6]][[1]] ## [1] &quot;genial&quot; [] vs. [[]] En listas, [[ es fundamental para accesar correctamente los objetos y poder navegar la lista. Como en vectores y matrices, [[ quita los nombres o atributos y permite extraer únicamente un elemento a la vez. En listas, además, devuelve el objeto dentro del i-ésimo elemento. Por el contrario, [ devuelve una lista. Puedo poner listas dentro de listas, dentro de listas… Se navega en orden como en el ejemplo. Las longitudes de los objetos en la lista se pueden pensar por niveles, por su propiedad recursiva. # El tamaño es del &quot;primer nivel&quot;. length(x) ## [1] 6 # Hay 6 elementos en x, todos de diferentes tipos names(x) ## [1] &quot;entero&quot; &quot;numerico&quot; &quot;complejo&quot; &quot;booleano&quot; &quot;caracter&quot; &quot;lista&quot; # Para obtener la longitud dentro del i-ésimo elemento de la lista, debo length(x[[6]]) # La lista anidada tiene 2 elementos ## [1] 2 # que no es lo mismo que length(x[6]) # Donde hay un solo elemento: una lista ## [1] 1 3.3.5 Factores (factor) Los factores son otro tipo de vectores pero que ayuda a representar datos del tipo categórico u ordinal, es decir, cuando los posibles valores de la variable tipo caracter es limitado. Por ejemplo, son útiles cuando tenemos una variable como “sexo” donde, al menos por ahora, legalmente solo puede tomar los valores hombre o mujer. Si, en cambio, se tiene un vector de nombres es conveniente dejarlo como caracter. Un factor se guarda como un enteros pero con etiquetas encima tal que cada entero corresponde a una etiqueta (label). y &lt;- c(&quot;no&quot;, &quot;si&quot;, &quot;si&quot;, &quot;no&quot;) class(y) ## [1] &quot;character&quot; # Debemos pedirle explícitamente que lo guarde como factor x &lt;- factor(c(&quot;no&quot;, &quot;si&quot;, &quot;si&quot;, &quot;no&quot;)) x ## [1] no si si no ## Levels: no si Al imprimir el objeto, se observa como los niveles fueron asignados. Éstos corresponden al número de valores únicos en el vector de caracter y se asignan en orden alfabético los valores. Los factores se despliegan como si fueran vectores tipo caracter y algunas operaciones son análogas: table(x) ## x ## no si ## 2 2 La ganancia es que son más rápidas. Aunque a veces los factores se comportan como vectores tipo caracter pero debemos recordar que por debajo son enteros y tenemos que ser cuidadosos si los tratamos como caracteres. Supongamos por ejemplo que tenemos un factor con valores 5, 6 o 7. Lo tenemos guardado como factor. ej &lt;- factor(c(&quot;7&quot;, &quot;6&quot;, &quot;5&quot;, &quot;7&quot;, &quot;5&quot;, &quot;7&quot;, &quot;6&quot;, &quot;5&quot;, &quot;5&quot;, &quot;6&quot;,&quot;5&quot;)) ej ## [1] 7 6 5 7 5 7 6 5 5 6 5 ## Levels: 5 6 7 Dado que los valores son números, conceptualmente tiene sentido operarlos como tal: as.integer(ej) ## [1] 3 2 1 3 1 3 2 1 1 2 1 Obtuvimos los enteros a los que las etiquetas originales habían sido asignados. Para recuperar los valores originales, debemos hacer as.integer(as.character(ej)) ## [1] 7 6 5 7 5 7 6 5 5 6 5 Algunos métodos que están hechos para caracteres coercionan un factor a caracter mientras que otros arrojan un error. Si usas métodos de caracteres, lo mejor es “castear” (coerción explícita) a caracter tu factor utilizando as.character(mifactor). De esta manera se pierden algunas cosas pero te aseguras que las cosas funcionen como deben. summary(x) ## no si ## 2 2 summary(as.character(x)) ## Length Class Mode ## 4 character character Summary R funciona mejor gracias a sus convenciones, es decir, porque los contribuyentes se ponen de acuerdo en seguir ciertas reglas de manera que sea más fácil utilizar los paquetes de otros (con sus objetos y funciones). La función summary es la función genérica que produce resumenes para objetos de muchas clases. La función invoca métodos que dependen de la clase del argumento enviado (en estos ejemplos, el resumen para un factor y para un caracter respectivamente). Los factores pueden incluir únicamente los niveles con los que fueron definidos. Por esa razón, la unión de dos factores ddeclarados en forma independiente puede dar resultados no deseados. y &lt;- factor(c(&quot;si&quot;, &quot;no&quot;, &quot;tal vez&quot;)) c(x, y) ## [1] 1 2 2 1 2 1 3 class(c(x, y)) ## [1] &quot;integer&quot; No es posible entonces recuperar el valor de las etiquetas. R hizo las operaciones posibles pero hubo pérdida de información. Para concatenar dos factores correctamente, es necesario: factor(c(as.character(x), as.character(y))) ## [1] no si si no si no tal vez ## Levels: no si tal vez En general, se recomienda incluir el valor de u nnivel posible, independientemente de si se tiene o no esa respuesta. Sin embargo, el problema al concatenar persiste. x &lt;- factor(c(&quot;no&quot;, &quot;si&quot;, &quot;si&quot;, &quot;no&quot;), levels = c(&quot;no&quot;, &quot;si&quot;, &quot;tal vez&quot;)) c(x, &quot;tal vez&quot;) ## [1] &quot;1&quot; &quot;2&quot; &quot;2&quot; &quot;1&quot; &quot;tal vez&quot; Para datos ordinales como las respuestas en una pregunta de encuesta con escala likert7 los factores son también objetos útiles. Veamos un ejemplo en donde tenemos 500 respuestas a la pregunta “este tutorial es muy útil”: set.seed(2887) respuestas &lt;- sample(x = c(1:5), size = 500, replace = T , prob = c(0.1, 0.15, 0.2, 0.4, 0.15)) y &lt;- factor( x = respuestas, levels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;), labels = c(&quot;totalmente en desacuerdo&quot;, &quot;en desacuerdo&quot; , &quot;ni de acuerdo ni en desacuerdo&quot; , &quot;de acuerdo&quot;, &quot;totalmente de acuerdo&quot;), ordered = T) table(y) ## y ## totalmente en desacuerdo en desacuerdo ## 51 74 ## ni de acuerdo ni en desacuerdo de acuerdo ## 108 194 ## totalmente de acuerdo ## 73 Nota como la tabla está ordenada de izquierda a derecha con la respuesta más en desacuerdo a la más de acuerdo pues introducimos la opción ordered = T en la definición del factor debido a que las respuestas están en una escala ordinal. Otras funciones útiles En el ejemplo anterior, introducimos las funciones: set.seed: sirve para fijar la semilla con la que se generan números aleatorios. Esto es importante pues al fijarla se puede reproducir exactamente el mismo vector de respuestas cuantas veces sea necesario. sample: permite extraer muestras de un vector x especificando el tamaño de la muestra, si es muestreo con reemplazo y permite establecer pesos para el muestreo. table(y) ## y ## totalmente en desacuerdo en desacuerdo ## 51 74 ## ni de acuerdo ni en desacuerdo de acuerdo ## 108 194 ## totalmente de acuerdo ## 73 Por último, al utilizar factores (y más aún, declarar un orden cuando es conceptualmente pertinente) es más fácil visualizar correctamente los datos con menor desgaste. Si graficamos las respuestas como caracter recibimos: library(ggplot2) df &lt;- data.frame(como.caracter = as.character(y), como.factor = y) ggplot(df, aes(x = como.caracter)) + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Si utilizamos el factor ordenado obtenemos: ggplot(df, aes(x = como.factor)) + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) Nota En R muchas cosas son más fáciles si se utliza la estructura de datos apropiada y se establecen correctamente todos los metadatos necesarios al objeto para que los defaults de R faciliten el trabajo. Al utilizar factores cuando es pertinente se gana, al menos, lo siguiente: Se almacenan los datos usando menos memoria. Esto es importante pues R trabaja en ram. El rendimiento es mejor que usando caracteres. Por default R utiliza los métodos apropiados para el tipo de variable. Por ejemplo, si se introduce un factor como variable dependiente en un modelo de regresión, automáticamente aplica un logit y no un ols. Se pueden especificar elementos, como el orden de los niveles, que son útiles para el análisis y presentación de resultados. A pesar de sus ventajas, si son incorrectamente utilizados las estructuras de datos pueden resultar en pérdidas de información o comportamientos indeseados. 3.3.6 Data frames Los dataframes son una de las estructuras de datos más importantes para guardar datos en R (H. Wickham 2014a, sección “Data frames”). En python, existe una estructura similar en la librería pandas creado para facilitar el análisis de datos en este lenguaje sin la necesidad de cambiar a un lenguaje de dominio específico como R (McKinney 2010, sección “What problem does pandas solve?”). Este objeto es tan importante porque muchos de los modelos estadísticos que se utliizan necesitan una estructura de datos tabular. Los dataframes tienen atributos adicionales a los que tienen los vectores: rownames() colnames() names() head() te enseña las primeras 6 lineas. tail() te enseña las últimas 6 líneas. nrow() te da el número de filas ncol() te da el número de columnas str() te dice el tipo de cada columna y te muestra ejemplos Podemos ver a los dataframes como un tipo de lista con algunas restricciones (R Core Team 2016a, sección “Data frames”): Los componentes deben ser vectores, factores, matrices numéricas, listas u otros dataframes. Las matrices, listaa y otros data frames proveen de tantas columnas, elementos o variables como las originales, respectivamente. Los vectores numéricos, lógicos y factores se incluyen en el dataframe sin transformaciones adicionales. Los vectores tipo caracter se coercionan a factores. Todos los elementos (las columnas) deben tener la misma longitud o tamaño. Los dataframes se pueden crear utilizando comandos como read.table() (que tiene como caso particular read.csv(). Se verá con detalle el uso de estas funciones en la sección 5.1. Para convertir un dataframe a una matriz se utiliza data.matrix(). La coerción es forzada y no necesariamente da lo que uno espera. Se pueden crear data.frames con la función data.frame(). df &lt;- data.frame( x = rnorm(10), y = runif(10), n = LETTERS[1:10], stringsAsFactors = F # F = FALSE, T = TRUE ) head(df) ## x y n ## 1 0.89814648 0.52584158 A ## 2 -0.37532709 0.68789829 B ## 3 -2.17112789 0.60079780 C ## 4 -0.63011959 0.86922537 D ## 5 0.03778982 0.44119997 E ## 6 0.35565256 0.02638035 F dim(df) ## [1] 10 3 str(df) ## &#39;data.frame&#39;: 10 obs. of 3 variables: ## $ x: num 0.8981 -0.3753 -2.1711 -0.6301 0.0378 ... ## $ y: num 0.526 0.688 0.601 0.869 0.441 ... ## $ n: chr &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ... ¿Por qué usar la opción stringsAsFactors = F? Por default las columnas tipo caracter en un dataframe son convertidas a factor. Esto es útil cuando se tienen los datos limpios y se va a proceder a modelas sin realizar mayores transformaciones o limpiezas a los datos. Sin embargo, cuando se realizarán manipulaciones a los mismos, es recomendable cambiar la opción por default para leer columnas como caracter, de esta forma se evitan los problemas mencionados en la sección de factores. Es posible concatenar columnas o filas: df &lt;- cbind(df, data.frame(z = rexp(10))) df &lt;- rbind(df, c(rnorm(1), runif(1), &quot;K&quot;, rexp(1))) dim(df) ## [1] 11 4 Repasamos las principales maneras de extraer los elementos de un dataframe utilizando el objeto \\(df\\): df &lt;- data.frame( x = rnorm(4), y = runif(4), n = LETTERS[1:4], stringsAsFactors = F # F = FALSE, T = TRUE ) # df[i] df[1] # La primera columna ## x ## 1 0.38112864 ## 2 0.51810269 ## 3 -0.84698783 ## 4 0.03558633 class(df[1]) # Regresa un dataframe ## [1] &quot;data.frame&quot; # df[[i]] df[[1]] # La primera columna ## [1] 0.38112864 0.51810269 -0.84698783 0.03558633 class(df[[1]]) # Regresa un vector ## [1] &quot;numeric&quot; # df[i, j] df[1,2] # elemento en la primera fila, segunda columna ## [1] 0.5346584 # df[[i, j]] df[[1, 2]] # mismo resultado ## [1] 0.5346584 # df$columna df$x # La columna llamada x ## [1] 0.38112864 0.51810269 -0.84698783 0.03558633 # df$&quot;columna&quot; df$&quot;x&quot; ## [1] 0.38112864 0.51810269 -0.84698783 0.03558633 df[[&quot;n&quot;]][1] # Podemos navegar igual que en una lista ## [1] &quot;A&quot; [] vs. [[]] Debido a que los dataframes son un caso particular de las listas, [[ es también fundamental para accesar correctamente los objetos. [[ quita los nombres o atributos, permite extraer únicamente un elemento a la vez y devuelve el objeto dentro del i-ésimo elemento. [ devuelve un data frame con la columna(s) que sea nombradas o los índices que sean utilizados. Cuando se declara un dataframe automáticamente se verifican que los nombres sean sintácticamente válidos con la función make.names data.frame(&quot;2000&quot; = c(100:104) , &quot;una-variable&quot; = c(200:204) , &quot;.2000&quot; = c(300:304) ) ## X2000 una.variable X.2000 ## 1 100 200 300 ## 2 101 201 301 ## 3 102 202 302 ## 4 103 203 303 ## 5 104 204 304 Nombres sintácticamente válidos Los dataframes pueden tener únicamente nombres sintácticamente válidos (Hornik 2016, sección “What are valid names?”): Está compuesto por letras, números, puntos o guiones bajos. No deben empezar con números. Tampoco pueden empezar con un punto seguido de un número. No se permiten palabras reservadas (if, else, repeat, next, TRUE, FALSE, entre otras). Bibliografía "],
["estructuras-de-datos-fuera-de-r-basico.html", "3.4 Estructuras de datos fuera de R-básico", " 3.4 Estructuras de datos fuera de R-básico Fuera del R Core Team (2016b), se han desarrollado otras estructuras de datos particularmente útiles para hacer análisis de datos. Hay paquetes compatibles con este tipo de estructuras que facilitan el trabajo. A continuación presentaremos data.tables y tibbles que sustituyen el data.frame. Ambos se coercionan a dataframe de manera automática cuando se llama a una función que contiene únicamente métodos para dataframe. 3.4.1 Data tables data.table provee una versión de alto rendimiento para los dataframes del R Core Team (2016b). Está implementado en el paquete del mismo nombre (Dowle et al. 2015). Un data.table se crea en forma análoga a un data.frame. En la sección anterior, creamos un objeto llamado \\(df\\) df &lt;- data.frame( x = rnorm(4), y = runif(4), n = LETTERS[1:4], stringsAsFactors = F ) Usamos la función data.table(): library(data.table) dt &lt;- data.table( x = rnorm(4), y = runif(4), n = LETTERS[1:4] ) str(dt) ## Classes &#39;data.table&#39; and &#39;data.frame&#39;: 4 obs. of 3 variables: ## $ x: num 1.777 1.024 0.952 -0.492 ## $ y: num 0.0295 0.9999 0.4618 0.6732 ## $ n: chr &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; ## - attr(*, &quot;.internal.selfref&quot;)=&lt;externalptr&gt; class(dt) ## [1] &quot;data.table&quot; &quot;data.frame&quot; Por default los vectores tipo caracter son leidos as-is, es decir, sin coercionar a factor. El objeto con clase data.table retiene todos los atributos del data.frame. Podemos usar las funciones: head, names, Para crear data.tables se puede coercionar cualquier data.frame con as.data.table(diamonds) ## carat cut color clarity depth table price x y z ## 1: 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2: 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3: 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4: 0.29 Premium I VS2 62.4 58 334 4.20 4.23 2.63 ## 5: 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## --- ## 53936: 0.72 Ideal D SI1 60.8 57 2757 5.75 5.76 3.50 ## 53937: 0.72 Good D SI1 63.1 55 2757 5.69 5.75 3.61 ## 53938: 0.70 Very Good D SI1 62.8 60 2757 5.66 5.68 3.56 ## 53939: 0.86 Premium H SI2 61.0 58 2757 6.15 6.12 3.74 ## 53940: 0.75 Ideal D SI2 62.2 55 2757 5.83 5.87 3.64 Nota como los datatables tienen por default una impresión diferente que un dataframe pues imprimen los primeros y los últimos 6 renglones. Los data.tables incorporan nuevas maneras de extraer objetos, agruparlos y juntarlos con otras tablas. Para más detalles, se pueden revisar las viñetas del paquete: Item Title datatable-benchmarking Benchmarking data.table (source, html) datatable-reshape Efficient reshaping using data.tables (source, html) datatable-faq Frequently asked questions (source, html) datatable-importing Importing data.table (source, html) datatable-intro Introduction to data.table (source, html) datatable-keys-fast-subset Keys and fast binary search based subset (source, html) datatable-reference-semantics Reference semantics (source, html) datatable-secondary-indices-and-auto-indexing Secondary indices and auto indexing (source, html) Para ver una viñeta en específico se puede usar vignette(&quot;datatable-faq&quot;, package = &quot;data.table&quot;). Viñetas Todos los paquetes tienen viñetas en donde se documentan en forma más detallada sus funciones, clases y métodos. 3.4.2 Tibbles Los tibbles son escencialmente dataframes pero con algunas modificaciones a los defaults para facilitar el trabajo (Wickham and Grolemund 2016, ver sección “tibbles”). Un tibble se crea en forma análoga a un data.frame. En la sección , creamos un objeto llamado \\(df\\) df &lt;- data.frame( x = rnorm(4), y = runif(4), n = LETTERS[1:4], ) Usamos la función tibble() del paquete Wickham, Francois, and Müller (2016): library(tibble) tb &lt;- tibble( x = rnorm(4), y = runif(4), n = LETTERS[1:4] ) str(tb) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4 obs. of 3 variables: ## $ x: num 0.208 1.155 0.731 -0.214 ## $ y: num 0.146 0.895 0.418 0.809 ## $ n: chr &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; class(tb) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Para crear tibbles se puede coercionar cualquier data.frame con as_tibble(diamonds) ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ... with 53,930 more rows Los tibbles, como los datatables tienen una impresión diferente que un dataframe. En este caso, se imprime la dimensión y los primeros 10 renglones. Al crear un tibble nunca hay conversión de tipos (no se convierte de caracter a factor), no se cambian los nombres de las variables y no se crean nombres para las filas. Se permite también tener nombres de variables que no son sintácticamente válidos, para utilizar estos nombres, se declaran con acento invertido ``` tibble( `2000` = c(100:104) , `una-variable` = c(200:204) , `año` = c(300:304) ) ## # A tibble: 5 x 3 ## `2000` `una-variable` año ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 100 200 300 ## 2 101 201 301 ## 3 102 202 302 ## 4 103 203 303 ## 5 104 204 304 Para utilizar nombres no sintácticamente válidos es necesario conjugarlos con el acento invertido al nombrarlos en otros paquetes como dplyr, ggplot2, entre otros que son compatibles con el objeto tibble. La otra diferencia importante entre los tibbles y los data.frames es que pueden incorporar elementos de listas en una columna en forma sencilla (H. Wickham 2016c). try(df &lt;- data.frame(x = list(1:2, 3:5))) df&lt;- data.frame(x = I(list(1:2, 3:5))) df ## x ## 1 1, 2 ## 2 3, 4, 5 tb &lt;- tibble(x = list(1:2, 3:5)) tb ## # A tibble: 2 x 1 ## x ## &lt;list&gt; ## 1 &lt;int [2]&gt; ## 2 &lt;int [3]&gt; Bibliografía "],
["objetos-importantes.html", "3.5 Objetos importantes", " 3.5 Objetos importantes 3.5.1 Infinito Inf es como R denomina al infinito. En el mundo de R se permite también positivo o negativo. 1/0 ## [1] Inf 1/Inf ## [1] 0 3.5.2 No es un número NaN es como R denota a algo que no es un número (literal: not a number). 0/0 ## [1] NaN 3.5.3 Valores perdidos (missing values) En la sección 3.5 se habló de otros objetos en R. De particular importancia es NA para valores perdidos en general y NaN para operaciones matemáticas no definidas. Lógicamente, podemos preguntar a R si un objeto es de este tipo is.na() is.nan() Los valores NA tienen una clase particular. Puede haber valores perdidos enteros NA_integer_ o caracteres NA_character_. NaN es un NA pero no al revés. x &lt;- c(1, 4, 6, NA, NaN, 45) is.nan(x) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE is.na(x) ## [1] FALSE FALSE FALSE TRUE TRUE FALSE Cuando tenemos un dataframe que tiene valores perdidos y lo queremos incorporar, por ejemplo, a un modelo de regresión, lo primero que hará el método es excluir todos los renglones que tengan algún valor perdido usando na.exclude(datos). Normalmente, este no es el tratamiento deseado para valores perdidos pero es el comportamiento por default. "],
["estructuras-de-control.html", "3.6 Estructuras de control", " 3.6 Estructuras de control Las estructuras de control permiten controlar la ejecución. Pueden ser utilizadas en un script o dentro de funciones. Entre las más comunes se encuentran: if, else for while repeat break next return 3.6.1 If if ( condicion ) { # Cuando se cumple la condicion, ejecuta esto } else { # Para todo lo que no se cumple la condicion, ejecuta esto } Ejemplo, x &lt;- 1:20 if ( sample(x, 1) &lt;= 10 ) { print(&quot;x es menor o igual que 10&quot;) } else { print(&quot;x es mayor que 10&quot;) } ## [1] &quot;x es menor o igual que 10&quot; O lo que es lo mismo: ifelse(sample(x, 1) &lt;= 10, &quot;x es menor o igual que 10&quot;, &quot;x es mayor que 10&quot;) ## [1] &quot;x es menor o igual que 10&quot; También es posible asignar variables dentro de una condición. if ( sample(x, 1) &lt;= 10 ){ y &lt;- 0 } else { y &lt;- 1 } # o y &lt;- if ( sample(x, 1) &lt;= 10 ){ 0 } else { 1 } 3.6.2 For Un ciclo for itera una variable y va realizando, para cada iteración, la secuencia de comandos que se especifica dentro del mismo. for (i in 1:3 ){ print(paste0(&quot;i vale: &quot;, i)) } ## [1] &quot;i vale: 1&quot; ## [1] &quot;i vale: 2&quot; ## [1] &quot;i vale: 3&quot; Es posible también iterar directamente sobre vectores o partes de vectores. x &lt;- c(&quot;Andrea&quot;, &quot;Liz&quot;, &quot;Edwin&quot;, &quot;Miguel&quot;) for ( i in seq(x) ) { print(x[i]) } ## [1] &quot;Andrea&quot; ## [1] &quot;Liz&quot; ## [1] &quot;Edwin&quot; ## [1] &quot;Miguel&quot; for ( e in x ) { print(e) } ## [1] &quot;Andrea&quot; ## [1] &quot;Liz&quot; ## [1] &quot;Edwin&quot; ## [1] &quot;Miguel&quot; for ( i in seq(x) ){ print(x[i]) } for ( i in 1:length(x) ) print(x[i]) Podemos incluir fors dentro de fors. m &lt;- matrix(1:10, 2) for( i in seq(nrow(m)) ) { for ( j in seq(ncol(m)) ) { print(m[i, j]) } } 3.6.3 Whiles Otra manera de iterar sobre comandos es con la estructura while. A diferencia del for, esta te permite iterar sobre la secuencia de comandos especificada hasta que se cumpla cierta condición lógica. Esta última tiene que variar a lo largo de las iteraciones o es posible generar ciclos infinitos. Esta estructrura da mucha flexibilidad. x &lt;- runif(1) while ( x &lt; 0.20 | i &lt;= 10 ) { print(x) x &lt;- runif(1) i &lt;- i + 1 } Importante Asegurate de especificar una manera de salir de un ciclo while. 3.6.4 Repeat - Break x &lt;- 1 repeat { # Haz algo print(x) x = x+1 # Hasta que se cumpla lo siguiente if (x == 6){ break } } 3.6.5 Next for (i in 1:20) { if (i %% 2 == 0){ next } else { print(i) } } Este ciclo itera sobre los valores del 1 al 20 e imprime los valores impares. Importante R no es muy eficiente cuando se combina con estructuras de control tipo for o while. Sin embargo, estas estructuras son muy comunes y es útil conocerlas. Normalmente, se recomienda utilizar estructuras vectorizadas (como ifelse) pues, de esta manera, R es mucho más eficiente. "],
["material-adicional-1.html", "3.7 Material adicional", " 3.7 Material adicional Curso de swirl R Programming, módulos 4 a 9. Curso Introduction to R de Data Camp. Curso TryR de Code School. "],
["vectorizacion-la-familia-apply-y-otros.html", "Capítulo 4 Vectorización, la familia apply y otros", " Capítulo 4 Vectorización, la familia apply y otros En este capítulo se profundiza en la forma en la que es posible operar los distintos objetos examinados en el capítulo anterior. En particular, se revisa con detalle las diferentes maneras con las que se pueden extraer subconjuntos de las estructuras de datos. Para vectores, se detallan los seis tipos de extracciones y, posteriormente, se describe cómo esos seis métodos aplican en matrices y dataframes. Se describe la asignación de valores a los subconjuntos extraídos, así como los operadores lógicos disponibles en R y sus particularidades. Se introducen también distintas aplicaciones del material revisados de forma que sea posible realizar operaciones que típicamente se hacen en Excel, como buscarv o buscarh. Se revisa cómo expandir una base con pesos, cómo seleccionar muestras aleatorias y cómo generar datos a partir de realizaciones de distribuciones específicas implementadas en R. Por último, se revisa la estrategia separa, aplica y combina (SAC), así como su implementación en R básico en la familia apply Esta estrategia permitirá que fácilmente se realicen operaciones complejas sobre grupos, especificando explícitamente la estructura de datos de entrada y de salida que se está buscando. "],
["subconjuntos-de-diferentes-estructuras-de-datos.html", "4.1 Subconjuntos de diferentes estructuras de datos", " 4.1 Subconjuntos de diferentes estructuras de datos Esta sección está basada en (H. Wickham 2014a, Subsetting) disponible en línea. Aprender a extraer subconjuntos de los datos es importante y permite realizar operaciones complejas con los mismos. De los conceptos importantes que se deben aprender son Los operadores para extraer subconjuntos (subsetting operators) Los 6 tipos de extracciones de subconjuntos Las diferencias a la hora de extraer subconjuntos de las diferentes estructuras de datos (factores, listas, matrices, dataframes) El uso de la extracción de subconjuntos junto a asignar variables. Cuando tenemos que extraer pedazos de los datos (o analizar solamente parte de éstos), necesitamos complementar str() con [[, es decir, la estructura nos dirá cómo utilizar el operador subconjunto de manera que de hecho extraigamos lo que queremos. 4.1.1 Operadores para extraer subconjuntos Dependiendo la estructura de datos que tenemos, será la forma en la que extraemos elementos de ella. Hay dos operadores de subconjunto: [[ y $. [[ se parece a [ pero regresa un solo valor y te permite sacar pedazos de una lista. $ es un atajo útil para [[. 4.1.1.1 Vectores atómicos ¿De qué formas puedo extraer elementos de un vector? Hay varias maneras sin importar la clase del vector. Enteros positivos regresan los elementos en las posiciones especificadas en el orden que especificamos. x &lt;- c(5.6, 7.8, 4.5, 3.3) x[c(3, 1)] ## [1] 4.5 5.6 ## Si duplicamos posiciones, nos regresa resultados duplicados x[c(1, 1, 1)] ## [1] 5.6 5.6 5.6 ## Si usamos valores reales, se coerciona a entero x[c(1.1, 2.4)] ## [1] 5.6 7.8 x[order(x)] ## [1] 3.3 4.5 5.6 7.8 x[order(x, decreasing = T)] ## [1] 7.8 5.6 4.5 3.3 Enteros negativos omiten los valores en las posiciones que se especifican. x ## [1] 5.6 7.8 4.5 3.3 x[-c(3, 1)] ## [1] 7.8 3.3 Mezclar no funciona. x[c(-3, 1)] Vectores lógicos selecciona los elementos cuyo valor correspondiente es TRUE. Esta es una de los tipos más útiles. x[c(TRUE, TRUE, FALSE, FALSE)] ## [1] 5.6 7.8 x[c(TRUE, FALSE)] # Autocompleta el vector lógico al tamaño de x ## [1] 5.6 4.5 x[c(TRUE, TRUE, NA, FALSE)] ## [1] 5.6 7.8 NA Nada si no especifico nada, me regresa el vector original x[] ## [1] 5.6 7.8 4.5 3.3 Cero el índice cero no aplica en R, te regresa el vector vacio x[0] ## numeric(0) Si el vector tiene nombres también los puedo usar. names(x) &lt;- c(&quot;a&quot;, &quot;ab&quot;, &quot;b&quot;, &quot;c&quot;) x[&quot;ab&quot;] ## ab ## 7.8 x[&quot;d&quot;] ## &lt;NA&gt; ## NA x[grep(&quot;a&quot;, names(x))] ## a ab ## 5.6 7.8 Las listas operan básicamente igual a vectores recordando que si usamos [ regresa una lista y tanto [[ y $ extrae componentes de la lista. 4.1.1.2 Matrices y arreglos Para estructuras de mayor dimensión se pueden extraer de tres maneras: Con vectores múltiples Con un solo vector Con una matriz m &lt;- matrix(1:12, nrow = 3) colnames(m) &lt;- LETTERS[1:4] m[1:2, ] ## A B C D ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 m[c(T, F, F), c(&quot;B&quot;, &quot;C&quot;)] ## B C ## 4 7 m[1, 4] ## D ## 10 Como ven, es solamente generalizar lo que se hace en vectores replicándolo al número de dimensiones que se tiene. m[c(T, F, F)] ## [1] 1 4 7 10 class(m[c(T, F, F)]) ## [1] &quot;integer&quot; [ simplifica al objeto. En matriz, me quita la dimensionalidad, en listas me da lo que esta dentro de esa celda. 4.1.1.3 Dataframes df &lt;- data.frame(x = 1:3, y = 3:1, z = letters[1:3]) df[c(1, 2), ] ## x y z ## 1 1 3 a ## 2 2 2 b df[, c(1, 2)] ## x y ## 1 1 3 ## 2 2 2 ## 3 3 1 df[, c(&quot;z&quot;, &quot;x&quot;)] ## z x ## 1 a 1 ## 2 b 2 ## 3 c 3 df[c(&quot;z&quot;, &quot;x&quot;)] ## z x ## 1 a 1 ## 2 b 2 ## 3 c 3 class(df[, c(&quot;z&quot;, &quot;x&quot;)]) ## [1] &quot;data.frame&quot; class(df[c(&quot;z&quot;, &quot;x&quot;)]) ## [1] &quot;data.frame&quot; str(df[&quot;x&quot;]) ## &#39;data.frame&#39;: 3 obs. of 1 variable: ## $ x: int 1 2 3 str(df[, &quot;x&quot;]) ## int [1:3] 1 2 3 str(df$x) ## int [1:3] 1 2 3 Ejercicios Utiliza la base mtcars Arregla los errores al extraer subconjuntos en dataframes mtcars[mtcars$cyl = 4, ] mtcars[-1:4, ] mtcars[mtcars$cyl &lt;= 5] mtcars[mtcars$cyl == 4 | 6, ] ¿Por qué al correr x &lt;- 1:5; x[NA] obtengo valores perdidos? Genera una matriz cuadrada tamaño 5 llamada m. ¿Qué te da correr m[upper.tri(m)]? ¿Por qué al realizar mtcars[1:20] me da un error? ¿Por qué mtcars[1:2] no me lo da? ¿Por qué mtcars[1:20, ] es distinto? Haz una función que extraiga la diagonal de la matriz m que creaste antes. Debe dar el mismo resultado que ejecutar diag(m) ¿Qué hace df[is.na(df)] &lt;- 0? 4.1.2 Asignar a un subconjunto Muchas veces lo que necesitamos es encontrar ciertos valores para poder reemplazarlos con algo más. Por ejemplo, muchas veces queremos imputar valores perdidos con cierto valor. # Variables continuas x &lt;- c(1, 2, 3, NA, NaN, 7) media &lt;- mean(x, na.rm = T) media ## [1] 3.25 x[is.na(x)] &lt;- media x ## [1] 1.00 2.00 3.00 3.25 3.25 7.00 # Variables discretas x &lt;- c(rep(&quot;azul&quot;, 3), &quot;verde&quot;, NA, &quot;verde&quot;, rep(&quot;rojo&quot;, 4)) x ## [1] &quot;azul&quot; &quot;azul&quot; &quot;azul&quot; &quot;verde&quot; NA &quot;verde&quot; &quot;rojo&quot; &quot;rojo&quot; ## [9] &quot;rojo&quot; &quot;rojo&quot; moda &lt;- names(table(x))[which(table(x) == max(table(x)))] # Engorroso, no? x[is.na(x)] &lt;- moda x ## [1] &quot;azul&quot; &quot;azul&quot; &quot;azul&quot; &quot;verde&quot; &quot;rojo&quot; &quot;verde&quot; &quot;rojo&quot; &quot;rojo&quot; ## [9] &quot;rojo&quot; &quot;rojo&quot; # Puedo reemplazar partes de un vector x &lt;- 1:5 x[c(1, 2)] &lt;- 2:3 x ## [1] 2 3 3 4 5 # Las longitudes de las asignaciones tienen que ser iguales x[-1] &lt;- 4:1 x ## [1] 2 4 3 2 1 # No se revisan duplicados x[c(1, 1)] &lt;- 2:3 x ## [1] 3 4 3 2 1 # Puedo sustituir valores considerando toda la logica x &lt;- c(1:10) x[x &gt; 5] &lt;- 0 x ## [1] 1 2 3 4 5 0 0 0 0 0 Por último, es útil notar la utilidad de asignar utilizando la forma de asignar nada mencionada anteriormente. class(mtcars) ## [1] &quot;data.frame&quot; mtcars[] &lt;- lapply(mtcars, as.integer) class(mtcars) ## [1] &quot;data.frame&quot; dim(mtcars) ## [1] 32 11 mtcars &lt;- lapply(mtcars, as.integer) class(mtcars) ## [1] &quot;list&quot; dim(mtcars) ## NULL Asignar utilizando el operador de suconjunto a nada nos permite preservar la estructura del objeto original así como su clase. En el caso de listas, si combinamos un operador de subconjunto mas asignación a nulo, podemos remover objetos de ésta. x &lt;- list(a = 1, b = 2) x[[2]] &lt;- NULL str(x) ## List of 1 ## $ a: num 1 x[&quot;b&quot;] &lt;- list(NULL) str(x) ## List of 2 ## $ a: num 1 ## $ b: NULL 4.1.3 Operadores lógicos Ejemplo: Supongamos que queremos saber qué elementos de \\(x\\) son menores que \\(5\\) ó mayores que \\(8\\). x &lt;- c(1:10) x[(x&gt;8) | (x&lt;5)] ## [1] 1 2 3 4 9 10 # ¿Cómo funciona? x ## [1] 1 2 3 4 5 6 7 8 9 10 x &gt; 8 ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE x &lt; 5 ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE x &gt; 8 | x &lt; 5 ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE TRUE TRUE # x &gt; 8 || x &lt; 5 x[c(T,T,T,T,F,F,F,F,T,T)] ## [1] 1 2 3 4 9 10 || vs. | y &amp;&amp; vs. &amp; La diferencia entre &amp; y &amp;&amp; (o | y ||) es que el primero es vectorizado y el segundo no. Ejercicio ¿Qué crees que pasa en las siguientes situaciones? rm(list = ls()) TRUE || a FALSE &amp;&amp; a TRUE &amp;&amp; a TRUE | a FALSE &amp; a La forma larga (la versión doble) no parece ser muy útil. El propósito de ésta es que es más apropiado cuando se programa usando estructuras de control, por ejemplo, en ifs*. if( c(T, F) ) print(&quot;Hola&quot;) ## [1] &quot;Hola&quot; Poner el &amp;&amp; me garantiza que la condicional será evaluado sobre un único valor falso/verdadero. (-2:2) &gt;= 0 ## [1] FALSE FALSE TRUE TRUE TRUE (-2:2) &lt;= 0 ## [1] TRUE TRUE TRUE FALSE FALSE ((-2:2) &gt;= 0) &amp;&amp; ((-2:2) &lt;= 0) ## [1] FALSE Ejercicio Explora los siguientes comandos impares &lt;- 1:10 %% 2 == 1 mult.3 &lt;- 1:10 %% 3 == 0 impares &amp; mult.3 impares | mult.3 xor(impares, mult.3) Bibliografía "],
["aplicaciones.html", "4.2 Aplicaciones", " 4.2 Aplicaciones Una de las formas más fáciles de frustrarse con R (y con cualquier otro lenguaje) es no saber decirle al lenguaje lo que se desea hacer. Entender cómo manipular las estructuras de datos y la lógica detrás de su comportamiento ahorra mucho sufrimiento y permite adaptarse ante cosas que necesitamos que aún no se encuentran implementadas por alguien más de una manera más sencilla. Con saber de subconjuntos podemos realizar varias tareas indispensables. 4.2.1 Buscarv o buscarh Excel es excelente haciendo estas tareas. Lo malo de excel es que no es reproducible. Es muy común que resulte imposible llegar de los datos originales al resultado final pues muchos pasos intermedios de limpieza no están documentados de forma alguna. Un script de limpieza nos permite no solamente ir del raw a la estructura de datos limpia y analizable sino que permite que alguien más verifique las operaciones que se están realizando, se identifiquen errores y que, cuando nos llega un nuevo mes, sea trivial incluir estos datos al resultado final. rm(list = ls()) x &lt;- c(&quot;m&quot;, &quot;f&quot;, &quot;u&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;m&quot;) busca &lt;- c(m = &quot;Male&quot;, f = &quot;Female&quot;, u = NA) busca[x] ## m f u f f m m ## &quot;Male&quot; &quot;Female&quot; NA &quot;Female&quot; &quot;Female&quot; &quot;Male&quot; &quot;Male&quot; unname(busca[x]) ## [1] &quot;Male&quot; &quot;Female&quot; NA &quot;Female&quot; &quot;Female&quot; &quot;Male&quot; &quot;Male&quot; c(m = &quot;humano&quot;, f = &quot;humano&quot;, u = &quot;desconocido&quot;)[x] ## m f u f f ## &quot;humano&quot; &quot;humano&quot; &quot;desconocido&quot; &quot;humano&quot; &quot;humano&quot; ## m m ## &quot;humano&quot; &quot;humano&quot; Esto nos permite pegar un vector a una base de datos de acuerdo a una condición. calificaciones &lt;- c(10, 9, 5, 5, 6) aprueba &lt;- data.frame( calificacion = 10:1, descripcion = c(rep(&quot;excelente&quot;, 2), &quot;bueno&quot;, rep(&quot;aceptable&quot;, 2) , rep(&quot;no satisfactorio&quot;, 5)), aprobatorio = c(rep(T, 5), rep(F, 5)) ) id &lt;- match(calificaciones, aprueba$calificacion) aprueba[id, ] ## calificacion descripcion aprobatorio ## 1 10 excelente TRUE ## 2 9 excelente TRUE ## 6 5 no satisfactorio FALSE ## 6.1 5 no satisfactorio FALSE ## 5 6 aceptable TRUE Ejercicios Realiza la misma operación con las calificaciones pero utilizando los nombres de las filas, es decir, los rownames(aprueba) Carga la libreria ggplot2 y utiliza la base de datos diamonds Utiliza el comando match para quedarte con las variables cut y x Genera la variable categórica tal que, si el precio es mayor que 5,000 el valor de price.cat es cara, si es mayor que 2,000 es normal y barata en otro caso. 4.2.2 Muestras aleatorias Podemos utilizar índices enteros para generar muestras aleatorias de nuestras bases de datos o de nuestros vectores. set.seed(102030) aprueba[sample(nrow(aprueba)), ] ## calificacion descripcion aprobatorio ## 10 1 no satisfactorio FALSE ## 2 9 excelente TRUE ## 8 3 no satisfactorio FALSE ## 7 4 no satisfactorio FALSE ## 9 2 no satisfactorio FALSE ## 3 8 bueno TRUE ## 1 10 excelente TRUE ## 6 5 no satisfactorio FALSE ## 4 7 aceptable TRUE ## 5 6 aceptable TRUE aprueba[sample(nrow(aprueba), replace = T, size = 5), ] ## calificacion descripcion aprobatorio ## 4 7 aceptable TRUE ## 1 10 excelente TRUE ## 4.1 7 aceptable TRUE ## 7 4 no satisfactorio FALSE ## 2 9 excelente TRUE Ejercicios Utiliza la base de datos de iris y genera un conjunto de prueba y uno de entrenamiento correspondientes al 20 y 80 % de los datos, respectivamente. Genera un vector x de tamaño 1000 con realizaciones de una normal media 10, varianza 3. Crea 100 muestras bootstrap del vector x. Calcula la media para cada una de tus muestras. Grafica con la función hist() el vector de medias de tus muestras. Genera un vector l de letras, tamaño 10 y ordénalo. (Usa letters y order). Ordena la base cars de acuerdo a distancia, en forma descendiente (muestra la cola -usa tail- de la base ordenada). 4.2.3 Expande bases Ahora, a veces tenemos tablas de resumen pero quisieramos extraer los datos originales. Combinamos rep con subconjuntos de enteros para expandir. df &lt;- data.frame( color = c(&quot;azul&quot;, &quot;verde&quot;, &quot;amarillo&quot;), n = c(4, 3, 5) ) df ## color n ## 1 azul 4 ## 2 verde 3 ## 3 amarillo 5 df[rep(1:nrow(df), df$n), ] ## color n ## 1 azul 4 ## 1.1 azul 4 ## 1.2 azul 4 ## 1.3 azul 4 ## 2 verde 3 ## 2.1 verde 3 ## 2.2 verde 3 ## 3 amarillo 5 ## 3.1 amarillo 5 ## 3.2 amarillo 5 ## 3.3 amarillo 5 ## 3.4 amarillo 5 4.2.4 Which, intersect y union Ya estuvimos utilizando otras aplicaciones de estos comandos: ordenamientos, selección de filas o columnas según una condición lógica. También utilizamos un comando muy útil llamado which. set.seed(45) x &lt;- sample(letters, 10) x &lt;= &quot;e&quot; ## [1] FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE which(x &lt;= &quot;e&quot;) ## [1] 7 9 10 Junto con which, puedes usar intersect y union. pares &lt;- 1:10 %% 2 == 0 m.5 &lt;- 1:10 %% 5 == 0 c(1:10)[union(which(pares), which(m.5))] c(1:10)[intersect(which(pares), which(m.5))] c(1:10)[which(xor(pares, m.5))] 4.2.5 Generación de datos a partir de distribuciones R básico provee funciones de distribución de probabilidad (p), funciones de densidad (d), funciones cuantiles (q) y generación de números aleatorios (r) para varias distribuciones como la binomial, chi-cuadrada, gamma, geométrica, etc. Dutang (2016) resumen otros paquetes en donde se encuentran implementadas otras funcionalidades o distribuciones multivariadas y cópulas. En las funciones de R básico, podemos construir un dataframe con realizaciones de distintas distintas distribuciones, por ejemplo, a continuación generamos la variable \\(x\\) como realizaciones de una normal, \\(y\\) con realizaciones de una exponencial y \\(z\\) con realizaciones de una uniforme. df &lt;- data.frame( x = rnorm(100) , y = rexp(100) , z = runif(100) ) Bibliografía "],
["split-apply-combine.html", "4.3 Split-apply-combine", " 4.3 Split-apply-combine Muchos problemas en el análisis de datos pueden ser resueltos aplicando la estrategia separa, aplica y combina (SAC) en donde divides un problema en pequeños pedazos manejables, operas en forma independiente cada uno de éstos y después combinas los resultados obtenidos (Wickham 2011). Esta estrategia se utiliza en diversas etapas del análisis de datos, por ejemplo (Wickham 2011): Preparación de datos. Cuando se crean nuevas variables según grupos, cuando se realizan ordenamientos por grupos, cuando se estandariza o normaliza variables. Estadística descriptiva. Cuando se crean agregados por grupos como sus medias o medianas. Modelado. Cuando se calculan modelos separados para cada panel en un estudio de este tipo. Estos modelos pueden examinarse por separado o unificarse para construir modelos más sofisticados que los conjuguen. Esta estrategia se utiliza en muchas herramientas: en las tablas dinámicas de Microsoft Excel, el operador group by de SQL, el argumento by disponible en algunos procedimientos de SAS (Wickham 2011). El paradigma split-apply-combine se resume en la figura 4.1. Figura 4.1: Ejemplificación del split-apply-combine (Vaidyanathan 2014, Split-Apply-Combine) Replicamos los vectores \\(x\\) y \\(y\\) de la figura en un dataframe: letras &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) df &lt;- data.frame( x = sort(letras[rep(seq(letras), 2)]), y = c(2, 4, 0, 5, 5, 10) ) df ## x y ## 1 a 2 ## 2 a 4 ## 3 b 0 ## 4 b 5 ## 5 c 5 ## 6 c 10 Queremos estimar la media de los valores en el vector \\(y\\) para cada tipo de letra en el vector \\(x\\). Esto lo podemos hacer utilizando la estrategia SAC, como en la figura. # Dividimos for (l in unique(df$x) ){ print(paste0(&quot;Grupo con letra: &quot;, l)) print(df[l == df$x, ]) } ## [1] &quot;Grupo con letra: a&quot; ## x y ## 1 a 2 ## 2 a 4 ## [1] &quot;Grupo con letra: b&quot; ## x y ## 3 b 0 ## 4 b 5 ## [1] &quot;Grupo con letra: c&quot; ## x y ## 5 c 5 ## 6 c 10 # Aplicamos for (l in unique(df$x) ){ print(paste0(&quot;Media para valores de letra: &quot;, l)) print(mean(df[l == df$x, ]$y)) } ## [1] &quot;Media para valores de letra: a&quot; ## [1] 3 ## [1] &quot;Media para valores de letra: b&quot; ## [1] 2.5 ## [1] &quot;Media para valores de letra: c&quot; ## [1] 7.5 # Combinamos medias &lt;- list() for (l in unique(df$x) ){ medias[[l]] &lt;- mean(df[l == df$x, ]$y) } as.data.frame(list(letras = names(medias), medias = unname(unlist(medias)))) ## letras medias ## 1 a 3.0 ## 2 b 2.5 ## 3 c 7.5 R tiene muchas funciones que facilitan realizar este tipo de operaciones. En particular, la familia apply fue pensada para realizarlas. Cada una de las funciones en esta familia recibe una estructura de datos en particular, aplica de determinada manera la función que se le especifica y combina los resultados de una forma específica. 4.3.1 apply apply aplica una función a cada fila o columna en una matriz. Separa: por columna o fila según se especifica en el parámetro MARGIN (1 para filas, 2 para columnas). Aplica: la función que se especifica en el parámetro FUN. Combina: regresa un vector con los resultados. m &lt;- matrix(c(1:5, 6:10), nrow = 5, ncol = 2) # 1 is the row index 2 is the column index m ## [,1] [,2] ## [1,] 1 6 ## [2,] 2 7 ## [3,] 3 8 ## [4,] 4 9 ## [5,] 5 10 apply(m, 1, sum) ## [1] 7 9 11 13 15 apply(m, 2, sum) ## [1] 15 40 Ejercicio Haz una función que reciba un vector y devuelva la suma de la posición \\(v_i + v_{i + 1}\\). Para el n-esimo elemento, suma el primero. Aplica esa función a las columnas y filas de la matriz m. # Respuesta suma.rec &lt;- function(v){ resultado &lt;- c() for (e in seq(length(v) - 1)){ resultado[e] &lt;- v[e] + v[e + 1] } resultado[length(v)] &lt;- v[length(v)] + v[1] return(resultado) } m apply(m, 1, suma.rec) apply(m, 2, suma.rec) 4.3.2 lapply lapply aplica una función a cada elemento en una lista. Como sabemos, un data.frame es únicamente un estilo particular de lista tal que todos sus elementos tienen el mismo tamaño. Por ende, también podemos utilizar lapply para iterar sobre las columnas de un data.frame. lista &lt;- list(a = 1:10, b = 2:20) lapply(lista, mean) ## $a ## [1] 5.5 ## ## $b ## [1] 11 df &lt;- data.frame(a = 1:10, b = 11:20) lapply(df, mean) ## $a ## [1] 5.5 ## ## $b ## [1] 15.5 Ejercicio El summary de un data.frame genera un resumen para los vectores que la conforman de acuerdo a la clase de la misma. Genera una función que regrese una tabla de frecuencias para factores y caracteres o una lista con media, desviación estándar para vectores numéricos o enteros. Aplícalo a la base diamonds usando lapply. # Respuesta mi.resumen &lt;- function(vector){ if( class(vector) == &quot;factor&quot; || class(vector) == &quot;character&quot;){ table(vector) } else if ( class(vector) == &quot;numeric&quot; || class(vector) == &quot;integer&quot;) { list(media = mean(vector), de = sqrt(var(vector))) } } lapply(names(diamonds), FUN = function(c) mi.resumen(diamonds[, c])) 4.3.3 sapply sapply es otra versión de lapply que regresa una lista o un vector, dependiendo si se especifica el parámetro simplify = T y si la función aplicada regresa un único valor. x &lt;- sapply(lista, mean, simplify = F) x ## $a ## [1] 5.5 ## ## $b ## [1] 11 x &lt;- sapply(lista, mean, simplify = T) x ## a b ## 5.5 11.0 Ejercicio Obtén un vector tipo caracter con los nombres de las clases de las columnas de iris. # Respuesta sapply(iris, class) Ejercicio Repite el ejercicio de la suma rara pero usa sapply. Recuerda la instrucción: Haz una función que reciba un vector y devuelva la suma de la posición \\(v_i + v_{i + 1}\\). Para el n-esimo elemento, suma el primero. Utiliza sapply para realizar esta operacion. # Respuesta x &lt;- 1:10 sapply(seq(x), FUN = function(i){ if( i == length(x) ){ x[1] + x[i] } else { x[i] + x[i + 1] } }) 4.3.4 mapply mapply es como la versión multivariada de sapply. Le aplica una función a todos los elementos correspondientes de un argumento. l1 &lt;-list(a = c(1:5), b = c(6:10)) l2 &lt;- list(c = c(11:15), d = c(16:20)) l1 ## $a ## [1] 1 2 3 4 5 ## ## $b ## [1] 6 7 8 9 10 l2 ## $c ## [1] 11 12 13 14 15 ## ## $d ## [1] 16 17 18 19 20 mapply(sum, l1$a, l1$b, l2$c, l2$d) ## [1] 34 38 42 46 50 l1[[&quot;a&quot;]][1] + l1[[&quot;b&quot;]][1] + l2[[&quot;c&quot;]][1] + l2[[&quot;d&quot;]][1] ## [1] 34 Ejercicio Crea una matriz de 4 x 4 donde el primer renglón sea de unos, el segundo de dos, el tercero de 3 y el cuarto de 4. Usa mapply para hacerlo. # Respuesta m &lt;- matrix(c(rep(1, 4), rep(2, 4), rep(3, 4), rep(4, 4)), nrow = 4, byrow = T) m me &lt;- t(mapply(rep, 1:4, 4)) me 4.3.5 tapply tapply le aplica una función a subconjuntos de un vector. head(warpbreaks) ## breaks wool tension ## 1 26 A L ## 2 30 A L ## 3 54 A L ## 4 25 A L ## 5 70 A L ## 6 52 A L with(warpbreaks, tapply(breaks, list(wool, tension), mean)) ## L M H ## A 44.55556 24.00000 24.55556 ## B 28.22222 28.77778 18.77778 tapply(warpbreaks$breaks, list(wool = warpbreaks$wool, tension = warpbreaks$tension), mean) ## tension ## wool L M H ## A 44.55556 24.00000 24.55556 ## B 28.22222 28.77778 18.77778 Ejercicio Utiliza la función tapply y la base de datos diamonds (que está dentro del paquete ggplot2) para obtener las medias de la variable carat para los grupos formados por la variable categórica cut y la variable categórica color. # Respuesta library(ggplot2) with(diamonds, tapply(carat, list(cut, color), mean)) 4.3.6 by by le aplica una función a subconjuntos de un data.frame. Se divide un data.frame según los valores de de uno o más factores. Se aplica la función FUN a cada subconjunto. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa by(data = iris[, 1:2], INDICES = iris[, &quot;Species&quot;], FUN = summary) ## iris[, &quot;Species&quot;]: setosa ## Sepal.Length Sepal.Width ## Min. :4.300 Min. :2.300 ## 1st Qu.:4.800 1st Qu.:3.200 ## Median :5.000 Median :3.400 ## Mean :5.006 Mean :3.428 ## 3rd Qu.:5.200 3rd Qu.:3.675 ## Max. :5.800 Max. :4.400 ## -------------------------------------------------------- ## iris[, &quot;Species&quot;]: versicolor ## Sepal.Length Sepal.Width ## Min. :4.900 Min. :2.000 ## 1st Qu.:5.600 1st Qu.:2.525 ## Median :5.900 Median :2.800 ## Mean :5.936 Mean :2.770 ## 3rd Qu.:6.300 3rd Qu.:3.000 ## Max. :7.000 Max. :3.400 ## -------------------------------------------------------- ## iris[, &quot;Species&quot;]: virginica ## Sepal.Length Sepal.Width ## Min. :4.900 Min. :2.200 ## 1st Qu.:6.225 1st Qu.:2.800 ## Median :6.500 Median :3.000 ## Mean :6.588 Mean :2.974 ## 3rd Qu.:6.900 3rd Qu.:3.175 ## Max. :7.900 Max. :3.800 Puedo calcular, por ejemplo, la suma de los valores del largo y ancho de los sépalos en la base de datos iris según la especie. res &lt;- by(iris[, c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;)], iris[, &quot;Species&quot;], sum) Posteriormente, se pueden combinar los elementos. as.data.frame(list( &quot;species&quot; = names(res), &quot;suma&quot; = sapply(seq(length(res)), FUN = function(i) res[[i]]) )) ## species suma ## 1 setosa 421.7 ## 2 versicolor 435.3 ## 3 virginica 478.1 Ejercicio Vuelve a utilizar la base de diamonds para calcular el promedio de carat según cut y color. # Respuesta library(ggplot2) head(diamonds) res &lt;- by(diamonds[, c(&quot;carat&quot;)], list(cut = as.factor(diamonds$cut) , color = as.factor(diamonds$color)) , mean, simplify = T) 4.3.7 replicate replicate es una función muy útil sobretodo en el contexto de simulación. replicate(5, rnorm(5), simplify = F) ## [[1]] ## [1] -0.01744899 -0.35920817 -1.46121725 -0.82974515 0.53160175 ## ## [[2]] ## [1] -0.2601847 0.5065636 1.3330763 -1.4945952 0.8039902 ## ## [[3]] ## [1] -0.2155771 -0.8922644 -0.1466588 -0.3234650 -1.0602366 ## ## [[4]] ## [1] -1.4859165 1.4469633 1.5193526 1.4491572 0.3427115 ## ## [[5]] ## [1] -0.94652506 -1.25920627 -0.06813108 -0.75359982 0.43192663 replicate(6, rnorm(4), simplify = T) ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 0.12276245 0.4528315 -0.1228450 -1.5292287 -0.42799037 0.6360040 ## [2,] 0.00389876 -0.4863693 -2.4085836 -0.7545786 1.92098812 0.3017047 ## [3,] -0.80426655 0.1570096 0.1789978 1.6316763 0.03015651 1.4364364 ## [4,] 0.12613563 -0.4231777 -0.7788772 0.6512902 -0.21573077 -0.7753874 hist(replicate(100, mean(rexp(10)))) Ejercicio Replica el ejercicio de muestras bootstrap utilizando la función replicate. Recordando las instrucciones: Genera un vector x de tamaño \\(1000\\) con realizaciones de una normal media \\(10\\), varianza \\(3\\). Crea \\(100\\) muestras bootstrap del vector \\(x\\). Calcula la media para cada una de tus muestras. Grafica con la función hist() el vector de medias de tus muestras. # Respuesta # 1 x &lt;- rnorm(1000, mean = 10, sd = sqrt(3)) hist( # 4 replicate(100, # 2 mean(sample(x, size = 1000, replace = T))), # 3 main = &quot;Muestras bootstrap&quot;, xlab = &quot;media&quot;, ylab = &quot;frecuencia&quot; ) 4.3.8 ¿Puede ser más fácil? La familia apply viene con R básico. Sin embargo, hay 3 implementaciones excelentes del paradigma split-apply-combine: plyr, dplyr y data.table. Si la familia apply es poderosa, se queda corta comparada con estos tres. plyr es la primera versión de SAC de Wickham (Wickham 2011). Posteriormente, mejoró muchas de las funciones en dplyr (Wickham and Francois, n.d.) sobretodo entorno a velocidad y facilidad de uso. plyr no termina de ser relevante pues varias de sus funciones aun no están en dplyr pero está por ser sustituido. data.table (Dowle et al. 2015), es una implementación con una tradición muy diferente y tiene también funciones muy poderosas aunque con una sintaxis muy distinta a dplyr. Es absurdamente eficiente y tiene múltiples aplicaciones. Muchas de las funciones en dplyr también están implementadas en data.table. Ambos paquetes son útiles pero priorizan distintos elementos. En el capítulo siguiente se repasarán los verbos en dplyr. Bibliografía "],
["material-adicional-2.html", "4.4 Material adicional", " 4.4 Material adicional Curso de swirl R Programming, módulos 10 a 15. Curso Intermediate R de Data Camp. Curso Intermediate R - Practice de Data Camp. "],
["herramientas-basicas-para-un-proyecto-de-datos.html", "Capítulo 5 Herramientas básicas para un proyecto de datos", " Capítulo 5 Herramientas básicas para un proyecto de datos Un proyecto de datos tiene una gran cantidad de componentes. Sin embargo, en básicamente todos se necesita iterar sobre el ciclo que se muestra en la figura 5.1. Figura 5.1: Modelo de las herramientas que se necesitan en un proyecto de datos según (Grolemund and Wickham 2016, Introducción). Primero es necesario importar nuestros datos a R. Los datos pueden estar en una gran cantidad de formatos o lugares. Después, normalmente es necesario limpiar nuestros datos, es decir, seguir criterios de datos limpios de tal forma que el cómo guardemos los datos equivalga a la semántica de los datos que tenemos. Es muy importante primero limpiar porque esto provee de consistencia a lo largo del análisis. Posteriormente, en casi todo proyecto, será necesario transformar los datos. A veces esto implica enfocarse en un subconjunto de los datos, generar nuevas variables, calcular estadísticos, arreglar los datos de cierta manera, entre muchos otros. Solamente después de estas etapas podemos empezar a generar conocimiento a partir de los datos. Para esto tenemos dos herramientas fundamentales: la estadística descriptiva (en el diagrama reducido a visualización) y la generación de modelos. La primera es fundamental pues permite derivar preguntas pertinentes a los datos, encontrar patrones, respuestas, plantear hipótesis. Sin embargo, éstas no escalan de la misma manera que los modelos pues éstos, una vez que aceptamos sus supuestos, generan los resultados que esperamos o contestan la pregunta planteada. Por último, necesitamos comunicar los resultados. En este capítulo nos ocuparemos, por sección, únicamente de 4 de las etapas mencionadas: importación, limpieza, transformación y visualización. Bibliografía "],
["importacion-de-datos.html", "5.1 Importación de datos", " 5.1 Importación de datos Esta sección resume algunas de las funciones existentes para importar datos de distintos formatos a R. En la figura 5.2 podemos ver la etapa del análisis de datos correspondiente. Figura 5.2: Importación en el análisis de datos (Grolemund and Wickham 2016, Introducción). Para aplicar las herramientas de R a nuestro trabajo, es necesario poder importar nuestros datos a R. R tiene conectores ya implementados para casi cualquier tipo y formato de datos. Entre los más comunes están8: Formato Lectura Escritura rds base::readRDS base::saveRDS separado por * utils::read.table; readr::read_delim utils::write.table; readr::write_delim csv utils::read.csv; readr::read_csv utils::write.csv; readr::write_csv Microsoft Excel readxl::read_excel xlsx::write.xlsx dbf foreign::read.dbf foreign::write.dbf IBM SPSS haven::read_sav haven::write_sav Stata haven::read_dta foreign::write.dta SAS haven::read_sas haven::write_sas Google spreadsheet googlesheets::gs_read googlesheets::gs_new Google bigquery bigrquery::query_exec Heroku Postgres sql2df df2sql rdata base::load base::save Los paquetes utilizados son (corre estos comandos en la consola): library(foreign) library(haven) library(readr) library(readxl) library(xlsx) library(googlesheets) library(bigrquery) Importancia de rutas relativas Para leer un archivo, recordemos el comando getwd() para encontrar la carpeta a la cual R esta dirigido en este momento. Una buena practica es considerar el directorio de trabajo como el lugar en donde esta guardado el archivo o script en el que se trabaja y “moverse” desde ahí hasta el archivo que se quiere leer. Ya sea en escritura o en lectura, R buscará a partir del directorio de trabajo (el que se despliega con getwd()) para buscar a partir de ahí el archivo por leer o para guardar el que se escribirá si se usan rutas relativas. En caso de usar rutas absolutas (a pesar de que esto no es una buena práctica) se hará lectura o escritura del archivo en el lugar especificado. Ejercicios R tiene conexión con muchos de los formatos en los que se encuentran los datos. Veremos algunos de los mas relevantes. El código en cada uno de los chunks (un chunk es el pedazo del documento en donde hay código de R) está hecho para que puedas correrlo en la consola (excepto cuando dice explícitamente do not run (leyenda comúnmente encontrada en los ejemplos de la documentación de las funciones. Con esto entenderás mejor el concepto de rutas relativas. 5.1.1 rds La extensión rds es de las más comúnmente utilizada en R, por ejemplo, para guardar los datos para un paquete. Las funciones pertenecen al base (R Core Team 2016b). Permiten guardar un solo objeto de R a un archivo y recuperarlo. Para escribirlos # Creamos un dataframe llamado misdatos misdatos &lt;- iris # Los guardamos en comprimido saveRDS(misdatos, file = &quot;misdatos.rds&quot;, ascii = FALSE, version = NULL, compress = TRUE, refhook = NULL) Nota como si usas el comando getwd() y después vas a la ruta indicada por medio del explorador de archivos, verás en esa carpeta el archivo misdatos.rds. Para leerlos usamos la ruta relativa. Dado que los guardamos en el directorio de trabajo actual (Recuerda, se puede cambiar con el comando setwd) entonces simplemente los llamamos: misdatos &lt;- readRDS(&quot;misdatos.rds&quot;) # Los borramos file.remove(&quot;misdatos.rds&quot;) 5.1.2 separado por * Con esto nos referimos a la colección de archivos en texto plano, es decir, .txt, .tsv, .psv, etcétera. Para escribirlos el mas común es write.table del paquete utils (R Core Team 2016c) # Do not run write.table(misdatos, file = &quot;~/misdatos.&lt;extension&gt;&quot;, append = FALSE , quote = TRUE, sep = &quot; &quot;, eol = &quot;\\n&quot;, na = &quot;NA&quot;, dec = &quot;.&quot; , row.names = TRUE, col.names = TRUE , qmethod = c(&quot;escape&quot;, &quot;double&quot;), fileEncoding = &quot;&quot;) En el paquete readr se implementa también write_delim # Do not run write_delim(misdatos, path = &quot;~/misdatos.&lt;extension&gt;&quot; , delim = &quot;\\t&quot;, na = &quot;NA&quot;, append = FALSE, col_names = !append) Escribamos ahora el dataframe misdatos en psv: write_delim(misdatos, path = &quot;misdatos.psv&quot;, delim = &quot;|&quot;) Para leerlos read.table del paquete utils (R Core Team 2016c) nos permite especificar casi cualquier particularidad en un archivo de texto plano. # Do not run misdatos &lt;- read.table(&quot;~/misdatos.&lt;extension&gt;&quot;, header = FALSE , sep = &quot;&quot;, quote = &quot;\\&quot;&#39;&quot;, dec = &quot;.&quot; , numerals = c(&quot;allow.loss&quot;, &quot;warn.loss&quot;, &quot;no.loss&quot;) , row.names, col.names, as.is = !stringsAsFactors , na.strings = &quot;NA&quot;, colClasses = NA, nrows = -1 , skip = 0, check.names = TRUE , fill = !blank.lines.skip, strip.white = FALSE , blank.lines.skip = TRUE, comment.char = &quot;#&quot; , allowEscapes = FALSE, flush = FALSE , stringsAsFactors = default.stringsAsFactors() , fileEncoding = &quot;&quot;, encoding = &quot;unknown&quot;, text , skipNul = FALSE) La función read_delim del paquete readr (Wickham, Hester, and Francois 2016) lee los datos más eficientemente a un objeto de clase tibble. # Do not run misdatos &lt;- read_delim(file = &quot;~/misdatos.&lt;extension&gt;&quot;, delim , quote = &quot;\\&quot;&quot;, escape_backslash = FALSE , escape_double = TRUE, col_names = TRUE , col_types = NULL, locale = default_locale() , na = c(&quot;&quot;, &quot;NA&quot;), quoted_na = TRUE, comment = &quot;&quot; , trim_ws = FALSE, skip = 0, n_max = Inf , guess_max = min(1000, n_max) , progress = interactive()) Leemos el archivo .psv que creamos antes: misdatos &lt;- read_delim(file = &quot;misdatos.psv&quot;, delim = &quot;|&quot;) # Los borramos file.remove(&quot;misdatos.psv&quot;) 5.1.3 csv (archivo separado por comas) Este es un caso particular de archivos de texto en el que se separan por comas. Como es muy utilizado, generalmente se hacen funciones donde ya se especifica el delimitador. Guardaremos el data frame misdatos en el directorio “arriba” de la ruta que se muestra usando getwd. Esto lo podemos hacer anteponiendo al nombre del archivo con ../. Para escribirlos # utils write.csv(misdatos, file = &quot;../misdatos.csv&quot;, row.names = F) # readr write_csv(misdatos, path = &quot;../misdatos.csv&quot;, na = &quot;NA&quot;, append = FALSE) Observa en el explorador de archivos en dónde es que se guardó el archivo misdatos.csv. Para leerlos, seguimos usando rutas relativas. # utils - como data.frame misdatos &lt;- read.table(&quot;../misdatos.csv&quot;, header=TRUE, sep=&quot;,&quot;) misdatos &lt;- read.csv(&quot;../misdatos.csv&quot;) # readr - como tibble misdatos &lt;- read_csv(&quot;../misdatos.csv&quot;) # Lo borro file.remove(&quot;../misdatos.csv&quot;) 5.1.4 Microsoft Excel Para escribirlos dentro del paquete xlsx usamos la función write.xlsx misdatos &lt;- iris write.xlsx(misdatos, &quot;misdatos.xlsx&quot;, row.names = F) Para leerlos dentro del paquete readxl se encuentra la función read_excel que es muy útil en este caso. misdatos &lt;- read_excel(&quot;misdatos.xlsx&quot;, sheet = 1, col_names = TRUE, col_types = NULL, na = &quot;&quot;, skip = 0) # Lo borro file.remove(&quot;misdatos.xlsx&quot;) 5.1.5 dbf Extensión que representa un archivo de una base de datos (database file). Para escribirlos: write.dbf(as.data.frame(misdatos), &quot;misdatos.dbf&quot;) Nota cómo tuvimos que coercionar el objeto a data frame. Como en el ejemplo anterior leímos un tibble y el paquete foreign es más viejo (y no conoce los tibbles) entonces le mandamos un objeto que si conoce. Veremos más adelante la ventaja de usar tibbles aún cuando de vez en cuando se tienen problemas de compatibilidad. Para leerlos: misdatos &lt;- read.dbf(&quot;misdatos.dbf&quot;) # Lo borro file.remove(&quot;misdatos.dbf&quot;) 5.1.6 IBM SPSS SPSS puede guardar los datos agregando etiquetas y otros metadatos. Para evitar retrabajo, puede leerse directamente a R. Para escribirlos # haven write_sav(data = misdatos, path = &quot;misdatos.sav&quot;) Para leerlos # haven - como tibble misdatos &lt;- read_sav(file = &quot;misdatos.sav&quot;, user_na = FALSE) # Lo borro file.remove(&quot;misdatos.sav&quot;) 5.1.7 Stata HOME DIRECTORY El directorio (carpeta) home es muy utilizado. Normalmente, se le denota como \\(\\thicksim\\) y es en donde un sistema operativo guarda los archivos del usuario que se encuentra en sesión. Dependiendo del sistema operativo que utilices, encontrarás este directorio en una ruta específica. En Microsoft Windows Vista 7, 8 y 10 lo encuentras en &lt;root&gt;\\Users\\&lt;username&gt;. En Linux lo encuentras en /home/&lt;username&gt;. En Mac OS X lo encuentras en /Users/&lt;username&gt;. Para escribirlos en Stata primero tenemos que cambiar los nombres de las variables en el data frame pues Stata no admite puntos en los nombres: names(misdatos) &lt;- tolower(gsub(&quot;\\\\.&quot;, &quot;_&quot;, names(misdatos))) # foreign write.dta(data = misdatos, file = &quot;~/misdatos.dta&quot;, version = 12) Para leerlos # haven - como tibble misdatos &lt;- read_dta(file = &quot;~/misdatos.dta&quot;, encoding = NULL) # Lo borramos file.remove(&quot;~/misdatos.dta&quot;) 5.1.8 SAS Para usar el paquete haven en este caso ejemplificaremos la creación de un directorio de archivos en tu computadora desde R: # Creamos un directorio llamado datos dir.create(&quot;datos_sas&quot;) Observa como, en el directorio que se despliega con getwd encuentras ahora una carpeta llamada datos_sas. Creamos ahí un archivo con la función write_sas de haven. Nota que, para escribirlos, también debemos asegurarnos que los nombres de variables estén compuestos por letras, números o guiones bajos: misdatos &lt;- iris names(misdatos) &lt;- tolower(gsub(&quot;\\\\.&quot;, &quot;_&quot;, names(misdatos))) # haven write_sas(data = misdatos, path = &quot;datos_sas/misdatos.sas7bdat&quot;) Para leerlos, utilizamos read_sas del paquete haven: # haven - como tibble misdatos &lt;- read_sas(&quot;datos_sas/misdatos.sas7bdat&quot; , catalog_file = NULL, encoding = NULL) Observa desde el explorador de archivos, cómo se creó el archivo dentro del directorio datos_sas/. También desde R podemos borrar el directorio: unlink(&quot;datos_sas&quot;, recursive = T, force = FALSE) La bandera recursive le dice al sistema que borre todo lo contenido en esa carpeta. 5.1.9 Google Spreadsheet Para hacer este ejercicio, debes tener una cuenta de gmail. Primero, debe realizarse la autenticación. Esto lo puedes hacer en cualquier sesión interactiva utilizando alguna función del paquete googlesheets gs_ls() En la consola de R te aparece: Se abrirá una ventana del explorador y deberás introducir tus credenciales de tu cuenta de gmail Después de poner tus credenciales, te aparecerá un mensaje pidiendo acceso a tus datos en drive: Al aceptar darle acceso, recibirás un mensaje parecido a Authentication complete. Please close this page and return to R. Ahora verás en la consola de R un listado de las google spreadsheets en tu cuenta de gmail. Ahora, vamos a escribir una nueva hoja en tu cuenta. gs_new(&quot;misdatos&quot;, ws_title = &quot;mihoja&quot;, input = head(iris) , trim = TRUE, verbose = FALSE) Si vas a tu google drive, deberás ver que se creó un nuevo elemento que se ve así: De igual forma, puedes ahora leer los datos de cualquier google spreadsheet que tengas en tu cuenta. misdatos &lt;- gs_read(gs_title(&quot;misdatos&quot;), ws = &quot;mihoja&quot;) # La borro gs_delete(gs_title(&quot;misdatos&quot;)) 5.1.10 Google bigquery Google bigquery es un data warehouse que permite guardar grandes bases de datos. Al contratar el servicio, google se encarga del hardware y la infraestructura necesaria para que su procesamiento sea rápido (Platform 2016). Para guardar tus datos en bigquery debes crear un proyecto en la consola de desarrolladores. Existen varias bases de dato públicas disponibles. Para poder utilizarlas, necesitas tener una cuenta. Puedes empezar una prueba gratis en la página de google cloud platform. Verás una pantalla como esta: Sigue las instrucciones y eventualmente llegarás a una pantalla como esta Copia el identificador de tu proyecto para que puedas realizar queries (llamadas a las bases de datos). Leemos la base de datos pública de natalidad en Estados Unidos. project &lt;- &quot;focus-healer-159122&quot; # pon tu projectID aquí sql &lt;- &#39;SELECT year, count(*) as babies, avg(mother_age) as mother_age_avg FROM[publicdata:samples.natality] WHERE year &gt; 1980 and year &lt; 2006 group by year;&#39; data &lt;- query_exec(query = sql, project = project) Nota como la tabla cuenta con aproximadamente. 140 millones de registros y se obtiene el detalle en segundos. 5.1.11 Heroku Postgres R no es un manejador de base de datos y, por ende, no es un lenguaje que permite trabajar con una gran cantidad de datos. R guarda los objetos utilizando la memoria virtual de la computadora, i.e. la RAM, misma que depende de varios elementos (incluido el sistema operativo) y que limita los datos que podrán ser procesados. Cuando necesitamos conocer el tamaño de los datos que están en el ambiente de trabajo, puede utilizarse el paquete pryr (H. Wickham 2015a, sección “the role of physical memory”). rm(list = ls()) # borramos los objetos del ambiente # Cargamos datos al ambiente flights &lt;- read_csv(&quot;data/flights.csv&quot;) airports &lt;- read_csv(&quot;data/airports.csv&quot;) planes &lt;- read_csv(&quot;data/planes.csv&quot;) ls() # mostramos los objetos en el ambiente library(pryr) # Cargamos el paquete pryr mem_used() # memoria utilizada object_size(flights, units = &quot;Mb&quot;) # Obtenemos el tamaño de un objeto sapply(ls(), function(x) object_size(get(x))) # de todos en el ambiente Las estrategias en memoria se revisaron brevemente en el apartado XXX, en este caso, es pertinente mencionar las estrategias fuera de memoria (out of memory). Es posible explorar un conjunto de datos sin necesidad de cargarlos en R pero utilizando comandos de R y trabajando desde un script de R, permitiendo que herramientas más eficientes (y apropiadas) para el trabajo de grandes volúmenes de datos realicen el procesamiento de los mismos. Los sistemas gestores de base de datos están optimizados para almacenar y buscar en grandes volúmenes de datos en forma más eficiente que R. Algunos ejemplos populares son Oracle y PostgreSQL (Peng, Kross, and Anderson 2016, sección “working with large datasets”). Hay múltiples paquetes que permiten establecer una conexión con estos sistemas desde una sesión de R. Los paquetes DBI y Postgresql permiten realizar esta tarea. Debido a que requieren credenciales se muestra una función para leer datos desde PostgreSQL y escribirlos sin necesidad de poner las credenciales dentro del mismo script. Para que funcionen apropiadamente, es necesario poner en el directorio de trabajo un archivo llamado parametros.yaml en donde se escriben las credenciales para Postgres: host : localhost db : postgres username : usr password : password Nota: el salto de línea en la última línea es importante. Para leer datos, creamos una función a la que podemos enviarle una cadena de comandos en SQL. ### POSTGRES sql2df &lt;- function(sql.file, df.file = &quot;&quot;) { require(DBI) require(futile.logger) require(yaml) require(RPostgreSQL) if(!file.exists(df.file)) { if(file.exists(&quot;./parametros.yaml&quot;)) { x &lt;- yaml::yaml.load_file(&quot;./parametros.yaml&quot;) } else { x &lt;- yaml::yaml.load_file(&quot;../parametros.yaml&quot;) } # Creamos la conexión a la base de datos futile.logger::flog.info(&quot;Conectando a la base de datos&quot;) con &lt;- dbConnect(RPostgreSQL::PostgreSQL(), dbname = x$db, host = x$host, port = 5432, user = x$username, password = x$password) futile.logger::flog.info(&quot;Conectado a %s, como %s&quot;, x$host, x$username) # Leemos el query sql &lt;- paste(readLines(sql.file,encoding=&quot;UTF-8&quot;) , sep=&quot; &quot;, collapse=&quot; &quot;) tryCatch( { futile.logger::flog.info(&quot;Ejecutando el query&quot;) # Creamos el query rs &lt;- RPostgreSQL::dbSendQuery(con, sql) futile.logger::flog.info(&quot;Obteniendo los datos&quot;) # Obtenemos los datos df &lt;- DBI::dbFetch(rs) # Liberamos el ResultSet futile.logger::flog.info(&quot;Limpiando el result set&quot;) RPostgreSQL::dbClearResult(rs) }, finally=RPostgreSQL::dbDisconnect(con) # Nos desconectamos de la BD ) if(df.file != &quot;&quot;){ saveRDS(object=df, file=df.file) } } else { df &lt;- readRDS(df.file) } return(df) } La función sql2df9 recibe como parámetro, como cadena, la ruta hacia un archivo de extensión .sql con los comandos a ejecutar en el manejador de base de datos. Éste puede verse, por ejemplo, como: select * from information_schema.tables where table_schema = &#39;information_schema&#39;; Guardamos ésta en el archivo sql/ejemplo.sql la cláusula de arriba. Después, llamamos a la función. ### POSTGRES datos &lt;- sql2df(&quot;sql/ejemplo.sql&quot;, df.file = &quot;ejemplo.rds&quot;) head(datos) Con el parámetro df.file es posible especificar una ruta para que se guarde una copia local del resultado de los datos. Esto es útil cuando se está trabajando con los datos, de forma que sea más rápido el trabajo con los mismos. Para escribir datos, podemos utilizar la función siguiente: ### POSTGRES df2sql &lt;- function(data.frame, df.schema.name, df.table.name, owner.to = NA) { require(DBI) require(futile.logger) require(yaml) require(RPostgreSQL) data.frame &lt;- data.frame(data.frame) # Normalizamos nombres names(data.frame) &lt;- normalizarNombres(names(data.frame)) if(file.exists(&quot;./parametros.yaml&quot;)) { x &lt;- yaml::yaml.load_file(&quot;./parametros.yaml&quot;) } else { x &lt;- yaml::yaml.load_file(&quot;../parametros.yaml&quot;) } # Creamos la conexión a la base de datos futile.logger::flog.info(&quot;Conectando a la base de datos&quot;) con &lt;- dbConnect(RPostgreSQL::PostgreSQL(), dbname = x$db, host = x$host, port = 5432, user = x$username, password = x$password) futile.logger::flog.info(&quot;Conectado a %s, como %s&quot; , x$host, x$username) tryCatch( { flog.info(&quot;Ejecutando la escritura de tabla %s en el esquema %s&quot; , df.table.name, df.schema.name) # Definimos el camino al esquema deseado if(df.schema.name != &quot;public&quot;){ dbSendQuery(conn = con , statement = paste0(&quot;SET search_path = &quot; , df.schema.name, &quot;, public;&quot;)) } long.name &lt;- paste0(df.schema.name, &quot;.&quot;, df.table.name) # Escribimos la tabla dbWriteTable(con, df.table.name, data.frame, overwrite=FALSE, append = TRUE) flog.info(&quot;Escribiendo los datos&quot;) if(!is.na(owner.to)){ flog.info(&quot;Otorgando ownership a %s&quot;, owner.to) dbSendQuery(con, paste0(&quot;alter table &quot;, long.name , &quot; owner to &quot;, owner.to, &quot;;&quot;)) } }, finally=dbDisconnect(con) # Nos desconectamos de la BD ) flog.info(&quot;Escritura finalizada&quot;) } # Función de ayuda normalizarNombres &lt;- function(column_names) { require(magrittr) gsub(&quot;\\\\s+&quot;, &quot; &quot;, stringr::str_trim(column_names)) %&gt;% gsub(&quot;^ *|(?&lt;= ) | *$&quot;, &quot;&quot;, ., perl=T) %&gt;% gsub(&#39;\\\\ |\\\\.&#39;, &#39;_&#39;, .) %&gt;% gsub(&quot;([a-z])([A-Z])&quot;, &quot;\\\\1_\\\\L\\\\2&quot;, ., perl = TRUE) %&gt;% gsub(&#39;ñ&#39;, &#39;n&#39;, .) %&gt;% iconv(., to=&#39;ASCII//TRANSLIT&#39;) %&gt;% tolower(.) } Se especifican en los parámetros el data.frame a escribir, una cadena de caracteres indicando el esquema en el que se escribirá la base, una cadena indicando el nombre de la tabla y es posible especificar qué dueño deberá asignarse para la base: ### POSTGRES df2sql(iris, &quot;public&quot;, &quot;iris&quot;, owner.to = &quot;usr&quot;) 5.1.12 rdata También es posible guardar objetos específicos del ambiente dentro de un formato especial con extensión rdata o RData. Esto es muy útil, por ejemplo, para guardar modelos u otros objetos y después poder utilizarlos en producción o en alguna aplicación que requiera un tiempo de respuesta bajo. Para escribirlos save(..., file = &quot;~/misdatos.rdata&quot;, ascii = FALSE, version = NULL, envir = parent.frame(), compress = isTRUE(!ascii), compression_level, eval.promises = TRUE, precheck = TRUE) Nota como ... pueden ser uno o más objetos de R. Para leerlos load(&quot;~/misdatos.rdata&quot;) Los objetos se cargarán al ambiente con los nombres con los que fueron guardados. Bibliografía "],
["transformacion-de-datos.html", "5.2 Transformación de datos", " 5.2 Transformación de datos Esta sección resume algunas de las funciones existentes para transformar datos en R. En particular, se revisan las transformaciones más comunes que se realizan sobre datos. En esta sección, se revisan las acciones implementadas en el paquete dplyr (Wickham and Francois, n.d.). En la figura 5.3 podemos ver la etapa del análisis de datos correspondiente. Figura 5.3: Transformación de datos (Grolemund and Wickham 2016, Introducción). Existen muchas maneras de transformar los datos y una gran cantidad de paquetes que implementan distintas funciones útiles para realizar esta tarea. En particular, resaltamos dplyr y data.table. En esta sección se ejemplifican todas las funciones que permiten hacer trabajo con datos que están implementadas en dplyr10 y en tidyr (H. Wickham 2016b). 5.2.1 Tareas comunes en la manipulación de datos Las funciones implementadas en este paquete están diseñadas para facilitar la transformación de datos. En general, la transformación de datos implica definir qué se hará con ellos, escribir un programa que realice esa tarea y ejecutarlo (Wickham and Francois, n.d., viñeta de introducción). dplyr y tidyr simplifican estos pasos al proveer de opciones limitadas consideradas como las tareas más comunes en la transformación de datos. Además, proveen de verbos simples que corresponden a funciones en R y que mapean directamente a estas tareas más comunes (ver Cuadro 5.1). Cuadro 5.1: Acciones y verbos comunes en la manipulación de datos (???). Acción Verbos Extracción de subconjuntos de observaciones. • filter: seleccionamos filas de acuerdo a los valores de las variables•distinct: elimina renglones duplicados•sample_frac: selecciona aleatoriamente una fracción de filas•sample_n: selecciona aleatoriamente \\(n\\) filas•slice: selecciona filas por posición•top_n: selecciona y ordena según una variable \\(n\\) entradas Extracción de subconjuntos de variables. •select: seleccionamos un subconjunto de las columnas utilizando los nombres de las variables Creación de resumenes de datos. •summarise: resume los datos en un valor único•summarise_each: aplica una función de resumen a cada columna•count: cuenta el número de filas con cada valor única de una variable Creación de nuevas variables. •mutate: genera nuevas variables a partir de las variables originales •mutate_each: aplica una función ventana a cada columna•transmute: genera una o más nuevas columnas eliminando las columnas originales Combinación de conjuntos de datos. •left_join: realiza un join conservando todas las observaciones de la primera tabla especificada•right_join: realiza un join conservando todas las observaciones de la segunda tabla especificada•inner_join: realiza un join conservando todas las observaciones que están en ambas tablas•full_join: realiza un join conservando todas las observaciones y valores de ambas tablas•semi_join: conserva todas las observaciones de la primera tabla que están en la segunda tabla•anti_join: conserva todas las observaciones de la primera tabla que no están en la segunda tabla•intersect: conserva observaciones que están tanto en la primera tabla como en la segunda•union: conserva observaciones que están en cualesquier tabla•setdiff: conserva observaciones de la primera tabla que no están en la segunda•bind_rows: une las filas de la segunda tabla a las de la primera•bind_cols: une las columnas de la segunda tabla a las de la primera Agrupar datos. •group_by: agrupa los datos según una o más variables•ungroup: elimina los grupos en un data frame Reorganizar datos (reshape data). •data_frame: combina vectores en un dataframe•arrange: Ordena las filas según una o más variables•rename: renombra columnas de un dataframe Dentro de tidyr hay más verbos útiles para reorganizar datos que se verán en la sección junto con los criterios de datos limpios que proporcionan un sustento para la conceptualización de la manipulación de datos eficiente en R. Todos estos verbos funcionan de la misma manera (tienen la misma estructura): El primer argumento de la función es un data.frame Los argumentos subsecuentes indican qué es lo que se debe hacer a ese data.frame Siempre regresa un data.frame A continuación, se ejemplifica el uso de los distintos verbos de la tabla 5.2. Para esto, utilizaremos los siguientes conjuntos de datos de muestra, todos disponibles en el paquete nycflights13 (H. Wickham 2016a). Se leerán desde archivo de texto plano para ejemplificar algunos elementos de la limpieza. Nota como utilizamos la función del paquete readr read_csv. Esta es una nueva implementación de read.csv pero mucho mas rápida. flights &lt;- read_csv(&quot;data/flights.csv&quot;) flights ## # A tibble: 227,496 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-01 12:00:00 14 0 1400 1500 0 -10 AA ## 2 2011-01-02 12:00:00 14 1 1401 1501 1 -9 AA ## 3 2011-01-03 12:00:00 13 52 1352 1502 -8 -8 AA ## 4 2011-01-04 12:00:00 14 3 1403 1513 3 3 AA ## 5 2011-01-05 12:00:00 14 5 1405 1507 5 -3 AA ## 6 2011-01-06 12:00:00 13 59 1359 1503 -1 -7 AA ## 7 2011-01-07 12:00:00 13 59 1359 1509 -1 -1 AA ## 8 2011-01-08 12:00:00 13 55 1355 1454 -5 -16 AA ## 9 2011-01-09 12:00:00 14 43 1443 1554 43 44 AA ## 10 2011-01-10 12:00:00 14 43 1443 1553 43 43 AA ## # ... with 227,486 more rows, and 6 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; planes &lt;- read_csv(&quot;data/planes.csv&quot;) planes ## # A tibble: 2,853 x 9 ## plane year mfr model no.eng no.seats speed engine type ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 N576AA 1991 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 2 N557AA 1993 MARZ BAR… KITFOX… 1 2 NA Recipr… Fixed win… ## 3 N403AA 1974 RAVEN S55A NA 1 60 None Balloon ## 4 N492AA 1989 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 5 N262AA 1985 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 6 N493AA 1989 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 7 N477AA 1988 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 8 N476AA 1988 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## 9 N504AA NA AUTHIER … TIERRA… 1 2 NA Recipr… Fixed win… ## 10 N565AA 1987 MCDONNEL… DC-9-8… 2 172 NA Turbo-… Fixed win… ## # ... with 2,843 more rows airports &lt;- read_csv(&quot;data/airports.csv&quot;) airports ## # A tibble: 3,376 x 7 ## iata airport city state country lat long ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 00M Thigpen Bay Springs MS USA 32.0 -89.2 ## 2 00R Livingston Municipal Livingston TX USA 30.7 -95.0 ## 3 00V Meadow Lake Colorado Springs CO USA 38.9 -105. ## 4 01G Perry-Warsaw Perry NY USA 42.7 -78.1 ## 5 01J Hilliard Airpark Hilliard FL USA 30.7 -81.9 ## 6 01M Tishomingo County Belmont MS USA 34.5 -88.2 ## 7 02A Gragg-Wade Clanton AL USA 32.9 -86.6 ## 8 02C Capitol Brookfield WI USA 43.1 -88.2 ## 9 02G Columbiana County East Liverpool OH USA 40.7 -80.6 ## 10 03D Memphis Memorial Memphis MO USA 40.4 -92.2 ## # ... with 3,366 more rows 5.2.2 Extracción de subconjuntos de observaciones 5.2.2.1 filter Ya habíamos visto muchas maneras de extraer datos específicos de una base de datos de acuerdo a condiciones lógicas impuestas en los valores de las filas de columnas especificas. filter nos permite poner tantas condiciones como queramos de manera muy fácil y entendible por cualquiera que lea nuestro código. Busquemos, por ejemplo, todos los vuelos hacia SFO u OAK filter(flights, dest == &quot;SFO&quot; | dest == &quot;OAK&quot;) ## # A tibble: 3,508 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-31 12:00:00 8 51 851 1052 1 -27 CO ## 2 2011-01-31 12:00:00 11 29 1129 1351 4 1 CO ## 3 2011-01-31 12:00:00 14 32 1432 1656 7 5 CO ## 4 2011-01-31 12:00:00 17 48 1748 2001 3 -4 CO ## 5 2011-01-31 12:00:00 21 43 2143 2338 50 24 CO ## 6 2011-01-31 12:00:00 7 29 729 1002 -1 2 CO ## 7 2011-01-31 12:00:00 15 58 1558 1812 -2 -8 CO ## 8 2011-01-30 12:00:00 9 35 935 1203 45 49 CO ## 9 2011-01-30 12:00:00 11 43 1143 1359 18 14 CO ## 10 2011-01-30 12:00:00 14 59 1459 1715 34 24 CO ## # ... with 3,498 more rows, and 6 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; Los vuelos con retraso mayor a 5 horas filter(flights, arr_delay &gt; 5) ## # A tibble: 77,848 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-09 12:00:00 14 43 1443 1554 43 44 AA ## 2 2011-01-10 12:00:00 14 43 1443 1553 43 43 AA ## 3 2011-01-11 12:00:00 14 29 1429 1539 29 29 AA ## 4 2011-01-17 12:00:00 15 30 1530 1634 90 84 AA ## 5 2011-01-20 12:00:00 15 7 1507 1622 67 72 AA ## 6 2011-01-31 12:00:00 14 41 1441 1553 41 43 AA ## 7 2011-01-13 12:00:00 7 22 722 841 2 6 AA ## 8 2011-01-16 12:00:00 7 43 743 843 23 8 AA ## 9 2011-01-17 12:00:00 7 24 724 842 4 7 AA ## 10 2011-01-24 12:00:00 7 31 731 904 11 29 AA ## # ... with 77,838 more rows, and 6 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; Podemos juntar las preguntas: vuelos con retraso mayor a 5 horas con destino a SFO o OAK filter(flights, dest == &quot;SFO&quot; | dest == &quot;OAK&quot;, arr_delay &gt; 5) ## # A tibble: 1,581 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-31 12:00:00 21 43 2143 2338 50 24 CO ## 2 2011-01-30 12:00:00 9 35 935 1203 45 49 CO ## 3 2011-01-30 12:00:00 11 43 1143 1359 18 14 CO ## 4 2011-01-30 12:00:00 14 59 1459 1715 34 24 CO ## 5 2011-01-30 12:00:00 17 49 1749 2011 4 6 CO ## 6 2011-01-30 12:00:00 19 31 1931 2159 41 41 CO ## 7 2011-01-30 12:00:00 21 0 2100 2320 10 9 CO ## 8 2011-01-29 12:00:00 8 52 852 1126 2 12 CO ## 9 2011-01-29 12:00:00 14 42 1442 1655 17 9 CO ## 10 2011-01-29 12:00:00 18 9 1809 2021 14 11 CO ## # ... with 1,571 more rows, and 6 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; 5.2.2.2 distinct Para eliminar duplicados, usamos la función distinct flights.dup &lt;- bind_rows(flights, flights) dim(flights.dup) ## [1] 454992 14 dim(distinct(flights.dup)) ## [1] 227496 14 rm(flights.dup) 5.2.2.3 sample_n, sample_frac, slice En ocasiones necesitamos extraer subconjuntos aleatorios de los datos, para ello podemos especificar el número de renglones que necesitamos (usando sample_n), el porcentaje de datos que deseamos (usando sample_frac) o las posiciones específicas de los datos que queremos (usando slice). set.seed(1099) # extraemos 10 datos en forma aleatoria sample_n(flights, size = 10) ## # A tibble: 10 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-05-29 12:00:00 12 3 1203 1304 -2 -16 AA ## 2 2011-05-30 12:00:00 13 43 1343 1432 -2 -8 WN ## 3 2011-07-20 12:00:00 18 21 1821 1956 10 20 CO ## 4 2011-07-10 12:00:00 13 5 1305 1355 5 0 WN ## 5 2011-06-17 12:00:00 11 30 1130 1228 5 3 WN ## 6 2011-12-03 12:00:00 7 59 759 851 -1 -9 WN ## 7 2011-06-12 12:00:00 9 19 919 1015 4 4 CO ## 8 2011-09-24 12:00:00 7 55 755 1124 -5 -5 XE ## 9 2011-04-19 12:00:00 17 48 1748 6 18 NA UA ## 10 2011-10-10 12:00:00 10 26 1026 1406 1 -1 CO ## # ... with 6 more variables: flight &lt;int&gt;, dest &lt;chr&gt;, plane &lt;chr&gt;, ## # cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; # Extraemos el 1% de los datos de flights sample_frac(flights, size = 0.01) ## # A tibble: 2,275 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-03-21 12:00:00 13 21 1321 1635 6 0 CO ## 2 2011-06-17 12:00:00 21 2 2102 2151 2 11 CO ## 3 2011-07-12 12:00:00 10 17 1017 1448 2 1 CO ## 4 2011-08-08 12:00:00 10 55 1055 1422 0 -3 WN ## 5 2011-09-13 12:00:00 19 1 1901 2314 -4 -5 CO ## 6 2011-03-06 12:00:00 18 32 1832 2044 -3 -11 CO ## 7 2011-05-09 12:00:00 6 53 653 843 18 -15 OO ## 8 2011-10-06 12:00:00 15 33 1533 1628 3 -7 WN ## 9 2011-06-17 12:00:00 13 50 1350 1545 0 2 OO ## 10 2011-11-01 12:00:00 14 30 1430 1601 5 1 CO ## # ... with 2,265 more rows, and 6 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; # extraemos las posiciones 100 a 110 slice(flights, 100:110) ## # A tibble: 11 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-12 12:00:00 16 31 1631 1739 1 -6 AA ## 2 2011-01-13 12:00:00 16 30 1630 1733 0 -12 AA ## 3 2011-01-14 12:00:00 16 29 1629 1734 -1 -11 AA ## 4 2011-01-15 12:00:00 16 32 1632 1736 2 -9 AA ## 5 2011-01-16 12:00:00 17 8 1708 1819 38 34 AA ## 6 2011-01-17 12:00:00 16 32 1632 1744 2 -1 AA ## 7 2011-01-18 12:00:00 16 25 1625 1740 -5 -5 AA ## 8 2011-01-19 12:00:00 16 29 1629 1731 -1 -14 AA ## 9 2011-01-20 12:00:00 16 41 1641 1752 11 7 AA ## 10 2011-01-21 12:00:00 16 38 1638 1746 8 1 AA ## 11 2011-01-22 12:00:00 16 23 1623 1742 -7 -3 AA ## # ... with 6 more variables: flight &lt;int&gt;, dest &lt;chr&gt;, plane &lt;chr&gt;, ## # cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; 5.2.2.4 top_n Podemos obtener los 5 vuelos con mayor retraso de salida: top_n(flights, 5, dep_delay) ## # A tibble: 5 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-06-21 12:00:00 23 34 2334 124 869 861 UA ## 2 2011-06-09 12:00:00 20 29 2029 2243 814 793 MQ ## 3 2011-08-01 12:00:00 1 56 156 452 981 957 CO ## 4 2011-11-08 12:00:00 7 21 721 948 931 918 MQ ## 5 2011-12-12 12:00:00 6 50 650 808 970 978 AA ## # ... with 6 more variables: flight &lt;int&gt;, dest &lt;chr&gt;, plane &lt;chr&gt;, ## # cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; O con el menor retraso de salida: top_n(flights, 5, desc(dep_delay)) ## # A tibble: 6 x 14 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-18 12:00:00 15 42 1542 1936 -18 -17 CO ## 2 2011-02-14 12:00:00 19 17 1917 2027 -23 -23 MQ ## 3 2011-04-10 12:00:00 21 1 2101 2206 -19 -12 XE ## 4 2011-08-03 12:00:00 17 41 1741 1810 -19 -40 XE ## 5 2011-10-04 12:00:00 14 38 1438 1813 -18 -31 EV ## 6 2011-12-24 12:00:00 11 12 1112 1314 -33 -25 OO ## # ... with 6 more variables: flight &lt;int&gt;, dest &lt;chr&gt;, plane &lt;chr&gt;, ## # cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt; 5.2.3 Extracción de subconjuntos de variables (select) Podemos ahora, mas fácilmente, quedarnos con únicamente ciertas variables. select esta implementado de tal manera que funciona nombrando las variables que se quieren utilizar. select(flights, flight, dest) ## # A tibble: 227,496 x 2 ## flight dest ## &lt;int&gt; &lt;chr&gt; ## 1 428 DFW ## 2 428 DFW ## 3 428 DFW ## 4 428 DFW ## 5 428 DFW ## 6 428 DFW ## 7 428 DFW ## 8 428 DFW ## 9 428 DFW ## 10 428 DFW ## # ... with 227,486 more rows También podemos especificar que queremos todas las variables menos algunas. select(flights, -date, -hour, -minute, -dep, -arr, -carrier, -flight) ## # A tibble: 227,496 x 7 ## dep_delay arr_delay dest plane cancelled time dist ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 -10 DFW N576AA 0 40 224 ## 2 1 -9 DFW N557AA 0 45 224 ## 3 -8 -8 DFW N541AA 0 48 224 ## 4 3 3 DFW N403AA 0 39 224 ## 5 5 -3 DFW N492AA 0 44 224 ## 6 -1 -7 DFW N262AA 0 45 224 ## 7 -1 -1 DFW N493AA 0 43 224 ## 8 -5 -16 DFW N477AA 0 40 224 ## 9 43 44 DFW N476AA 0 41 224 ## 10 43 43 DFW N504AA 0 45 224 ## # ... with 227,486 more rows Podemos pedir las variables que empiezan con algún caracter. select(flights, starts_with(&quot;d&quot;)) ## # A tibble: 227,496 x 5 ## date dep dep_delay dest dist ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2011-01-01 12:00:00 1400 0 DFW 224 ## 2 2011-01-02 12:00:00 1401 1 DFW 224 ## 3 2011-01-03 12:00:00 1352 -8 DFW 224 ## 4 2011-01-04 12:00:00 1403 3 DFW 224 ## 5 2011-01-05 12:00:00 1405 5 DFW 224 ## 6 2011-01-06 12:00:00 1359 -1 DFW 224 ## 7 2011-01-07 12:00:00 1359 -1 DFW 224 ## 8 2011-01-08 12:00:00 1355 -5 DFW 224 ## 9 2011-01-09 12:00:00 1443 43 DFW 224 ## 10 2011-01-10 12:00:00 1443 43 DFW 224 ## # ... with 227,486 more rows O las que contienen algún patrón select(flights, contains(&quot;dep&quot;)) ## # A tibble: 227,496 x 2 ## dep dep_delay ## &lt;int&gt; &lt;int&gt; ## 1 1400 0 ## 2 1401 1 ## 3 1352 -8 ## 4 1403 3 ## 5 1405 5 ## 6 1359 -1 ## 7 1359 -1 ## 8 1355 -5 ## 9 1443 43 ## 10 1443 43 ## # ... with 227,486 more rows Ejercicios Revisa la ayuda de select con ?select. Juega con la función starts_with(). ¿Qué variables empiezan con “de”? Juega con la función ends_with(). ¿Qué variables terminan con “delay”? Utiliza la base de datos iris como en el ejemplo de la ayuda. ¿Qué hace la función contains()? ¿Cómo es diferente de matches()? ¿Cómo obtienes todas las variables menos Petal.Width? 5.2.4 Creación de resumenes de datos Las funciones summarise, summarise_each y count permiten realizar resumenes para ciertas variables existentes o nuevas en los datos. 5.2.4.1 summarise Ahora, si queremos saber el promedio de velocidad de los vuelos podemos calcularlo fácilmente con summarise. flights$velocidad &lt;- flights$dist/flights$time summarise(flights, vel_prom = mean(velocidad, na.rm = T)) ## vel_prom ## 1 7.017055 Funciones resumen Pueden utilizarse junto con summarise cualesquiera función en R (por ejemplo: min, max, mean, median, var, sd) que realice agregaciones de vectores. Sin embargo, el paquete dplyr implementa varias funciones útiles adicionales como (???): first: extrae el primer valor de un vector last: extrae el último valor de un vector n: cuenta el número de valores en un vector n_distinct cuenta el número de valores único en un vector 5.2.4.2 summarise_each Podemos especificar una función a aplicar a variables específicas en un dataframe. Por ejemplo, extraer la media para las variables: date, dep_delay, arr_delay, time y dist. summarise_each(flights, funs(mean), date, dep_delay, arr_delay, time, dist) ## # A tibble: 1 x 5 ## date dep_delay arr_delay time dist ## &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2011-07-02 03:05:12 NA NA NA 788. Debido a que existen valores perdidos en variables como retraso de salida (dep_delay) y retrasos de llegada (arr_delay), debemos especificar la opción para no utilizar los NAs en la función. summarise_each(flights, funs(mean(., na.rm = T)), date, dep_delay , arr_delay, time, dist) ## # A tibble: 1 x 5 ## date dep_delay arr_delay time dist ## &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2011-07-02 03:05:12 9.44 7.09 108. 788. # opcion 2 mean_na &lt;- function(x){ mean(x, na.rm = T) } summarise_each(flights, funs(mean_na), date, dep_delay, arr_delay, time, dist) ## # A tibble: 1 x 5 ## date dep_delay arr_delay time dist ## &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2011-07-02 03:05:12 9.44 7.09 108. 788. 5.2.4.3 count Podemos contar los valores únicos en variables categóricas, por ejemplo, contar el número de vuelos por aerolínea: dplyr::count(flights, carrier, sort = T) ## # A tibble: 15 x 2 ## carrier n ## &lt;chr&gt; &lt;int&gt; ## 1 XE 73053 ## 2 CO 70032 ## 3 WN 45343 ## 4 OO 16061 ## 5 MQ 4648 ## 6 US 4082 ## 7 AA 3244 ## 8 DL 2641 ## 9 EV 2204 ## 10 FL 2139 ## 11 UA 2072 ## 12 F9 838 ## 13 B6 695 ## 14 AS 365 ## 15 YV 79 5.2.5 Creación de nuevas variables 5.2.5.1 mutate y transmute Muchas veces lo que se desea es generar nuevas variables utilizando funciones sobre las variables de la tabla. Por ejemplo, queremos saber cual fue el vuelo mas rápido. Para esto queremos calcular la velocidad promedio del vuelo. select(arrange(mutate(flights, velocidad = dist/time), desc(velocidad)), flight, dest, velocidad) ## # A tibble: 227,496 x 3 ## flight dest velocidad ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1646 AUS 12.7 ## 2 5229 MEM 11.2 ## 3 944 CLT 10.7 ## 4 4634 HOB 10.7 ## 5 500 IND 10.3 ## 6 106 EWR 10.1 ## 7 644 CLE 10.1 ## 8 1074 CLE 10.1 ## 9 1054 EWR 10.1 ## 10 1424 DCA 10.1 ## # ... with 227,486 more rows Esta manera de transformar a los datos (utilizando varios de los verbos) es confusa y difícil de leer. Es más sencillo utilizar el operador pipe11 de R implementado en el paquete magrittr, es decir, %&gt;% (Bache and Wickham 2014). flights2 &lt;- mutate(flights, velocidad = dist/time) %&gt;% arrange(., desc(velocidad)) %&gt;% select(., flight, dest, velocidad) flights2 ## # A tibble: 227,496 x 3 ## flight dest velocidad ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1646 AUS 12.7 ## 2 5229 MEM 11.2 ## 3 944 CLT 10.7 ## 4 4634 HOB 10.7 ## 5 500 IND 10.3 ## 6 106 EWR 10.1 ## 7 644 CLE 10.1 ## 8 1074 CLE 10.1 ## 9 1054 EWR 10.1 ## 10 1424 DCA 10.1 ## # ... with 227,486 more rows La lectura es mucho mas sencilla de esta forma pues se lee de manera secuencial las transformaciones que se están realizando a los datos: Agrego la columna de velocidad a la base de datos de flights, luego (operador pipe) Ordeno los vuelos en forma descendiente según su velocidad, luego Selecciono las variables de vuelo, destino y velocidad. Que el código sea entendible no es importante únicamente en el contexto del trabajo colaborativo pues muchas veces los lectores de su código serán ustedes en el futuro. transmute es muy similar a mutate pero elimina las variables que no fueron creadas por la función. dplyr::transmute(flights, velocidad = dist/time) %&gt;% arrange(., desc(velocidad)) ## # A tibble: 227,496 x 1 ## velocidad ## &lt;dbl&gt; ## 1 12.7 ## 2 11.2 ## 3 10.7 ## 4 10.7 ## 5 10.3 ## 6 10.1 ## 7 10.1 ## 8 10.1 ## 9 10.1 ## 10 10.1 ## # ... with 227,486 more rows Ejercicios ¿Cuáles son los 10 aviones-aerolíneas mas lentos? Utiliza el operador pipe, mutate, arrange y head. Utiliza la función str_sub dentro de stringr para extraer únicamente el día del campo date. Utiliza la función ymd del paquete lubridate para declarar date como una fecha (¡otra clase!). Utiliza las funciones paste0 del base y ymd_hm de lubridate para declarar date como un datetime. # Respuestas #1 mutate(flights, velocidad = dist/time) %&gt;% arrange(velocidad) %&gt;% head(10) %&gt;% select(plane, carrier, velocidad) # Más lindo, usando group_by y top_n: más específicamente el más # lento por carrier mutate(flights, velocidad = dist/time) %&gt;% group_by(carrier) %&gt;% arrange(velocidad) %&gt;% top_n(1) %&gt;% select(plane, carrier, velocidad) #2 mutate(flights, dia = stringr::str_sub(date, 9, 10)) %&gt;% select(date, dia) head(flights) # 3 mutate(flights, fecha = stringr::str_sub(date, 1, 10) , fecha = lubridate::ymd(fecha)) %&gt;% select(date, fecha) # 4 mutate(flights, fecha = lubridate::ymd_hms(date)) %&gt;% select(date, fecha) Funciones ventana window functions Dentro de mutate, se pueden utilizar otras funciones que realicen transformaciones sobre vectores que regresen un vector del mismo tamaño, así como funciones propias. Ahora bien, dplyr implementa otras funciones ventana como (???): lead: regresa todos los valores del vector movidos por una posición posterior lag: regresa todos los valores del vector movidos por una posición anterior dense_rank: rango sin huecos min_rank: rango especificando el criterio de mínimo para empates percent_rank: rango reescalado para estar entre 0 y 1 row_number: número de fila ntile: creación de \\(n\\) percentiles between: verifica si el valor está entre dos valores cume_dist: distribución acumulada cumall: para vectores lógicos, intersección de los valores al renglón i-ésimo cumany: para vectores lógicos, unión de los valores al renglón i-ésimo cummean: acumula la media Para mayor detalle, puede revisarse la viñeta “window-functions” en el paquete dplyr (Wickham and Francois, n.d.) con el comando vignette(“window-functions”, package \\(=\\) “dplyr”) 5.2.5.2 mutate_each Igual que con summarise_each, mutate_each permite especificar una transformación vía una función ventana para variables específicas. Por ejemplo, extraemos los deciles correspondientes para las variables tiempo (time) y distancia (dist). flights.m &lt;- mutate_each(flights, funs(ntile(., 10)), time, dist) table(flights.m$time) ## ## 1 2 3 4 5 6 7 8 9 10 ## 22388 22387 22388 22387 22387 22388 22387 22388 22387 22387 5.2.6 Combinación de conjuntos de datos (joins) Muchas veces la información se tiene repartida entre diferentes tablas pero es necesario juntar las variables de las diferentes observaciones en una sola tabla para modelarlas o describirlas. Es muy estándar, en el lenguaje SQL, el tipo de joins que se pueden utilizar. La figura 5.4 muestra un resumen del tipo de joins que pueden realizarse. Figura 5.4: Joins en el lenguaje SQL (Moffat 2009). El paquete dplyr implementa estos joins de manera natural, utilizando la lógica de SQL. inner_join: regresa todas las filas de x en donde hay valores correspondientes para y, junto con todas las columnas. left_join: regresa todas las filas de x, rellenando con NA para valores que no encontró en y. right_join: regresa todas las filas de y, rellenando con NA para valores que no encontró en y. full_join: regresa todas las filas y todas las columnas para x y y. Donde no hay valores en alguno de los dos, rellena con NA. semi_join: regresa todas las filas de x para las que hay valores en y regresando únicamente las columnas de x. anti_join: regresa todas las filas de x donde no hay valores en y, manteniendo solo las columnas de x. Ahora, supongamos que queremos saber la velocidad promedio de los aviones que tenemos en nuestros datos para todos sus vuelos. # base de aviones con velocidad vel_aviones &lt;- flights %&gt;% group_by(plane) %&gt;% dplyr::summarise(vel_prom = mean(dist/time, na.rm = T)) inner_join( planes, vel_aviones ) %&gt;% select(plane, year, vel_prom) %&gt;% arrange(desc(vel_prom)) ## # A tibble: 2,853 x 3 ## plane year vel_prom ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 N653JB 2007 9.33 ## 2 N709UW 1999 9.32 ## 3 N3744F 2001 9.07 ## 4 N3769L 2002 9.07 ## 5 N623JB 2005 9.04 ## 6 N607JB 2005 8.94 ## 7 N580JB 2003 8.87 ## 8 N658JB 2007 8.87 ## 9 N589JB 2004 8.81 ## 10 N760JB 2008 8.79 ## # ... with 2,843 more rows Ahora, queremos saber los destinos con mayores retrasos. destinos &lt;- flights %&gt;% group_by(dest) %&gt;% dplyr::summarise(retraso = mean(arr_delay, na.rm = T)) inner_join( airports, destinos, by = c(&quot;iata&quot; = &quot;dest&quot;) ) %&gt;% arrange(desc(retraso)) ## # A tibble: 114 x 8 ## iata airport city state country lat long retraso ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ANC Ted Stevens Anchor… Anchorage AK USA 61.2 -150. 26.1 ## 2 CID Eastern Iowa Cedar Rap… IA USA 41.9 -91.7 17.8 ## 3 DSM Des Moines Interna… Des Moines IA USA 41.5 -93.7 16.0 ## 4 SFO San Francisco Inte… San Franc… CA USA 37.6 -122. 14.9 ## 5 BPT Southeast Texas Re… Beaumont/… TX USA 30.0 -94.0 14.3 ## 6 GRR Kent County Intern… Grand Rap… MI USA 42.9 -85.5 13.7 ## 7 DAY James M Cox Dayton… Dayton OH USA 39.9 -84.2 13.7 ## 8 VPS Eglin Air Force Ba… Valparaiso FL USA 30.5 -86.5 12.5 ## 9 SAV Savannah Internati… Savannah GA USA 32.1 -81.2 12.3 ## 10 RIC Richmond Internati… Richmond VA USA 37.5 -77.3 12.3 ## # ... with 104 more rows 5.2.7 Agrupar datos 5.2.7.1 group_by Un verbo muy poderoso es el group_by. Es por este tipo de verbos que resultó necesario generar un objeto diferente al tradicional dataframe. Básicamente, el tbl_df es capaz de guardar agrupamientos específicos sobre los cuáles puede hacer funciones ventana (window functions) o resúmenes sobre los grupos que se definen. 5.2.7.1.1 Ejemplo Los datos de vuelos se agrupan naturalmente sobre las aerolíneas. flights.g &lt;- flights %&gt;% group_by(., carrier) flights.g ## # A tibble: 227,496 x 15 ## # Groups: carrier [15] ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-01 12:00:00 14 0 1400 1500 0 -10 AA ## 2 2011-01-02 12:00:00 14 1 1401 1501 1 -9 AA ## 3 2011-01-03 12:00:00 13 52 1352 1502 -8 -8 AA ## 4 2011-01-04 12:00:00 14 3 1403 1513 3 3 AA ## 5 2011-01-05 12:00:00 14 5 1405 1507 5 -3 AA ## 6 2011-01-06 12:00:00 13 59 1359 1503 -1 -7 AA ## 7 2011-01-07 12:00:00 13 59 1359 1509 -1 -1 AA ## 8 2011-01-08 12:00:00 13 55 1355 1454 -5 -16 AA ## 9 2011-01-09 12:00:00 14 43 1443 1554 43 44 AA ## 10 2011-01-10 12:00:00 14 43 1443 1553 43 43 AA ## # ... with 227,486 more rows, and 7 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt;, ## # velocidad &lt;dbl&gt; Ejercicios Busca en la ayuda la función top_n. Utilízala, junto con group_by, arrange y summarise para extraer los 10 aviones por aerolínea con el menor promedio de velocidad. ¿Cuáles son los aeropuertos con mayor promedio de retraso en la salida? ¿Cuáles son los aeropuertos con mayor promedio de retraso en las llegadas? # Respuestas # 1 ?top_n # 2 flights %&gt;% mutate(velocidad = dist/time) %&gt;% group_by(plane, carrier) %&gt;% summarise(vel_prom = mean(velocidad, na.rm = T)) %&gt;% ungroup() %&gt;% group_by(carrier) %&gt;% arrange(vel_prom) %&gt;% top_n(1) # 3 flights %&gt;% group_by(dest) %&gt;% summarise(arr_delay = mean(arr_delay, na.rm = T)) %&gt;% arrange(desc(arr_delay)) %&gt;% head(10) Afectación de otros verbos por group_by El establecer grupos puede conjugarse con los demás verbos implementados en el paquete dplyr y los afecta de diferente manera (Wickham and Francois, n.d., viñeta de introducción): select realiza la misma operación pero retiene siempre las variables de agrupación. arrange realiza el arreglo según las variables especificadas pero ordena primero según los grupos. mutate y filter realizan las operación dentro de los grupos definidos y son más útiles cuando se utilizan en conjunción a las funciones ventana. sample_n y sample_frac extraen el número o fracción de observaciones según el número o fracción de filas en cada grupo. summarise en conjunción con group_by llevan acabo el paradigma split (por las variables definidas en el group_by), apply (por las funciones especificadas en el summarise) y lo combinan en un dataframe. 5.2.7.2 ungroup La función group_by agrega la clase grouped_df, así como atributos al objeto. g.df &lt;- group_by(flights, plane, carrier) class(g.df) ## [1] &quot;grouped_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; names(attributes(g.df)) ## [1] &quot;names&quot; &quot;row.names&quot; &quot;spec&quot; ## [4] &quot;class&quot; &quot;vars&quot; &quot;drop&quot; ## [7] &quot;indices&quot; &quot;group_sizes&quot; &quot;biggest_group_size&quot; ## [10] &quot;labels&quot; class(flights) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; names(attributes(flights)) ## [1] &quot;names&quot; &quot;row.names&quot; &quot;spec&quot; &quot;class&quot; La función ungroup los elimina: class(ungroup(g.df)) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; names(attributes(ungroup(g.df))) ## [1] &quot;class&quot; &quot;names&quot; &quot;row.names&quot; &quot;spec&quot; Ejercicios ¿Cuáles son los aeropuertos que SI están en la base de destinos? ¿Cuáles son los aeropuertos que NO están en la base de destinos? Realiza un resumen de los vuelos por aeropuerto para varias variables con la función summarise. Utiliza la función inner_join para pegar la tablas de resumen creada en el paso anterior a la tabla airports Realiza un resumen de los vuelos por avión para varias variables con la función summarise. Utiliza la función left_join para pegar la tablas de resumen creada en el paso anterior a la tabla planes Extrae el porcentaje de vuelos cancelados por aerolínea cada año y el porcentaje de vuelos retrasados por aerolínea cada año. # Respuestas # 1 semi_join(airports, flights, by = c(&quot;iata&quot; = &quot;dest&quot;)) # 2 anti_join(airports, flights, by = c(&quot;iata&quot; = &quot;dest&quot;)) # 3 res.vuelos &lt;- flights %&gt;% group_by(dest) %&gt;% summarise( flights = n() , planes = n_distinct(plane) , carriers = n_distinct(carrier) , cancelled_flights = sum(cancelled, na.rm = T) , dep_delay_mean = mean(dep_delay, na.rm = T) ) # 4 airports_flights &lt;- inner_join(airports, res.vuelos , by = c(&quot;iata&quot; = &quot;dest&quot;)) # 5 res.aviones &lt;- flights %&gt;% group_by(plane) %&gt;% summarise( flights = n() , carriers = n_distinct(carrier) , cancelled_flights = sum(cancelled, na.rm = T) , dep_delay_mean = mean(dep_delay, na.rm = T) , arr_delay_mean = mean(arr_delay, na.rm = T) , dist_mean = mean(dist, na.rm = T) , vel_mean = mean(dist/time, na.rm = T) ) # 6 planes_flights &lt;- left_join(planes, res.aviones) # 7 flights %&gt;% mutate(anio = lubridate::year(date)) %&gt;% group_by(carrier, anio) %&gt;% summarise( vuelos.anuales = n() , cancelados = sum(cancelled, na.rm = T)/vuelos.anuales * 100 , retrasados = sum(dep_delay &gt; 0, na.rm = T)/vuelos.anuales * 100 ) %&gt;% ungroup() 5.2.8 Reorganizar datos 5.2.8.1 data_frame Al igual que la función data.frame, esta función permite generar un data frame a partir de vectores: df &lt;- data_frame( x = rnorm(100) , y = runif(100) ) class(df) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; df &lt;- data.frame( x = rnorm(100) , y = runif(100) ) class(df) ## [1] &quot;data.frame&quot; La clase del objeto generado por la función data_frame es un tibble mientras que la función del base data.frame es de clase data.frame. 5.2.8.2 arrange order habíamos visto que es la implementación del base para ordenar vectores o en su defecto, dataframes de acuerdo a valores de vectores en esta. Sin embargo, es engorrosa la manera de llamarlo. Podemos arreglar los valores de las tablas, fácilmente con arrange. Por ejemplo, podemos ver los 5 vuelos con mayor retraso de llegada. head(arrange(flights, desc(arr_delay)), n=5) ## # A tibble: 5 x 15 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-12-12 12:00:00 6 50 650 808 970 978 AA ## 2 2011-08-01 12:00:00 1 56 156 452 981 957 CO ## 3 2011-11-08 12:00:00 7 21 721 948 931 918 MQ ## 4 2011-06-21 12:00:00 23 34 2334 124 869 861 UA ## 5 2011-05-20 12:00:00 8 58 858 1027 803 822 MQ ## # ... with 7 more variables: flight &lt;int&gt;, dest &lt;chr&gt;, plane &lt;chr&gt;, ## # cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt;, velocidad &lt;dbl&gt; O los 5 con menor atraso de llegada head(arrange(flights, arr_delay), n=5) ## # A tibble: 5 x 15 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-07-03 12:00:00 19 14 1914 2039 -1 -70 XE ## 2 2011-12-25 12:00:00 7 41 741 926 -4 -57 OO ## 3 2011-08-21 12:00:00 9 35 935 1039 -10 -56 OO ## 4 2011-08-31 12:00:00 9 34 934 1039 -11 -56 OO ## 5 2011-08-26 12:00:00 21 7 2107 2205 -3 -55 OO ## # ... with 7 more variables: flight &lt;int&gt;, dest &lt;chr&gt;, plane &lt;chr&gt;, ## # cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt;, velocidad &lt;dbl&gt; Podemos arreglar primero por destino y luego por retraso de llegada. arrange(flights, dest, arr_delay) ## # A tibble: 227,496 x 15 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-11-25 12:00:00 12 55 1255 1344 0 -26 WN ## 2 2011-01-12 12:00:00 8 56 856 1000 -14 -25 OO ## 3 2011-12-25 12:00:00 19 50 1950 2045 -5 -25 WN ## 4 2011-03-16 12:00:00 17 39 1739 1841 -8 -24 OO ## 5 2011-03-17 12:00:00 11 17 1117 1214 -3 -24 XE ## 6 2011-12-30 12:00:00 17 27 1727 1828 -3 -24 OO ## 7 2011-01-29 12:00:00 17 32 1732 1837 -3 -23 CO ## 8 2011-05-29 12:00:00 18 11 1811 1902 -4 -23 WN ## 9 2011-02-13 12:00:00 17 34 1734 1843 -1 -22 CO ## 10 2011-04-17 12:00:00 17 18 1718 1818 -7 -22 WN ## # ... with 227,486 more rows, and 7 more variables: flight &lt;int&gt;, ## # dest &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt;, ## # velocidad &lt;dbl&gt; 5.2.8.3 rename Es posible renombrar las variables por nombre utilizando la función rename: dplyr::rename(flights, iata = dest) ## # A tibble: 227,496 x 15 ## date hour minute dep arr dep_delay arr_delay carrier ## &lt;dttm&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 2011-01-01 12:00:00 14 0 1400 1500 0 -10 AA ## 2 2011-01-02 12:00:00 14 1 1401 1501 1 -9 AA ## 3 2011-01-03 12:00:00 13 52 1352 1502 -8 -8 AA ## 4 2011-01-04 12:00:00 14 3 1403 1513 3 3 AA ## 5 2011-01-05 12:00:00 14 5 1405 1507 5 -3 AA ## 6 2011-01-06 12:00:00 13 59 1359 1503 -1 -7 AA ## 7 2011-01-07 12:00:00 13 59 1359 1509 -1 -1 AA ## 8 2011-01-08 12:00:00 13 55 1355 1454 -5 -16 AA ## 9 2011-01-09 12:00:00 14 43 1443 1554 43 44 AA ## 10 2011-01-10 12:00:00 14 43 1443 1553 43 43 AA ## # ... with 227,486 more rows, and 7 more variables: flight &lt;int&gt;, ## # iata &lt;chr&gt;, plane &lt;chr&gt;, cancelled &lt;int&gt;, time &lt;int&gt;, dist &lt;int&gt;, ## # velocidad &lt;dbl&gt; Bibliografía "],
["datos-limpios.html", "5.3 Datos limpios", " 5.3 Datos limpios Esta sección resume algunas de las funciones existentes para limpiar datos de distintos formatos a R. En particular, se utiliza la conceptualización de datos limpios presentada en Wickham and others (2014) e implementada en el paquete tidyr (H. Wickham 2016b). En la figura podemos ver la etapa del análisis de datos correspondiente. Figura 5.5: Limpieza de datos (Grolemund and Wickham 2016, Introducción). Mucho del esfuerzo en analítica lidia con la limpieza de datos. Tomar datos de diferentes fuentes y poderlas poner en la forma en la que uno los necesita para realizar analítica toma mucho tiempo y esfuerzo. Existen herramientas que permiten que esta parte sea más fácil y eficiente. Entre éstas se encuentran los criterios de datos limpios. Los conjuntos de datos limpios (tidy datasets) permiten manipularlos fácilmente, modelarlos y visualizarlos. Aunque funcionan independientemente del lenguaje utilizado, son particularmente útiles en R pues éste es un lenguaje pensado para estructuras de datos tabulares; mismas que son más fácilmente explotables si se usan datos limpios (Wickham and Grolemund 2016). Los datos limpios tienen una estructura específica: cada variable es una columna, cada observación una fila y tipo de unidad observacional forma una tabla12. 5.3.0.1 Datos limpios en el procesamiento de datos Esta actividad incluye una gran cantidad de elementos: revisión de valores atípicos, extracción de variables de cadenas en datos no estructurados, imputación de valores perdidos. Los datos limpios son tan solo un subconjunto de este proceso y lidian con el cómo estructurar los datos de manera que se facilite el análisis. Los criterios de datos limpios están diseñados para facilitar la exploración inicial y el análisis de datos, así como simplificar el desarrollo de herramientas para el análisis de datos que trabajen bien con datos limpios. Los criterios de datos limpios están muy relacionados a los de las bases de datos relacionales y, por ende, al álgebra relacional de Codd (Wickham and others 2014). Sin embargo, se expresan y enmarcan en lenguaje que le es familiar a estadísticos. Están creados para lidiar con conjuntos de datos que se encuentran en el mundo real pues -aunque parecen simples- es difícil encontrar datos limpios de origen. Los criterios de datos limpios proporcionan un marco mental a través del cual la intuición es explícita, es decir, proporcionan una manera estándar de ligar la estructura de un dataset (es decir su layout físico) con su semántica (su significado). 5.3.0.1.1 Estructura de datos: un ejemplo La mayoría de los datos estadísticos están conformados por tablas rectangulares compuestas por filas y columnas. Las columnas casi siempre están etiquetadas (colnames) y las filas a veces lo están. Tomamos el ejemplo de datos de la figura en donde se presentan datos de un experimento13. La tabla contiene dos columnas y tres filas, ambas etiquetadas. Figura 5.6: Típica presentación de datos. Podemos estructurar los datos de diferentes maneras pero la abstracción de filas y columnas solamente nos permite pensar en la representación transpuesta que se muestra en la figura . El diseño cambia pero los datos son los mismos. Además de la apariencia, deberíamos de poder describir la semántica -el significado- de los valores que se muestran en una tabla (Wickham and others 2014, pág. 3) pero la abstracción de filas y columnas no da para más. Figura 5.7: Mismos datos que en ef{fig:estructura} pero traspuestos. 5.3.0.2 Semántica Un conjunto de datos es una colección de valores (normalmente cuantitativos/números o cualitativos/caracteres). Los valores se organizan de dos maneras: cada valor pertenece simultáneamente a una variable y a una observación. Una variable contiene todos los valores de una medida y del mismo atributo subyacente (por ejemplo, temperatura, duración, altura, latitud) a través de unidades. Una observación, en cambio, contiene todos los valores medidos para la misma unidad (por ejemplo, una persona, un día, un municipio) a través de distintos atributos. Los mismos datos en las figuras y los pensamos ahora en estos términos. Tenemos 3 variables: persona con tres posibles valores (John, Jane, Mary) tratamiento con dos posibles valores (a o b) resultado con 6 valores (-, 16, 3, 2, 11, 1) El diseño del experimento mismo nos habla de la estructura de las observaciones y los posibles valores que pueden tomar. Por ejemplo, en este caso el valor perdido nos dice que, por diseño, se debió de capturar esta variable pero no se hizo (por eso es importante guardarlo como tal)14. En la figura se muestran los mismos datos que antes pero pensados tal que las variables son columnas y las observaciones (en este caso, cada punto en el diseño experimental) son filas. Figura 5.8: Observaciones son filas, variables columnas. Normalmente, es fácil determinar cuáles son las observaciones y cuáles son las variables en los distintos casos, pero es difícil dar una definición en forma precisa. Por ejemplo, si tienes teléfonos de casa y celulares, se pueden considerar como dos variables distintas en muchos contextos pero en prevención de fraude necesitas una variable que guarde el tipo de teléfono y otra en la que se guarde el número pues el uso regular del mismo número de teléfono por parte de la misma persona puede ayudar a detectarlo. En general, es más fácil describir las relaciones funcionales entre las variables que entre las filas pues las puedes operar fácilmente: por ejemplo, el radio entre dos variables, una combinación lineal de varias variables. También es más fácil hacer comparaciones entre grupos de observaciones que entre columnas: la suma, el promedio, la varianza, la moda (Wickham and others 2014, pág. 4). Las observaciones, por su parte, son más complejas pues normalmente se enmarcan en un análisis específico que se desea realizar con los datos y existen varios niveles. Por ejemplo, en un análisis de ingreso podemos tener datos sociodemográficos de los individuos, datos geográficos del lugar en el que viven, datos macroeconómicos del tiempo específico, datos de la familia del individuo, datos del trabajo del individuo, entre otros. 5.3.1 Datos limpios Éstos mapean de forma estándar el significado y la estructura de los datos. Un conjunto de datos se considera sucio o limpio dependiendo de cómo las filas, columnas y tablas mapean a observaciones, variables y tipos. En datos limpios: Cada variable es una columna. Cada observación es una fila. Cada tipo de unidad observacional es una tabla / cada valor tiene su celda. En la figura podemos ver estos tres elementos de los datos limpios y cómo se representan en un dataframe. Figura 5.9: Ejemplificación de datos limpios (Wickham and Grolemund 2016, sección Data Tidying). Esto equivale a la tercera forma normal de Codd (Wickham and others 2014, pág. 4) enfocado a un solo conjunto de datos y no a datos conectados como en bases relacionales. Los datos sucios son cualquier otro tipo de manera de organizar los datos. La tabla corresponde a datos limpios: cada fila es una observación, es decir, el resultado de un tratamiento a una persona. Cada columna es una variable. Solo tenemos un tipo de unidad observacional, es decir, cada renglón es una unidad del diseño experimental. Con los datos así ordenados, suele ser más fácil extraer datos que, por ejemplo, en Tabla . Los datos limpios permiten hacerle preguntas a los datos de manera simple y sistemática. En particular, es una estructura muy útil para programación vectorizada como la que R tiene (el ejercicio 5) porque la forma en la que almacenamos los datos se asegura que valores para diferentes variables de la misma observación siempre están apareados. Por convención, las variables se acomodan de una forma particular. Las variables fijas (en este ejemplo, las propias al diseño experimental) van primero y posteriormente las variables medidas. Ordenamos éstas de forma que las que están relacionadas sean contiguas. 5.3.2 De sucio a limpio Los conjuntos de datos normalmente no cumplen con estos criterios. Es raro obtener un conjunto de datos con el cuál podemos trabajar de manera inmediata. Los 5 problemas más comunes para llevar datos sucios a limpios (Wickham and others 2014, pág. 5) son: Los nombres de las columnas son valores, no nombres de variables. Múltiples variables se encuentran en la misma columna. Las variables están guardadas tanto en filas como en columnas. Muchos tipos de unidad observacional se encuentran en la misma tabla. Una sola unidad observacional se guardó en varias tablas. Estos problemas pueden ser resueltos con las funciones implementadas en el paquete tidyr: gather, spread, separate y unite. 5.3.2.1 Los nombres de las columnas son valores, no nombres de variables La tabla muestra datos sucios con este problema. La base acompaña al paquete tidyr (H. Wickham 2016b) y es una muestra de los datos del reporte sobre tuberculosis de la organización mundial de la salud. Contiene observaciones anuales por país para casos de tuberculosis según distintos grupos. La descripción de todas las variables se puede ver tecleando ?who Dentro de un reporte, la representación que se tiene de las variables tiene sentido. Por ejemplo, en la tabla vemos los casos de tuberculosis para distintos grupos de edad de hombres en México para cierto tipo de diagnóstico. En las columnas tenemos varias variables: método de diagnóstico, género y categorías de edad. Para arreglarlo, necesitamos juntar (gather) las columnas con valores de variables en una sola columna que contenga esos nombres como valores. En otras palabras, debemos convertir de la columna 5 en adelante en filas. Con el paquete tidyr esto se puede realizar en forma fácil con el comando gather de manera que obtenemos un dataframe como el que se muestra en la tabla . junta &lt;- tidyr::gather(who, key = variables, value = casos , -country, -iso2, -iso3, -year, na.rm = T) Los parámetros que recibe la función gather son (al menos): El data.frame como primer parámetro. La llave (parámetro key) será el nombre que tomará la variable con los nombres de las columnas a juntar. El valor (parámetro value) es el nombre de la variable que contendrá los valores correspondientes a cada valor (el diagnóstico \\(i-ésimo\\), el \\(j-ésimo\\) género y el \\(k-ésimo\\) grupo de edad). Al último, especificamos las variables que NO se deben de juntar (en este caso: el país, iso2, iso3 y el año). Hay parámetros opcionales en la función. Para estos datos en particular, por ejemplo, es conveniente remover los grupos para los que no se tiene el dato con el parámetro na.rm = TRUE. # Creamos los datos df &lt;- data.frame( sujetos = LETTERS[1:16], grupo = sample(c(&quot;control&quot;, &quot;tratamiento&quot;), size = 16, replace = T, prob = c(0.5, 0.5)) # , meses = as.vector(sapply(paste0(&quot;mes&quot;,1:12), rep, 16)) ) m &lt;- t(sapply(runif(16, 16, 35), FUN = function(x){cumsum(c(x, rnorm(11, mean = 0.5, sd = 1)))})) colnames(m) &lt;- paste0(&quot;mes&quot;,1:12) df &lt;- cbind(df, m) # Respuesta: opción 1 tidyr::gather(df, key = mes, value = IMC, -sujetos, -grupo) # opción 2 tidyr::gather(df, key = mes, value = IMC, mes1:mes12) 5.3.2.2 Múltiples variables se encuentran en la misma columna Otra forma de datos sucios es cuando una columna con nombres de variables tiene realmente varias variables dentro del nombre. Si regresamos al ejemplo de la sección anterior, podemos notar que todavía no se tienen datos limpios. Primero, notamos una redundancia: todos los valores tienen el sufijo “new_” o “new” pero éste no tiene significado. Eliminamos ese pedazo de texto de los valores con la función gsub. Segundo, debemos extraer los valores de las variables método de diagnóstico, género y categoría de edad de la columna que acabamos de construir (que llamamos “variables”). En la descripción de las variables (teclea ?who) se describen a los títulos de las columnas (que ahora están guardados en la variable variables) tales que contienen como prefijo “new_”, seguido del diagnóstico que puede ser de dos o tres caracteres, “_f&quot; para mujeres o “_m&quot; para hombres y, por último, el rango de edad. Para eso, utilizamos la función extract del paquete tidyr. A esta función, debemos decirle cuál es el nombre de la variable que contiene varios valores (parámetro col), los nuevos nombres de columnas (parámetro into) y la expresión regular con la que irá capturando los pedazos y asignándolos a la columna correcta (parámetro regex). limpios &lt;- junta %&gt;% mutate(variables = gsub(&quot;new_|new&quot;, &quot;&quot;, variables)) %&gt;% tidyr::extract(., col = variables , into = c(&quot;diagnostico&quot;, &quot;genero&quot;, &quot;edad&quot;) , regex = &quot;([[:alnum:]]+)_([a-z])([[0-9]]+)&quot;) Por último, se deben limpiar las categorías de edad. En este caso, se decide volverlos un factor con las categorías ordenadas por los grupos de edad existentes en la base: limpios %&lt;&gt;% mutate( edad = factor(edad, levels = c(&quot;014&quot;, &quot;1524&quot;, &quot;2534&quot;, &quot;3544&quot; , &quot;4554&quot;, &quot;5564&quot;, &quot;65&quot;) , labels = c(&quot;0-14&quot;, &quot;15-24&quot;, &quot;25-34&quot;, &quot;35-44&quot; , &quot;45-54&quot;, &quot;55-64&quot;, &quot;65&gt;&quot;) , ordered = T) ) De esta forma, obtenemos los datos como se ven en la tabla donde tenemos una variable para el método de diagnóstico, una para el género, otra para la edad y una última con el número de casos observados. # Respuestas # Generamos los datos pob &lt;- tibble( id = 1:1000 , variables = paste0( sample(x = c(&#39;f&#39;, &#39;m&#39;), size = 1000, replace = T) , &quot;_&quot; , floor(runif(1000, 45, 99)) , &quot;_&quot; , floor(runif(1000, 50, 190)) ) ) # Utilizamos separate para generar las variables: # sexo, año de nacimiento y altura pob.tidy &lt;- pob %&gt;% separate(col = variables , into = c(&quot;sexo&quot;, &quot;anio_nac&quot;, &quot;altura&quot;), sep = &quot;_&quot;) # Pasamos a enteros las variables anio de nac y altura pob.tidy %&lt;&gt;% mutate_each(funs(as.integer), anio_nac, altura) pob.tidy 5.3.2.3 Las variables están guardadas tanto en filas como en columnas Uno de los problemas más difíciles es cuando las variables están tanto en filas como en columnas. Para ejemplificar este problema, se muestran los datos de temperatura máxima y mínima en algunas zonas de México (H. Wickham 2014b, archivo: data/weather.txt). Los datos que limpiaremos se ven en la tabla . Como se puede ver, tenemos valores del día del mes de la observación como nombres de variables: d1 (día 1), d2 (día 2), etc. Esto es homólogo al problema 1 visto anteriormente. También tenemos variables en las filas: la temperatura máxima y la temperatura mínima deberían ser el nombre de las columnas. Para limpiar, lo primero que debemos hacer es juntar los días (que son valores de la variable día) en una sola columna. Después utilizamos la nueva variable para crear la fecha. Así, obtenemos la tabla , a partir de los datos en el dataframe raw. # Tidy # Primero, juntamos la variable dias clean1 &lt;- tidyr::gather(raw, key = variable, value = value, d1:d31 , na.rm = T) # Después, generamos la variable día y fecha clean1$day &lt;- as.integer(str_replace(clean1$variable, &quot;d&quot;, &quot;&quot;)) clean1$date &lt;- as.Date(ISOdate(clean1$year, clean1$month, clean1$day)) # Seleccionamos las variables limpias y ordenamos clean1 &lt;- dplyr::select_(clean1, &quot;id&quot;, &quot;date&quot;, &quot;element&quot;, &quot;value&quot;) %&gt;% dplyr::arrange(date, element) El segundo paso es transformar la variable element en dos columnas pues, en realidad, almacena dos variables: temperatura máxima y mínima. # Las temperaturas van a columnas clean2 &lt;- tidyr::spread(clean1, key = element, value = value) En este caso, se utilizó la función spread del paquete tidyr. Esta función realiza una especie de inverso a la operación que hace gather. En lugar de juntar nombres de variables, utiliza los valores de una variable como nombres de columnas (parámetro key) y rellena apropiadamente las celdas con los valores de otra variable (parámetro value). Los demás parámetros son opcionales y, por ejemplo, en lugar de tener un parámetro para especificar qué hacer con los NA (en gather: na.rm), en este caso pide el parámetro fill cuyo default es NA pero, en algunos casos, es más apropiado insertar otro valor para rellenar valores de celdas en donde no había un valor correspondiente. 5.3.2.4 Muchos tipos de unidad observacional se encuentran en la misma tabla En ocasiones las bases de datos involucran diferentes tipos de unidad observacional. Para tener datos limpios, cada unidad observacional debe estar almacenada en su propia tabla. Para este ejemplo, utilizamos la base de datos billboard (H. Wickham 2014b, archivo: data/billboard.csv) billboard &lt;- readr::read_csv(&quot;tidyr_datasets/billboard.csv&quot;) billboard_long &lt;- gather(billboard, week, rank, x1st.week:x76th.week , na.rm = TRUE) billboard_tidy &lt;- billboard_long %&gt;% mutate( week = extract_numeric(week), date = as.Date(date.entered) + 7 * (week - 1)) %&gt;% select(-date.entered) head(billboard_tidy) ## # A tibble: 6 x 9 ## year artist.inverted track time genre date.peaked week rank ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;tim&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2000 Destiny&#39;s Child Inde… 03:38 Rock 2000-11-18 1 78 ## 2 2000 Santana Mari… 04:18 Rock 2000-04-08 1 15 ## 3 2000 Savage Garden I Kn… 04:07 Rock 2000-01-29 1 71 ## 4 2000 Madonna Music 03:45 Rock 2000-09-16 1 41 ## 5 2000 Aguilera, Chri… Come… 03:38 Rock 2000-10-14 1 57 ## 6 2000 Janet Does… 04:17 Rock 2000-08-26 1 59 ## # ... with 1 more variable: date &lt;date&gt; # Respuesta # Tenemos por un lado una unidad observacional: las características de la # canción. # Por el otro tenemos otra unidad observacional: las posiciones que tuvieron # las canciones en cada semana. Debemos separar las unidades observacionales, esto significa separar la base de datos en dos: la tabla canciones que almacena artista, nombre de la canción y duración; la tabla posiciones que almacena el ranking de la canción en cada semana. canciones &lt;- billboard_tidy %&gt;% select(artist.inverted, track, year, time) %&gt;% unique() %&gt;% arrange(artist.inverted) %&gt;% mutate(song_id = row_number(artist.inverted)) head(canciones, 5) ## # A tibble: 5 x 5 ## artist.inverted track year time song_id ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;tim&gt; &lt;int&gt; ## 1 2Ge+her The Hardest Part Of Breaking Up (Is… 2000 03:15 1 ## 2 2 Pac Baby Don&#39;t Cry (Keep Ya Head Up II) 2000 04:22 2 ## 3 3 Doors Down Kryptonite 2000 03:53 3 ## 4 3 Doors Down Loser 2000 04:24 4 ## 5 504 Boyz Wobble Wobble 2000 03:35 5 posiciones &lt;- billboard_tidy %&gt;% left_join(canciones, c(&quot;artist.inverted&quot;, &quot;track&quot;, &quot;year&quot;, &quot;time&quot;)) %&gt;% select(song_id, date, week, rank) %&gt;% arrange(song_id, date) %&gt;% tbl_df posiciones ## # A tibble: 5,307 x 4 ## song_id date week rank ## &lt;int&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 2000-09-02 1 91 ## 2 1 2000-09-09 2 87 ## 3 1 2000-09-16 3 92 ## 4 2 2000-02-26 1 87 ## 5 2 2000-03-04 2 82 ## 6 2 2000-03-11 3 72 ## 7 2 2000-03-18 4 77 ## 8 2 2000-03-25 5 87 ## 9 2 2000-04-01 6 94 ## 10 2 2000-04-08 7 99 ## # ... with 5,297 more rows 5.3.2.5 Una sola unidad observarcional se guardó en varias tablas Este ejemplo y datos se toman de Ortiz (2015). Es común que los valores sobre una misma unidad observacional estén separados en varios archivos. Muchas veces, cada archivo es una variable, e.g. el mes o el nombre del paciente, etc. Para limpiar estos datos debemos: Leemos los archivos en una lista de tablas. Para cada tabla agregamos una columna que registra el nombre del archivo original. Combinamos las tablas en un solo dataframe. La carpeta tidyr_datasets/specdata contiene 332 archivos csv que almacenan información de monitoreo de contaminación en 332 ubicaciones de EUA. Cada archivo contiene información de una unidad de monitoreo y el número de identificación del monitor es el nombre del archivo. Primero creamos un vector con los nombres de los archivos en un directorio con extensión .csv. paths &lt;- dir(&quot;tidyr_datasets/specdata&quot;, pattern = &quot;\\\\.csv$&quot; , full.names = TRUE) names(paths) &lt;- basename(paths) specdata_US &lt;- tbl_df(ldply(paths, read.csv, stringsAsFactors = FALSE)) specdata_US %&gt;% head ## # A tibble: 6 x 5 ## .id Date sulfate nitrate ID ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 001.csv 2003-01-01 NA NA 1 ## 2 001.csv 2003-01-02 NA NA 1 ## 3 001.csv 2003-01-03 NA NA 1 ## 4 001.csv 2003-01-04 NA NA 1 ## 5 001.csv 2003-01-05 NA NA 1 ## 6 001.csv 2003-01-06 NA NA 1 Las variables quedaron un poco sucias… las limpiamos y seleccionamos solo las de interés. specdata &lt;- specdata_US %&gt;% mutate( monitor = extract_numeric(.id), date = as.Date(Date)) %&gt;% select(id = ID, monitor, date, sulfate, nitrate) specdata %&gt;% head ## # A tibble: 6 x 5 ## id monitor date sulfate nitrate ## &lt;int&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2003-01-01 NA NA ## 2 1 1 2003-01-02 NA NA ## 3 1 1 2003-01-03 NA NA ## 4 1 1 2003-01-04 NA NA ## 5 1 1 2003-01-05 NA NA ## 6 1 1 2003-01-06 NA NA Figura 5.10: Datos de pensiones del IMSS e ISSSTE 2000 a 2016 (“Cuarto Informe de Gobierno, 2015-2016. Anexo Estadístico.” 2016, págs. 218-219). # Respuesta rm(list = ls()) # Funciones auxiliares # Como son archivos de excel, muchas líneas están vacias pero R no # lo entiende. Esta función quita esas lineas. quita.nas &lt;- function(df, prop.na = 0.8) { df &lt;- df[, !is.na(names(df)) &amp; names(df) != &quot;&quot;] r &lt;- sapply(seq(nrow(df)), FUN = function(x){ sum(is.na(df[x,])) }) r &lt;- r/ncol(df) df[r &lt; prop.na, ] } # Como pegaremos estados a partir de sus nombres (y no una clave) # Esta función limpia los nombres de los estados limpia &lt;- function(nn) { gsub(&quot;\\\\s+&quot;, &quot; &quot;, stringr::str_trim(nn)) %&gt;% gsub(&quot;^ *|(?&lt;= ) | *$&quot;, &quot;&quot;, ., perl=T) %&gt;% iconv(., to=&#39;ASCII//TRANSLIT&#39;) %&gt;% tolower(.) } ## Funcion para pegar la clave del estado a partir del nombre pega.estados &lt;- function(df, nombres = &quot;entidad&quot;) { df$pega &lt;- limpia(df[[nombres]]) d &lt;- rbind(readRDS(&quot;tidyr_datasets/informe/estados_p.rds&quot;), data.frame( estado = c(&quot;00&quot;, &quot;00&quot;, &quot;30&quot;, &quot;16&quot;, &quot;15&quot;, &quot;05&quot;) , pega = c(&quot;nacional&quot;, &quot;total nacional&quot;, &quot;veracruz&quot; , &quot;michoacan&quot;, &quot;estado de mexico&quot;, &quot;coahuila&quot;) , stringsAsFactors = F ) ) dd &lt;- dplyr::left_join(df, d) dplyr::select(dd, -pega) } # Limpieza de datos df &lt;- read_excel(&quot;tidyr_datasets/informe/M2_218.xlsx&quot;, skip = 4 , col_names = T) names(df) &lt;- c(&#39;entidad&#39;, paste0(&#39;imss_&#39;, 2000:2008) , paste0(&#39;issste_&#39;, 2000:2008)) df &lt;- df %&gt;% quita.nas(.) %&gt;% pega.estados(.) %&gt;% tidyr::gather(., key = variable, value = valor, -entidad , -estado, na.rm = T) %&gt;% tidyr::separate(variable, c(&quot;indicador&quot;, &quot;anio&quot;), extra = &quot;drop&quot;) %&gt;% dplyr::mutate(indicador = paste0(&quot;pago_pensiones_&quot;, indicador)) all &lt;- df df &lt;- read_excel(&quot;tidyr_datasets/informe/M2_219.xlsx&quot;, skip = 4 , col_names = T) names(df) &lt;- c(&#39;entidad&#39;, paste0(&#39;imss_&#39;, 2009:2016) , paste0(&#39;issste_&#39;, 2009:2016)) df &lt;- df %&gt;% quita.nas(.) %&gt;% pega.estados(.) %&gt;% tidyr::gather(., key = variable, value = valor, -entidad , -estado, na.rm = T) %&gt;% tidyr::separate(variable, c(&quot;indicador&quot;, &quot;anio&quot;) , extra = &quot;drop&quot;) %&gt;% dplyr::mutate(indicador = paste0(&quot;pago_pensiones_&quot;, indicador)) all &lt;- rbind(all, df) all ## # A tibble: 1,122 x 5 ## entidad estado indicador anio valor ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Total nacional 00 pago_pensiones_imss 2000 41.2 ## 2 Aguascalientes 01 pago_pensiones_imss 2000 41.5 ## 3 Baja California 02 pago_pensiones_imss 2000 38.9 ## 4 Baja California Sur 03 pago_pensiones_imss 2000 28.2 ## 5 Campeche 04 pago_pensiones_imss 2000 37.5 ## 6 Coahuila 05 pago_pensiones_imss 2000 46.5 ## 7 Colima 06 pago_pensiones_imss 2000 37.9 ## 8 Chiapas 07 pago_pensiones_imss 2000 34.9 ## 9 Chihuahua 08 pago_pensiones_imss 2000 39.2 ## 10 Ciudad de México 09 pago_pensiones_imss 2000 35.8 ## # ... with 1,112 more rows Bibliografía "],
["conclusion.html", "Capítulo 6 Conclusión", " Capítulo 6 Conclusión Hola "],
["markdown.html", "A Markdown", " A Markdown Hola "],
["r-markdown.html", "A.1 R Markdown", " A.1 R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: "],
["packrat.html", "B Packrat", " B Packrat Hola "],
["el-directorio-del-proyecto.html", "B.1 El directorio del proyecto", " B.1 El directorio del proyecto Directorio "],
["instalacion-1.html", "B.2 Instalación", " B.2 Instalación Instalación "],
["r-markdown-1.html", "B.3 R Markdown", " B.3 R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: "],
["formatos.html", "C Formatos", " C Formatos Usa la mnemotécnica del inglés: get working directory ≡ getwd. Notarás como muchas funciones tienen un nombre que acorta lo que hacen. Packrat Cuando cambian las versiones de distintos paquetes de R, es posible que código que solía funcionar deje de hacerlo. Por esta razón, es conveniente empaquetar proyectos de código de manera que el código en un proyecto específico tenga asociados también las versiones específicas de los paquetes con los cuáles fue creado. Una forma de lograr esto es utilizando packrat. Para mayor detalle, ver el apéndice B. Ejercicios primero luego después En R Todo lo que existe es un objeto. Todo lo que sucede es una llamada a una función. Note Caution Important Tip Warning "],
["bibliografia.html", "Bibliografía", " Bibliografía "]
]
